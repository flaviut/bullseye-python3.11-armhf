Description: Updates from the 3.11 branch (until 2022-11-03).
 We pick the latest updates from the maintainance branch, and carry them in a
 patch, rather than creating and uploading uploading a new .orig tarball.

# git diff --no-renames deaf509e8fc6e0363bd6f26d52ad42f976ec42f2 eb023a84d92661bcde9dfe1641576774710f6c64 | filterdiff -x ?/.hgignore -x ?/.hgeol -x ?/.hgtags -x ?/.hgtouch -x ?/.gitignore -x ?/.gitattributes -x '?/.github/*' -x '?/.git*' -x ?/.codecov.yml -x ?/.travis.yml -x ?/configure --remove-timestamps

diff --git a/Doc/about.rst b/Doc/about.rst
index 0ce3566792..5e6160ff27 100644
--- a/Doc/about.rst
+++ b/Doc/about.rst
@@ -7,7 +7,7 @@ These documents are generated from `reStructuredText`_ sources by `Sphinx`_, a
 document processor specifically written for the Python documentation.
 
 .. _reStructuredText: https://docutils.sourceforge.io/rst.html
-.. _Sphinx: http://sphinx-doc.org/
+.. _Sphinx: https://www.sphinx-doc.org/
 
 .. In the online version of these documents, you can submit comments and suggest
    changes directly on the documentation pages.
diff --git a/Doc/c-api/arg.rst b/Doc/c-api/arg.rst
index 0c15045fcb..85f9eda17a 100644
--- a/Doc/c-api/arg.rst
+++ b/Doc/c-api/arg.rst
@@ -335,7 +335,7 @@ Other objects
       status = converter(object, address);
 
    where *object* is the Python object to be converted and *address* is the
-   :c:type:`void*` argument that was passed to the ``PyArg_Parse*`` function.
+   :c:expr:`void*` argument that was passed to the ``PyArg_Parse*`` function.
    The returned *status* should be ``1`` for a successful conversion and ``0`` if
    the conversion has failed.  When the conversion fails, the *converter* function
    should raise an exception and leave the content of *address* unmodified.
diff --git a/Doc/c-api/conversion.rst b/Doc/c-api/conversion.rst
index 9b9c4ffa4d..fdb321fe7a 100644
--- a/Doc/c-api/conversion.rst
+++ b/Doc/c-api/conversion.rst
@@ -28,7 +28,8 @@ not.
 The wrappers ensure that ``str[size-1]`` is always ``'\0'`` upon return. They
 never write more than *size* bytes (including the trailing ``'\0'``) into str.
 Both functions require that ``str != NULL``, ``size > 0``, ``format != NULL``
-and ``size < INT_MAX``.
+and ``size < INT_MAX``. Note that this means there is no equivalent to the C99
+``n = snprintf(NULL, 0, ...)`` which would determine the necessary buffer size.
 
 The return value (*rv*) for these functions should be interpreted as follows:
 
diff --git a/Doc/c-api/dict.rst b/Doc/c-api/dict.rst
index 041afedee2..819168d487 100644
--- a/Doc/c-api/dict.rst
+++ b/Doc/c-api/dict.rst
@@ -118,7 +118,7 @@ Dictionary Objects
 .. c:function:: PyObject* PyDict_GetItemString(PyObject *p, const char *key)
 
    This is the same as :c:func:`PyDict_GetItem`, but *key* is specified as a
-   :c:type:`const char*`, rather than a :c:expr:`PyObject*`.
+   :c:expr:`const char*`, rather than a :c:expr:`PyObject*`.
 
    Note that exceptions which occur while calling :meth:`__hash__` and
    :meth:`__eq__` methods and creating a temporary string object
diff --git a/Doc/c-api/init.rst b/Doc/c-api/init.rst
index aecc3b877d..55c05096ae 100644
--- a/Doc/c-api/init.rst
+++ b/Doc/c-api/init.rst
@@ -1741,8 +1741,8 @@ you need to include :file:`pythread.h` to use thread-local storage.
 
 .. note::
    None of these API functions handle memory management on behalf of the
-   :c:type:`void*` values.  You need to allocate and deallocate them yourself.
-   If the :c:type:`void*` values happen to be :c:expr:`PyObject*`, these
+   :c:expr:`void*` values.  You need to allocate and deallocate them yourself.
+   If the :c:expr:`void*` values happen to be :c:expr:`PyObject*`, these
    functions don't do refcount operations on them either.
 
 .. _thread-specific-storage-api:
@@ -1800,7 +1800,7 @@ is not possible due to its implementation being opaque at build time.
 
    .. note::
       A freed key becomes a dangling pointer. You should reset the key to
-      `NULL`.
+      ``NULL``.
 
 
 Methods
diff --git a/Doc/c-api/marshal.rst b/Doc/c-api/marshal.rst
index 571d68cdf3..8e25968c69 100644
--- a/Doc/c-api/marshal.rst
+++ b/Doc/c-api/marshal.rst
@@ -43,7 +43,7 @@ The following functions allow marshalled values to be read back in.
 
 .. c:function:: long PyMarshal_ReadLongFromFile(FILE *file)
 
-   Return a C :c:type:`long` from the data stream in a :c:expr:`FILE*` opened
+   Return a C :c:expr:`long` from the data stream in a :c:expr:`FILE*` opened
    for reading.  Only a 32-bit value can be read in using this function,
    regardless of the native size of :c:expr:`long`.
 
@@ -53,7 +53,7 @@ The following functions allow marshalled values to be read back in.
 
 .. c:function:: int PyMarshal_ReadShortFromFile(FILE *file)
 
-   Return a C :c:type:`short` from the data stream in a :c:expr:`FILE*` opened
+   Return a C :c:expr:`short` from the data stream in a :c:expr:`FILE*` opened
    for reading.  Only a 16-bit value can be read in using this function,
    regardless of the native size of :c:expr:`short`.
 
diff --git a/Doc/c-api/memory.rst b/Doc/c-api/memory.rst
index f726cd4866..7041c15d23 100644
--- a/Doc/c-api/memory.rst
+++ b/Doc/c-api/memory.rst
@@ -95,6 +95,8 @@ for the I/O buffer escapes completely the Python memory manager.
 Allocator Domains
 =================
 
+.. _allocator-domains:
+
 All allocating functions belong to one of three different "domains" (see also
 :c:type:`PyMemAllocatorDomain`). These domains represent different allocation
 strategies and are optimized for different purposes. The specific details on
@@ -479,6 +481,25 @@ Customize Memory Allocators
    See also :c:member:`PyPreConfig.allocator` and :ref:`Preinitialize Python
    with PyPreConfig <c-preinit>`.
 
+   .. warning::
+
+       :c:func:`PyMem_SetAllocator` does have the following contract:
+
+        * It can be called after :c:func:`Py_PreInitialize` and before
+          :c:func:`Py_InitializeFromConfig` to install a custom memory
+          allocator. There are no restrictions over the installed allocator
+          other than the ones imposed by the domain (for instance, the Raw
+          Domain allows the allocator to be called without the GIL held). See
+          :ref:`the section on allocator domains <allocator-domains>` for more
+          information.
+
+        * If called after Python has finish initializing (after
+          :c:func:`Py_InitializeFromConfig` has been called) the allocator
+          **must** wrap the existing allocator. Substituting the current
+          allocator for some other arbitrary one is **not supported**.
+
+
+
 .. c:function:: void PyMem_SetupDebugHooks(void)
 
    Setup :ref:`debug hooks in the Python memory allocators <pymem-debug-hooks>`
diff --git a/Doc/c-api/typehints.rst b/Doc/c-api/typehints.rst
index 88554a346c..4c1957a2a1 100644
--- a/Doc/c-api/typehints.rst
+++ b/Doc/c-api/typehints.rst
@@ -15,7 +15,7 @@ two types exist -- :ref:`GenericAlias <types-genericalias>` and
    Equivalent to calling the Python class
    :class:`types.GenericAlias`.  The *origin* and *args* arguments set the
    ``GenericAlias``\ 's ``__origin__`` and ``__args__`` attributes respectively.
-   *origin* should be a :c:type:`PyTypeObject*`, and *args* can be a
+   *origin* should be a :c:expr:`PyTypeObject*`, and *args* can be a
    :c:expr:`PyTupleObject*` or any ``PyObject*``.  If *args* passed is
    not a tuple, a 1-tuple is automatically constructed and ``__args__`` is set
    to ``(args,)``.
diff --git a/Doc/c-api/typeobj.rst b/Doc/c-api/typeobj.rst
index 4f4e239bfa..af0d760a30 100644
--- a/Doc/c-api/typeobj.rst
+++ b/Doc/c-api/typeobj.rst
@@ -1484,7 +1484,7 @@ and :c:type:`PyType_Type` effectively act as defaults.)
    If the instances of this type are weakly referenceable, this field is greater
    than zero and contains the offset in the instance structure of the weak
    reference list head (ignoring the GC header, if present); this offset is used by
-   :c:func:`PyObject_ClearWeakRefs` and the :c:func:`PyWeakref_\*` functions.  The
+   :c:func:`PyObject_ClearWeakRefs` and the ``PyWeakref_*`` functions.  The
    instance structure needs to include a field of type :c:expr:`PyObject*` which is
    initialized to ``NULL``.
 
diff --git a/Doc/conf.py b/Doc/conf.py
index e5c989da0b..fd4ee2d5ee 100644
--- a/Doc/conf.py
+++ b/Doc/conf.py
@@ -234,28 +234,3 @@
 # Relative filename of the data files
 refcount_file = 'data/refcounts.dat'
 stable_abi_file = 'data/stable_abi.dat'
-
-# Sphinx 2 and Sphinx 3 compatibility
-# -----------------------------------
-
-# bpo-40204: Allow Sphinx 2 syntax in the C domain
-c_allow_pre_v3 = True
-
-# bpo-40204: Disable warnings on Sphinx 2 syntax of the C domain since the
-# documentation is built with -W (warnings treated as errors).
-c_warn_on_allowed_pre_v3 = False
-
-# Fix '!' not working with C domain when pre_v3 is enabled
-import sphinx
-
-if sphinx.version_info[:2] < (5, 3):
-    from sphinx.domains.c import CXRefRole
-
-    original_run = CXRefRole.run
-
-    def new_run(self):
-        if self.disabled:
-            return super(CXRefRole, self).run()
-        return original_run(self)
-
-    CXRefRole.run = new_run
diff --git a/Doc/extending/embedding.rst b/Doc/extending/embedding.rst
index 5f5abdf9c1..e64db37334 100644
--- a/Doc/extending/embedding.rst
+++ b/Doc/extending/embedding.rst
@@ -298,16 +298,16 @@ be directly useful to you:
 
   .. code-block:: shell-session
 
-     $ /opt/bin/python3.4-config --cflags
-     -I/opt/include/python3.4m -I/opt/include/python3.4m -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes
+     $ /opt/bin/python3.11-config --cflags
+     -I/opt/include/python3.11 -I/opt/include/python3.11 -Wsign-compare  -DNDEBUG -g -fwrapv -O3 -Wall
 
-* ``pythonX.Y-config --ldflags`` will give you the recommended flags when
-  linking:
+* ``pythonX.Y-config --ldflags --embed`` will give you the recommended flags
+  when linking:
 
   .. code-block:: shell-session
 
-     $ /opt/bin/python3.4-config --ldflags
-     -L/opt/lib/python3.4/config-3.4m -lpthread -ldl -lutil -lm -lpython3.4m -Xlinker -export-dynamic
+     $ /opt/bin/python3.11-config --ldflags --embed
+     -L/opt/lib/python3.11/config-3.11-x86_64-linux-gnu -L/opt/lib -lpython3.11 -lpthread -ldl  -lutil -lm
 
 .. note::
    To avoid confusion between several Python installations (and especially
diff --git a/Doc/extending/newtypes.rst b/Doc/extending/newtypes.rst
index 21ef1f04cf..5ba6383640 100644
--- a/Doc/extending/newtypes.rst
+++ b/Doc/extending/newtypes.rst
@@ -208,7 +208,7 @@ a special case, for which the new value passed to the handler is ``NULL``.
 Python supports two pairs of attribute handlers; a type that supports attributes
 only needs to implement the functions for one pair.  The difference is that one
 pair takes the name of the attribute as a :c:expr:`char\*`, while the other
-accepts a :c:type:`PyObject\*`.  Each type can use whichever pair makes more
+accepts a :c:expr:`PyObject*`.  Each type can use whichever pair makes more
 sense for the implementation's convenience. ::
 
    getattrfunc  tp_getattr;        /* char * version */
@@ -341,7 +341,7 @@ Type-specific Attribute Management
 
 For simplicity, only the :c:expr:`char\*` version will be demonstrated here; the
 type of the name parameter is the only difference between the :c:expr:`char\*`
-and :c:type:`PyObject\*` flavors of the interface. This example effectively does
+and :c:expr:`PyObject*` flavors of the interface. This example effectively does
 the same thing as the generic example above, but does not use the generic
 support added in Python 2.2.  It explains how the handler functions are
 called, so that if you do need to extend their functionality, you'll understand
diff --git a/Doc/faq/general.rst b/Doc/faq/general.rst
index ad4e38a04a..489bca7643 100644
--- a/Doc/faq/general.rst
+++ b/Doc/faq/general.rst
@@ -188,7 +188,7 @@ at https://docs.python.org/3/.  PDF, plain text, and downloadable HTML versions
 also available at https://docs.python.org/3/download.html.
 
 The documentation is written in reStructuredText and processed by `the Sphinx
-documentation tool <http://sphinx-doc.org/>`__.  The reStructuredText source for
+documentation tool <https://www.sphinx-doc.org/>`__.  The reStructuredText source for
 the documentation is part of the Python source distribution.
 
 
@@ -270,7 +270,7 @@ Where in the world is www.python.org located?
 ---------------------------------------------
 
 The Python project's infrastructure is located all over the world and is managed
-by the Python Infrastructure Team. Details `here <http://infra.psf.io>`__.
+by the Python Infrastructure Team. Details `here <https://infra.psf.io>`__.
 
 
 Why is it called Python?
diff --git a/Doc/faq/programming.rst b/Doc/faq/programming.rst
index 76bd1538b4..f3c5b0f764 100644
--- a/Doc/faq/programming.rst
+++ b/Doc/faq/programming.rst
@@ -25,8 +25,9 @@ Reference Manual <pdb>`. You can also write your own debugger by using the code
 for pdb as an example.
 
 The IDLE interactive development environment, which is part of the standard
-Python distribution (normally available as Tools/scripts/idle), includes a
-graphical debugger.
+Python distribution (normally available as
+`Tools/scripts/idle3 <https://github.com/python/cpython/blob/main/Tools/scripts/idle3>`_),
+includes a graphical debugger.
 
 PythonWin is a Python IDE that includes a GUI debugger based on pdb.  The
 PythonWin debugger colors breakpoints and has quite a few cool features such as
@@ -78,7 +79,8 @@ set of modules required by a program and bind these modules together with a
 Python binary to produce a single executable.
 
 One is to use the freeze tool, which is included in the Python source tree as
-``Tools/freeze``. It converts Python byte code to C arrays; with a C compiler you can
+`Tools/freeze <https://github.com/python/cpython/tree/main/Tools/freeze>`_.
+It converts Python byte code to C arrays; with a C compiler you can
 embed all your modules into a new program, which is then linked with the
 standard Python modules.
 
@@ -114,7 +116,7 @@ Core Language
 Why am I getting an UnboundLocalError when the variable has a value?
 --------------------------------------------------------------------
 
-It can be a surprise to get the UnboundLocalError in previously working
+It can be a surprise to get the :exc:`UnboundLocalError` in previously working
 code when it is modified by adding an assignment statement somewhere in
 the body of a function.
 
@@ -123,6 +125,7 @@ This code:
    >>> x = 10
    >>> def bar():
    ...     print(x)
+   ...
    >>> bar()
    10
 
@@ -133,7 +136,7 @@ works, but this code:
    ...     print(x)
    ...     x += 1
 
-results in an UnboundLocalError:
+results in an :exc:`!UnboundLocalError`:
 
    >>> foo()
    Traceback (most recent call last):
@@ -155,6 +158,7 @@ global:
    ...     global x
    ...     print(x)
    ...     x += 1
+   ...
    >>> foobar()
    10
 
@@ -176,6 +180,7 @@ keyword:
    ...        x += 1
    ...    bar()
    ...    print(x)
+   ...
    >>> foo()
    10
    11
@@ -273,7 +278,7 @@ main.py::
    import mod
    print(config.x)
 
-Note that using a module is also the basis for implementing the Singleton design
+Note that using a module is also the basis for implementing the singleton design
 pattern, for the same reason.
 
 
@@ -291,9 +296,9 @@ using multiple imports per line uses less screen space.
 
 It's good practice if you import modules in the following order:
 
-1. standard library modules -- e.g. ``sys``, ``os``, ``getopt``, ``re``
+1. standard library modules -- e.g. :mod:`sys`, :mod:`os`, :mod:`argparse`, :mod:`re`
 2. third-party library modules (anything installed in Python's site-packages
-   directory) -- e.g. mx.DateTime, ZODB, PIL.Image, etc.
+   directory) -- e.g. :mod:`!dateutil`, :mod:`!requests`, :mod:`!PIL.Image`
 3. locally developed modules
 
 It is sometimes necessary to move imports to a function or class to avoid
@@ -471,7 +476,7 @@ object ``x`` refers to).  After this assignment we have two objects (the ints
 
 Some operations (for example ``y.append(10)`` and ``y.sort()``) mutate the
 object, whereas superficially similar operations (for example ``y = y + [10]``
-and ``sorted(y)``) create a new object.  In general in Python (and in all cases
+and :func:`sorted(y) <sorted>`) create a new object.  In general in Python (and in all cases
 in the standard library) a method that mutates an object will return ``None``
 to help avoid getting the two types of operations confused.  So if you
 mistakenly write ``y.sort()`` thinking it will give you a sorted copy of ``y``,
@@ -644,7 +649,7 @@ Sequences can be copied by slicing::
 How can I find the methods or attributes of an object?
 ------------------------------------------------------
 
-For an instance x of a user-defined class, ``dir(x)`` returns an alphabetized
+For an instance ``x`` of a user-defined class, :func:`dir(x) <dir>` returns an alphabetized
 list of the names containing the instance attributes and methods and attributes
 defined by its class.
 
@@ -669,9 +674,9 @@ callable. Consider the following code::
    <__main__.A object at 0x16D07CC>
 
 Arguably the class has a name: even though it is bound to two names and invoked
-through the name B the created instance is still reported as an instance of
-class A.  However, it is impossible to say whether the instance's name is a or
-b, since both names are bound to the same value.
+through the name ``B`` the created instance is still reported as an instance of
+class ``A``.  However, it is impossible to say whether the instance's name is ``a`` or
+``b``, since both names are bound to the same value.
 
 Generally speaking it should not be necessary for your code to "know the names"
 of particular values. Unless you are deliberately writing introspective
@@ -841,7 +846,7 @@ How do I get int literal attribute instead of SyntaxError?
 ----------------------------------------------------------
 
 Trying to lookup an ``int`` literal attribute in the normal manner gives
-a syntax error because the period is seen as a decimal point::
+a :exc:`SyntaxError` because the period is seen as a decimal point::
 
    >>> 1.__class__
      File "<stdin>", line 1
@@ -887,7 +892,7 @@ leading '0' in a decimal number (except '0').
 How do I convert a number to a string?
 --------------------------------------
 
-To convert, e.g., the number 144 to the string '144', use the built-in type
+To convert, e.g., the number ``144`` to the string ``'144'``, use the built-in type
 constructor :func:`str`.  If you want a hexadecimal or octal representation, use
 the built-in functions :func:`hex` or :func:`oct`.  For fancy formatting, see
 the :ref:`f-strings` and :ref:`formatstrings` sections,
@@ -1006,11 +1011,11 @@ Not as such.
 For simple input parsing, the easiest approach is usually to split the line into
 whitespace-delimited words using the :meth:`~str.split` method of string objects
 and then convert decimal strings to numeric values using :func:`int` or
-:func:`float`.  ``split()`` supports an optional "sep" parameter which is useful
+:func:`float`.  :meth:`!split()` supports an optional "sep" parameter which is useful
 if the line uses something other than whitespace as a separator.
 
 For more complicated input parsing, regular expressions are more powerful
-than C's :c:func:`sscanf` and better suited for the task.
+than C's ``sscanf`` and better suited for the task.
 
 
 What does 'UnicodeDecodeError' or 'UnicodeEncodeError' error  mean?
@@ -1206,15 +1211,16 @@ difference is that a Python list can contain objects of many different types.
 
 The ``array`` module also provides methods for creating arrays of fixed types
 with compact representations, but they are slower to index than lists.  Also
-note that NumPy and other third party packages define array-like structures with
+note that `NumPy <https://numpy.org/>`_
+and other third party packages define array-like structures with
 various characteristics as well.
 
-To get Lisp-style linked lists, you can emulate cons cells using tuples::
+To get Lisp-style linked lists, you can emulate *cons cells* using tuples::
 
    lisp_list = ("like",  ("this",  ("example", None) ) )
 
 If mutability is desired, you could use lists instead of tuples.  Here the
-analogue of lisp car is ``lisp_list[0]`` and the analogue of cdr is
+analogue of a Lisp *car* is ``lisp_list[0]`` and the analogue of *cdr* is
 ``lisp_list[1]``.  Only do this if you're sure you really need to, because it's
 usually a lot slower than using Python lists.
 
@@ -1270,7 +1276,7 @@ use a list comprehension::
    A = [[None] * w for i in range(h)]
 
 Or, you can use an extension that provides a matrix datatype; `NumPy
-<http://www.numpy.org/>`_ is the best known.
+<https://numpy.org/>`_ is the best known.
 
 
 How do I apply a method to a sequence of objects?
@@ -1334,11 +1340,12 @@ that even though there was an error, the append worked::
     ['foo', 'item']
 
 To see why this happens, you need to know that (a) if an object implements an
-``__iadd__`` magic method, it gets called when the ``+=`` augmented assignment
+:meth:`~object.__iadd__` magic method, it gets called when the ``+=`` augmented
+assignment
 is executed, and its return value is what gets used in the assignment statement;
-and (b) for lists, ``__iadd__`` is equivalent to calling ``extend`` on the list
+and (b) for lists, :meth:`!__iadd__` is equivalent to calling :meth:`~list.extend` on the list
 and returning the list.  That's why we say that for lists, ``+=`` is a
-"shorthand" for ``list.extend``::
+"shorthand" for :meth:`!list.extend`::
 
     >>> a_list = []
     >>> a_list += [1]
@@ -1363,7 +1370,7 @@ Thus, in our tuple example what is happening is equivalent to::
      ...
    TypeError: 'tuple' object does not support item assignment
 
-The ``__iadd__`` succeeds, and thus the list is extended, but even though
+The :meth:`!__iadd__` succeeds, and thus the list is extended, but even though
 ``result`` points to the same object that ``a_tuple[0]`` already points to,
 that final assignment still results in an error, because tuples are immutable.
 
@@ -1440,7 +1447,8 @@ See also :ref:`why-self`.
 How do I check if an object is an instance of a given class or of a subclass of it?
 -----------------------------------------------------------------------------------
 
-Use the built-in function ``isinstance(obj, cls)``.  You can check if an object
+Use the built-in function :func:`isinstance(obj, cls) <isinstance>`.  You can
+check if an object
 is an instance of any of a number of classes by providing a tuple instead of a
 single class, e.g. ``isinstance(obj, (class1, class2, ...))``, and can also
 check whether an object is one of Python's built-in types, e.g.
@@ -1537,13 +1545,13 @@ Here the ``UpperOut`` class redefines the ``write()`` method to convert the
 argument string to uppercase before calling the underlying
 ``self._outfile.write()`` method.  All other methods are delegated to the
 underlying ``self._outfile`` object.  The delegation is accomplished via the
-``__getattr__`` method; consult :ref:`the language reference <attribute-access>`
+:meth:`~object.__getattr__` method; consult :ref:`the language reference <attribute-access>`
 for more information about controlling attribute access.
 
 Note that for more general cases delegation can get trickier. When attributes
-must be set as well as retrieved, the class must define a :meth:`__setattr__`
+must be set as well as retrieved, the class must define a :meth:`~object.__setattr__`
 method too, and it must do so carefully.  The basic implementation of
-:meth:`__setattr__` is roughly equivalent to the following::
+:meth:`!__setattr__` is roughly equivalent to the following::
 
    class X:
        ...
@@ -1551,7 +1559,8 @@ method too, and it must do so carefully.  The basic implementation of
            self.__dict__[name] = value
        ...
 
-Most :meth:`__setattr__` implementations must modify ``self.__dict__`` to store
+Most :meth:`!__setattr__` implementations must modify
+:meth:`self.__dict__ <object.__dict__>` to store
 local state for self without causing an infinite recursion.
 
 
@@ -1689,17 +1698,17 @@ My class defines __del__ but it is not called when I delete the object.
 
 There are several possible reasons for this.
 
-The del statement does not necessarily call :meth:`__del__` -- it simply
+The :keyword:`del` statement does not necessarily call :meth:`~object.__del__` -- it simply
 decrements the object's reference count, and if this reaches zero
-:meth:`__del__` is called.
+:meth:`!__del__` is called.
 
 If your data structures contain circular links (e.g. a tree where each child has
 a parent reference and each parent has a list of children) the reference counts
 will never go back to zero.  Once in a while Python runs an algorithm to detect
 such cycles, but the garbage collector might run some time after the last
-reference to your data structure vanishes, so your :meth:`__del__` method may be
+reference to your data structure vanishes, so your :meth:`!__del__` method may be
 called at an inconvenient and random time. This is inconvenient if you're trying
-to reproduce a problem. Worse, the order in which object's :meth:`__del__`
+to reproduce a problem. Worse, the order in which object's :meth:`!__del__`
 methods are executed is arbitrary.  You can run :func:`gc.collect` to force a
 collection, but there *are* pathological cases where objects will never be
 collected.
@@ -1707,7 +1716,7 @@ collected.
 Despite the cycle collector, it's still a good idea to define an explicit
 ``close()`` method on objects to be called whenever you're done with them.  The
 ``close()`` method can then remove attributes that refer to subobjects.  Don't
-call :meth:`__del__` directly -- :meth:`__del__` should call ``close()`` and
+call :meth:`!__del__` directly -- :meth:`!__del__` should call ``close()`` and
 ``close()`` should make sure that it can be called more than once for the same
 object.
 
@@ -1724,7 +1733,7 @@ and sibling references (if they need them!).
    Normally, calling :func:`sys.exc_clear` will take care of this by clearing
    the last recorded exception.
 
-Finally, if your :meth:`__del__` method raises an exception, a warning message
+Finally, if your :meth:`!__del__` method raises an exception, a warning message
 is printed to :data:`sys.stderr`.
 
 
@@ -1852,8 +1861,8 @@ For example, here is the implementation of
 How can a subclass control what data is stored in an immutable instance?
 ------------------------------------------------------------------------
 
-When subclassing an immutable type, override the :meth:`__new__` method
-instead of the :meth:`__init__` method.  The latter only runs *after* an
+When subclassing an immutable type, override the :meth:`~object.__new__` method
+instead of the :meth:`~object.__init__` method.  The latter only runs *after* an
 instance is created, which is too late to alter data in an immutable
 instance.
 
@@ -1955,8 +1964,8 @@ can't be made to work because it cannot detect changes to the
 attributes.
 
 To make the *lru_cache* approach work when the *station_id* is mutable,
-the class needs to define the *__eq__* and *__hash__* methods so that
-the cache can detect relevant attribute updates::
+the class needs to define the :meth:`~object.__eq__` and :meth:`~object.__hash__`
+methods so that the cache can detect relevant attribute updates::
 
     class Weather:
         "Example with a mutable station identifier"
diff --git a/Doc/glossary.rst b/Doc/glossary.rst
index 59f9426f60..3d74d550dc 100644
--- a/Doc/glossary.rst
+++ b/Doc/glossary.rst
@@ -882,7 +882,7 @@ Glossary
 
    package
       A Python :term:`module` which can contain submodules or recursively,
-      subpackages.  Technically, a package is a Python module with an
+      subpackages.  Technically, a package is a Python module with a
       ``__path__`` attribute.
 
       See also :term:`regular package` and :term:`namespace package`.
diff --git a/Doc/howto/argparse.rst b/Doc/howto/argparse.rst
index a97d10cfe6..adc2f37371 100644
--- a/Doc/howto/argparse.rst
+++ b/Doc/howto/argparse.rst
@@ -732,9 +732,9 @@ your program, just in case they don't know::
    if args.quiet:
        print(answer)
    elif args.verbose:
-       print("{} to the power {} equals {}".format(args.x, args.y, answer))
+       print(f"{args.x} to the power {args.y} equals {answer}")
    else:
-       print("{}^{} == {}".format(args.x, args.y, answer))
+       print(f"{args.x}^{args.y} == {answer}")
 
 Note that slight difference in the usage text. Note the ``[-v | -q]``,
 which tells us that we can either use ``-v`` or ``-q``,
diff --git a/Doc/howto/clinic.rst b/Doc/howto/clinic.rst
index e5ed32f69a..4e9b3dee09 100644
--- a/Doc/howto/clinic.rst
+++ b/Doc/howto/clinic.rst
@@ -1,5 +1,7 @@
 .. highlight:: c
 
+.. _howto-clinic:
+
 **********************
 Argument Clinic How-To
 **********************
diff --git a/Doc/howto/functional.rst b/Doc/howto/functional.rst
index 1c3bd23f9f..e68bc2ebb1 100644
--- a/Doc/howto/functional.rst
+++ b/Doc/howto/functional.rst
@@ -994,7 +994,7 @@ requesting iterator-2 and its corresponding key.
 The functools module
 ====================
 
-The :mod:`functools` module in Python 2.5 contains some higher-order functions.
+The :mod:`functools` module contains some higher-order functions.
 A **higher-order function** takes one or more functions as input and returns a
 new function.  The most useful tool in this module is the
 :func:`functools.partial` function.
diff --git a/Doc/howto/isolating-extensions.rst b/Doc/howto/isolating-extensions.rst
index 2657b4ec6a..2eddb582da 100644
--- a/Doc/howto/isolating-extensions.rst
+++ b/Doc/howto/isolating-extensions.rst
@@ -461,7 +461,7 @@ Module State Access from Slot Methods, Getters and Setters
 
    .. After adding to limited API:
 
-      If you use the `limited API <https://docs.python.org/3/c-api/stable.html>__,
+      If you use the :ref:`limited API <stable>,
       you must update ``Py_LIMITED_API`` to ``0x030b0000``, losing ABI
       compatibility with earlier versions.
 
diff --git a/Doc/howto/logging-cookbook.rst b/Doc/howto/logging-cookbook.rst
index c51071879a..bf6f54a841 100644
--- a/Doc/howto/logging-cookbook.rst
+++ b/Doc/howto/logging-cookbook.rst
@@ -765,13 +765,71 @@ serialization.
 Running a logging socket listener in production
 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 
-To run a logging listener in production, you may need to use a process-management tool
-such as `Supervisor <http://supervisord.org/>`_. `Here
-<https://gist.github.com/vsajip/4b227eeec43817465ca835ca66f75e2b>`_ is a Gist which
-provides the bare-bones files to run the above functionality using Supervisor: you
-will need to change the ``/path/to/`` parts in the Gist to reflect the actual paths you
-want to use.
-
+.. _socket-listener-gist: https://gist.github.com/vsajip/4b227eeec43817465ca835ca66f75e2b
+
+To run a logging listener in production, you may need to use a
+process-management tool such as `Supervisor <http://supervisord.org/>`_.
+`Here is a Gist <socket-listener-gist_>`__
+which provides the bare-bones files to run the above functionality using
+Supervisor. It consists of the following files:
+
++-------------------------+----------------------------------------------------+
+| File                    | Purpose                                            |
++=========================+====================================================+
+| :file:`prepare.sh`      | A Bash script to prepare the environment for       |
+|                         | testing                                            |
++-------------------------+----------------------------------------------------+
+| :file:`supervisor.conf` | The Supervisor configuration file, which has       |
+|                         | entries for the listener and a multi-process web   |
+|                         | application                                        |
++-------------------------+----------------------------------------------------+
+| :file:`ensure_app.sh`   | A Bash script to ensure that Supervisor is running |
+|                         | with the above configuration                       |
++-------------------------+----------------------------------------------------+
+| :file:`log_listener.py` | The socket listener program which receives log     |
+|                         | events and records them to a file                  |
++-------------------------+----------------------------------------------------+
+| :file:`main.py`         | A simple web application which performs logging    |
+|                         | via a socket connected to the listener             |
++-------------------------+----------------------------------------------------+
+| :file:`webapp.json`     | A JSON configuration file for the web application  |
++-------------------------+----------------------------------------------------+
+| :file:`client.py`       | A Python script to exercise the web application    |
++-------------------------+----------------------------------------------------+
+
+The web application uses `Gunicorn <https://gunicorn.org/>`_, which is a
+popular web application server that starts multiple worker processes to handle
+requests. This example setup shows how the workers can write to the same log file
+without conflicting with one another --- they all go through the socket listener.
+
+To test these files, do the following in a POSIX environment:
+
+#. Download `the Gist <socket-listener-gist_>`__
+   as a ZIP archive using the :guilabel:`Download ZIP` button.
+
+#. Unzip the above files from the archive into a scratch directory.
+
+#. In the scratch directory, run ``bash prepare.sh`` to get things ready.
+   This creates a :file:`run` subdirectory to contain Supervisor-related and
+   log files, and a :file:`venv` subdirectory to contain a virtual environment
+   into which ``bottle``, ``gunicorn`` and ``supervisor`` are installed.
+
+#. Run ``bash ensure_app.sh`` to ensure that Supervisor is running with
+   the above configuration.
+
+#. Run ``venv/bin/python client.py`` to exercise the web application,
+   which will lead to records being written to the log.
+
+#. Inspect the log files in the :file:`run` subdirectory. You should see the
+   most recent log lines in files matching the pattern :file:`app.log*`. They won't be in
+   any particular order, since they have been handled concurrently by different
+   worker processes in a non-deterministic way.
+
+#. You can shut down the listener and the web application by running
+   ``venv/bin/supervisorctl -c supervisor.conf shutdown``.
+
+You may need to tweak the configuration files in the unlikely event that the
+configured ports clash with something else in your test environment.
 
 .. _context-info:
 
@@ -3708,10 +3766,75 @@ instance). Then, you'd get this kind of result:
     WARNING:demo:Bar
     >>>
 
-Of course, these above examples show output according to the format used by
+Of course, the examples above show output according to the format used by
 :func:`~logging.basicConfig`, but you can use a different formatter when you
 configure logging.
 
+Note that with the above scheme, you are somewhat at the mercy of buffering and
+the sequence of write calls which you are intercepting. For example, with the
+definition of ``LoggerWriter`` above, if you have the snippet
+
+.. code-block:: python
+
+    sys.stderr = LoggerWriter(logger, logging.WARNING)
+    1 / 0
+
+then running the script results in
+
+.. code-block:: text
+
+    WARNING:demo:Traceback (most recent call last):
+
+    WARNING:demo:  File "/home/runner/cookbook-loggerwriter/test.py", line 53, in <module>
+
+    WARNING:demo:
+    WARNING:demo:main()
+    WARNING:demo:  File "/home/runner/cookbook-loggerwriter/test.py", line 49, in main
+
+    WARNING:demo:
+    WARNING:demo:1 / 0
+    WARNING:demo:ZeroDivisionError
+    WARNING:demo::
+    WARNING:demo:division by zero
+
+As you can see, this output isn't ideal. That's because the underlying code
+which writes to ``sys.stderr`` makes mutiple writes, each of which results in a
+separate logged line (for example, the last three lines above). To get around
+this problem, you need to buffer things and only output log lines when newlines
+are seen. Let's use a slghtly better implementation of ``LoggerWriter``:
+
+.. code-block:: python
+
+    class BufferingLoggerWriter(LoggerWriter):
+        def __init__(self, logger, level):
+            super().__init__(logger, level)
+            self.buffer = ''
+
+        def write(self, message):
+            if '\n' not in message:
+                self.buffer += message
+            else:
+                parts = message.split('\n')
+                if self.buffer:
+                    s = self.buffer + parts.pop(0)
+                    self.logger.log(self.level, s)
+                self.buffer = parts.pop()
+                for part in parts:
+                    self.logger.log(self.level, part)
+
+This just buffers up stuff until a newline is seen, and then logs complete
+lines. With this approach, you get better output:
+
+.. code-block:: text
+
+    WARNING:demo:Traceback (most recent call last):
+    WARNING:demo:  File "/home/runner/cookbook-loggerwriter/main.py", line 55, in <module>
+    WARNING:demo:    main()
+    WARNING:demo:  File "/home/runner/cookbook-loggerwriter/main.py", line 52, in main
+    WARNING:demo:    1/0
+    WARNING:demo:ZeroDivisionError: division by zero
+
+
 .. patterns-to-avoid:
 
 Patterns to avoid
diff --git a/Doc/howto/sorting.rst b/Doc/howto/sorting.rst
index 588e895b04..decce12bf3 100644
--- a/Doc/howto/sorting.rst
+++ b/Doc/howto/sorting.rst
@@ -247,7 +247,7 @@ To accommodate those situations, Python provides
 :class:`functools.cmp_to_key` to wrap the comparison function
 to make it usable as a key function::
 
-    sorted(words, key=cmp_to_key(strcoll)
+    sorted(words, key=cmp_to_key(strcoll))  # locale-aware sort order
 
 Odds and Ends
 =============
diff --git a/Doc/howto/unicode.rst b/Doc/howto/unicode.rst
index 4969d2420d..ca09aee72b 100644
--- a/Doc/howto/unicode.rst
+++ b/Doc/howto/unicode.rst
@@ -517,7 +517,7 @@ References
 
 Some good alternative discussions of Python's Unicode support are:
 
-* `Processing Text Files in Python 3 <http://python-notes.curiousefficiency.org/en/latest/python3/text_file_processing.html>`_, by Nick Coghlan.
+* `Processing Text Files in Python 3 <https://python-notes.curiousefficiency.org/en/latest/python3/text_file_processing.html>`_, by Nick Coghlan.
 * `Pragmatic Unicode <https://nedbatchelder.com/text/unipain.html>`_, a PyCon 2012 presentation by Ned Batchelder.
 
 The :class:`str` type is described in the Python library reference at
diff --git a/Doc/library/argparse.rst b/Doc/library/argparse.rst
index 76efed95bd..bcbb38a05e 100644
--- a/Doc/library/argparse.rst
+++ b/Doc/library/argparse.rst
@@ -63,7 +63,7 @@ Name                   Description
 action_                Specify how an argument should be handled                   ``'store'``, ``'store_const'``, ``'store_true'``, ``'append'``, ``'append_const'``, ``'count'``, ``'help'``, ``'version'``
 choices_               Limit values to a specific set of choices                   ``['foo', 'bar']``, ``range(1, 10)``, or :class:`~collections.abc.Container` instance
 const_                 Store a constant value
-default_               Default value used when an argument is not provided         Defaults to *None*
+default_               Default value used when an argument is not provided         Defaults to ``None``
 dest_                  Specify the attribute name used in the result namespace
 help_                  Help message for an argument
 metavar_               Alternate display name for the argument as shown in help
@@ -201,9 +201,10 @@ ArgumentParser objects
    * usage_ - The string describing the program usage (default: generated from
      arguments added to parser)
 
-   * description_ - Text to display before the argument help (default: none)
+   * description_ - Text to display before the argument help
+     (by default, no text)
 
-   * epilog_ - Text to display after the argument help (default: none)
+   * epilog_ - Text to display after the argument help (by default, no text)
 
    * parents_ - A list of :class:`ArgumentParser` objects whose arguments should
      also be included
@@ -1914,8 +1915,8 @@ FileType objects
       Namespace(out=<_io.TextIOWrapper name='file.txt' mode='w' encoding='UTF-8'>, raw=<_io.FileIO name='raw.dat' mode='wb'>)
 
    FileType objects understand the pseudo-argument ``'-'`` and automatically
-   convert this into ``sys.stdin`` for readable :class:`FileType` objects and
-   ``sys.stdout`` for writable :class:`FileType` objects::
+   convert this into :data:`sys.stdin` for readable :class:`FileType` objects and
+   :data:`sys.stdout` for writable :class:`FileType` objects::
 
       >>> parser = argparse.ArgumentParser()
       >>> parser.add_argument('infile', type=argparse.FileType('r'))
diff --git a/Doc/library/ast.rst b/Doc/library/ast.rst
index da0fe8c3d6..3ed2c4fa73 100644
--- a/Doc/library/ast.rst
+++ b/Doc/library/ast.rst
@@ -1990,20 +1990,28 @@ and classes for traversing abstract syntax trees:
 
 .. function:: literal_eval(node_or_string)
 
-   Safely evaluate an expression node or a string containing a Python literal or
+   Evaluate an expression node or a string containing only a Python literal or
    container display.  The string or node provided may only consist of the
    following Python literal structures: strings, bytes, numbers, tuples, lists,
    dicts, sets, booleans, ``None`` and ``Ellipsis``.
 
-   This can be used for safely evaluating strings containing Python values from
-   untrusted sources without the need to parse the values oneself.  It is not
-   capable of evaluating arbitrarily complex expressions, for example involving
-   operators or indexing.
+   This can be used for evaluating strings containing Python values without the
+   need to parse the values oneself.  It is not capable of evaluating
+   arbitrarily complex expressions, for example involving operators or
+   indexing.
+
+   This function had been documented as "safe" in the past without defining
+   what that meant. That was misleading. This is specifically designed not to
+   execute Python code, unlike the more general :func:`eval`. There is no
+   namespace, no name lookups, or ability to call out. But it is not free from
+   attack: A relatively small input can lead to memory exhaustion or to C stack
+   exhaustion, crashing the process. There is also the possibility for
+   excessive CPU consumption denial of service on some inputs. Calling it on
+   untrusted data is thus not recommended.
 
    .. warning::
-      It is possible to crash the Python interpreter with a
-      sufficiently large/complex string due to stack depth limitations
-      in Python's AST compiler.
+      It is possible to crash the Python interpreter due to stack depth
+      limitations in Python's AST compiler.
 
       It can raise :exc:`ValueError`, :exc:`TypeError`, :exc:`SyntaxError`,
       :exc:`MemoryError` and :exc:`RecursionError` depending on the malformed
diff --git a/Doc/library/asyncio-api-index.rst b/Doc/library/asyncio-api-index.rst
index 54c1cd6582..ad475150fe 100644
--- a/Doc/library/asyncio-api-index.rst
+++ b/Doc/library/asyncio-api-index.rst
@@ -57,7 +57,7 @@ await on multiple things with timeouts.
       - Monitor for completion.
 
     * - :func:`timeout`
-      - Run with a timeout. Useful in cases when `wait_for` is not suitable.
+      - Run with a timeout. Useful in cases when ``wait_for`` is not suitable.
 
     * - :func:`to_thread`
       - Asynchronously run a function in a separate OS thread.
diff --git a/Doc/library/asyncio-dev.rst b/Doc/library/asyncio-dev.rst
index 14f2c3533c..921a394a59 100644
--- a/Doc/library/asyncio-dev.rst
+++ b/Doc/library/asyncio-dev.rst
@@ -149,7 +149,8 @@ adjusted::
 
 
 Network logging can block the event loop. It is recommended to use
-a separate thread for handling logs or use non-blocking IO.
+a separate thread for handling logs or use non-blocking IO. For example,
+see :ref:`blocking-handlers`.
 
 
 .. _asyncio-coroutine-not-scheduled:
diff --git a/Doc/library/asyncio-eventloop.rst b/Doc/library/asyncio-eventloop.rst
index 93bca96fff..cf9b3b7ce0 100644
--- a/Doc/library/asyncio-eventloop.rst
+++ b/Doc/library/asyncio-eventloop.rst
@@ -856,9 +856,14 @@ TLS Upgrade
 
    Upgrade an existing transport-based connection to TLS.
 
-   Return a new transport instance, that the *protocol* must start using
-   immediately after the *await*.  The *transport* instance passed to
-   the *start_tls* method should never be used again.
+   Create a TLS coder/decoder instance and insert it between the *transport*
+   and the *protocol*. The coder/decoder implements both *transport*-facing
+   protocol and *protocol*-facing transport.
+
+   Return the created two-interface instance. After *await*, the *protocol*
+   must stop using the original *transport* and communicate with the returned
+   object only because the coder caches *protocol*-side data and sporadically
+   exchanges extra TLS session packets with *transport*.
 
    Parameters:
 
diff --git a/Doc/library/asyncio-policy.rst b/Doc/library/asyncio-policy.rst
index a73e99510f..bfc3e3090f 100644
--- a/Doc/library/asyncio-policy.rst
+++ b/Doc/library/asyncio-policy.rst
@@ -7,7 +7,7 @@
 Policies
 ========
 
-An event loop policy is a global (per-interpreter) object
+An event loop policy is a global object
 used to get and set the current :ref:`event loop <asyncio-event-loop>`,
 as well as create new event loops.
 The default policy can be :ref:`replaced <asyncio-policy-get-set>` with
diff --git a/Doc/library/asyncio-protocol.rst b/Doc/library/asyncio-protocol.rst
index 969354ceb1..7bc906eaaf 100644
--- a/Doc/library/asyncio-protocol.rst
+++ b/Doc/library/asyncio-protocol.rst
@@ -156,7 +156,8 @@ Base Transport
    will be received.  After all buffered data is flushed, the
    protocol's :meth:`protocol.connection_lost()
    <BaseProtocol.connection_lost>` method will be called with
-   :const:`None` as its argument.
+   :const:`None` as its argument. The transport should not be
+   used once it is closed.
 
 .. method:: BaseTransport.is_closing()
 
diff --git a/Doc/library/asyncio-stream.rst b/Doc/library/asyncio-stream.rst
index ce88d70d66..d87e3c042c 100644
--- a/Doc/library/asyncio-stream.rst
+++ b/Doc/library/asyncio-stream.rst
@@ -183,7 +183,8 @@ StreamReader
 .. class:: StreamReader
 
    Represents a reader object that provides APIs to read data
-   from the IO stream.
+   from the IO stream. As an :term:`asynchronous iterable`, the
+   object supports the :keyword:`async for` statement.
 
    It is not recommended to instantiate *StreamReader* objects
    directly; use :func:`open_connection` and :func:`start_server`
diff --git a/Doc/library/bisect.rst b/Doc/library/bisect.rst
index c2927c1ebd..9b40f80f58 100644
--- a/Doc/library/bisect.rst
+++ b/Doc/library/bisect.rst
@@ -127,7 +127,7 @@ thoughts in mind:
 .. seealso::
 
    * `Sorted Collections
-     <http://www.grantjenks.com/docs/sortedcollections/>`_ is a high performance
+     <https://grantjenks.com/docs/sortedcollections/>`_ is a high performance
      module that uses *bisect* to managed sorted collections of data.
 
    * The `SortedCollection recipe
diff --git a/Doc/library/codecs.rst b/Doc/library/codecs.rst
index 4a665f2254..8225236350 100644
--- a/Doc/library/codecs.rst
+++ b/Doc/library/codecs.rst
@@ -189,7 +189,8 @@ wider range of codecs when working with binary files:
 
    .. note::
 
-      Underlying encoded files are always opened in binary mode.
+      If *encoding* is not ``None``, then the
+      underlying encoded files are always opened in binary mode.
       No automatic conversion of ``'\n'`` is done on reading and writing.
       The *mode* argument may be any binary mode acceptable to the built-in
       :func:`open` function; the ``'b'`` is automatically added.
diff --git a/Doc/library/configparser.rst b/Doc/library/configparser.rst
index 72aa20d73d..bfd6a7f58b 100644
--- a/Doc/library/configparser.rst
+++ b/Doc/library/configparser.rst
@@ -33,13 +33,17 @@ can be customized by end users easily.
 
 .. seealso::
 
+   Module :mod:`tomllib`
+      TOML is a well-specified format for application configuration files.
+      It is specifically designed to be an improved version of INI.
+
    Module :mod:`shlex`
-      Support for creating Unix shell-like mini-languages which can be used as
-      an alternate format for application configuration files.
+      Support for creating Unix shell-like mini-languages which can also
+      be used for application configuration files.
 
    Module :mod:`json`
-      The json module implements a subset of JavaScript syntax which can also
-      be used for this purpose.
+      The ``json`` module implements a subset of JavaScript syntax which is
+      sometimes used for configuration, but does not support comments.
 
 
 .. testsetup::
diff --git a/Doc/library/contextvars.rst b/Doc/library/contextvars.rst
index be1dd0c9eb..08a7c7d74e 100644
--- a/Doc/library/contextvars.rst
+++ b/Doc/library/contextvars.rst
@@ -110,7 +110,7 @@ Context Variables
 
       A read-only property.  Set to the value the variable had before
       the :meth:`ContextVar.set` method call that created the token.
-      It points to :attr:`Token.MISSING` is the variable was not set
+      It points to :attr:`Token.MISSING` if the variable was not set
       before the call.
 
    .. attribute:: Token.MISSING
diff --git a/Doc/library/csv.rst b/Doc/library/csv.rst
index 9dec7240d9..f7e85f2baa 100644
--- a/Doc/library/csv.rst
+++ b/Doc/library/csv.rst
@@ -416,7 +416,7 @@ Dialects support the following attributes:
 
 .. attribute:: Dialect.skipinitialspace
 
-   When :const:`True`, whitespace immediately following the *delimiter* is ignored.
+   When :const:`True`, spaces immediately following the *delimiter* are ignored.
    The default is :const:`False`.
 
 
diff --git a/Doc/library/dataclasses.rst b/Doc/library/dataclasses.rst
index 4364ac3424..847299649d 100644
--- a/Doc/library/dataclasses.rst
+++ b/Doc/library/dataclasses.rst
@@ -81,7 +81,7 @@ Module contents
 
      @dataclass(init=True, repr=True, eq=True, order=False, unsafe_hash=False, frozen=False, match_args=True, kw_only=False, slots=False, weakref_slot=False)
      class C:
-        ...
+         ...
 
    The parameters to :func:`dataclass` are:
 
@@ -191,7 +191,7 @@ Module contents
     .. versionchanged:: 3.11
        If a field name is already included in the ``__slots__``
        of a base class, it will not be included in the generated ``__slots__``
-       to prevent `overriding them <https://docs.python.org/3/reference/datamodel.html#notes-on-using-slots>`_.
+       to prevent :ref:`overriding them <datamodel-note-slots>`.
        Therefore, do not use ``__slots__`` to retrieve the field names of a
        dataclass. Use :func:`fields` instead.
        To be able to determine inherited slots,
@@ -482,10 +482,10 @@ Module contents
 
     @dataclass
     class Point:
-      x: float
-      _: KW_ONLY
-      y: float
-      z: float
+        x: float
+        _: KW_ONLY
+        y: float
+        z: float
 
     p = Point(0, y=1.5, z=2.0)
 
@@ -578,8 +578,8 @@ value is not provided when creating the class::
   @dataclass
   class C:
       i: int
-      j: int = None
-      database: InitVar[DatabaseType] = None
+      j: int | None = None
+      database: InitVar[DatabaseType | None] = None
 
       def __post_init__(self, database):
           if self.j is None and database is not None:
@@ -773,24 +773,24 @@ default value have the following special behaviors:
 ::
 
   class IntConversionDescriptor:
-    def __init__(self, *, default):
-      self._default = default
+      def __init__(self, *, default):
+          self._default = default
 
-    def __set_name__(self, owner, name):
-      self._name = "_" + name
+      def __set_name__(self, owner, name):
+          self._name = "_" + name
 
-    def __get__(self, obj, type):
-      if obj is None:
-        return self._default
+      def __get__(self, obj, type):
+          if obj is None:
+              return self._default
 
-      return getattr(obj, self._name, self._default)
+          return getattr(obj, self._name, self._default)
 
-    def __set__(self, obj, value):
-      setattr(obj, self._name, int(value))
+      def __set__(self, obj, value):
+          setattr(obj, self._name, int(value))
 
   @dataclass
   class InventoryItem:
-    quantity_on_hand: IntConversionDescriptor = IntConversionDescriptor(default=100)
+      quantity_on_hand: IntConversionDescriptor = IntConversionDescriptor(default=100)
 
   i = InventoryItem()
   print(i.quantity_on_hand)   # 100
diff --git a/Doc/library/decimal.rst b/Doc/library/decimal.rst
index 6bce940f75..260108136d 100644
--- a/Doc/library/decimal.rst
+++ b/Doc/library/decimal.rst
@@ -114,7 +114,7 @@ reset them before monitoring a calculation.
 .. seealso::
 
    * IBM's General Decimal Arithmetic Specification, `The General Decimal Arithmetic
-     Specification <http://speleotrove.com/decimal/decarith.html>`_.
+     Specification <https://speleotrove.com/decimal/decarith.html>`_.
 
 .. %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 
diff --git a/Doc/library/dis.rst b/Doc/library/dis.rst
index 98866b72a3..1e323bd500 100644
--- a/Doc/library/dis.rst
+++ b/Doc/library/dis.rst
@@ -38,7 +38,9 @@ interpreter.
       Some instructions are accompanied by one or more inline cache entries,
       which take the form of :opcode:`CACHE` instructions. These instructions
       are hidden by default, but can be shown by passing ``show_caches=True`` to
-      any :mod:`dis` utility.
+      any :mod:`dis` utility. Furthermore, the interpreter now adapts the
+      bytecode to specialize it for different runtime conditions. The
+      adaptive bytecode can be shown by passing ``adaptive=True``.
 
 
 Example: Given the function :func:`myfunc`::
@@ -71,8 +73,8 @@ The bytecode analysis API allows pieces of Python code to be wrapped in a
 :class:`Bytecode` object that provides easy access to details of the compiled
 code.
 
-.. class:: Bytecode(x, *, first_line=None, current_offset=None, show_caches=False)
-
+.. class:: Bytecode(x, *, first_line=None, current_offset=None,\
+                    show_caches=False, adaptive=False)
 
    Analyse the bytecode corresponding to a function, generator, asynchronous
    generator, coroutine, method, string of source code, or a code object (as
@@ -91,6 +93,12 @@ code.
    disassembled code. Setting this means :meth:`.dis` will display a "current
    instruction" marker against the specified opcode.
 
+   If *show_caches* is ``True``, :meth:`.dis` will display inline cache
+   entries used by the interpreter to specialize the bytecode.
+
+   If *adaptive* is ``True``, :meth:`.dis` will display specialized bytecode
+   that may be different from the original bytecode.
+
    .. classmethod:: from_traceback(tb, *, show_caches=False)
 
       Construct a :class:`Bytecode` instance from the given traceback, setting
@@ -118,7 +126,7 @@ code.
       This can now handle coroutine and asynchronous generator objects.
 
    .. versionchanged:: 3.11
-      Added the ``show_caches`` parameter.
+      Added the *show_caches* and *adaptive* parameters.
 
 Example:
 
@@ -174,7 +182,7 @@ operation is being performed, so the intermediate analysis object isn't useful:
       Added *file* parameter.
 
 
-.. function:: dis(x=None, *, file=None, depth=None, show_caches=False)
+.. function:: dis(x=None, *, file=None, depth=None, show_caches=False, adaptive=False)
 
    Disassemble the *x* object.  *x* can denote either a module, a class, a
    method, a function, a generator, an asynchronous generator, a coroutine,
@@ -195,6 +203,12 @@ operation is being performed, so the intermediate analysis object isn't useful:
    The maximal depth of recursion is limited by *depth* unless it is ``None``.
    ``depth=0`` means no recursion.
 
+   If *show_caches* is ``True``, this function will display inline cache
+   entries used by the interpreter to specialize the bytecode.
+
+   If *adaptive* is ``True``, this function will display specialized bytecode
+   that may be different from the original bytecode.
+
    .. versionchanged:: 3.4
       Added *file* parameter.
 
@@ -205,10 +219,10 @@ operation is being performed, so the intermediate analysis object isn't useful:
       This can now handle coroutine and asynchronous generator objects.
 
    .. versionchanged:: 3.11
-      Added the ``show_caches`` parameter.
+      Added the *show_caches* and *adaptive* parameters.
 
 
-.. function:: distb(tb=None, *, file=None, show_caches=False)
+.. function:: distb(tb=None, *, file=None, show_caches=False, adaptive=False)
 
    Disassemble the top-of-stack function of a traceback, using the last
    traceback if none was passed.  The instruction causing the exception is
@@ -221,11 +235,11 @@ operation is being performed, so the intermediate analysis object isn't useful:
       Added *file* parameter.
 
    .. versionchanged:: 3.11
-      Added the ``show_caches`` parameter.
+      Added the *show_caches* and *adaptive* parameters.
 
 
-.. function:: disassemble(code, lasti=-1, *, file=None, show_caches=False)
-              disco(code, lasti=-1, *, file=None, show_caches=False)
+.. function:: disassemble(code, lasti=-1, *, file=None, show_caches=False, adaptive=False)
+              disco(code, lasti=-1, *, file=None, show_caches=False, adaptive=False)
 
    Disassemble a code object, indicating the last instruction if *lasti* was
    provided.  The output is divided in the following columns:
@@ -248,10 +262,10 @@ operation is being performed, so the intermediate analysis object isn't useful:
       Added *file* parameter.
 
    .. versionchanged:: 3.11
-      Added the ``show_caches`` parameter.
+      Added the *show_caches* and *adaptive* parameters.
 
 
-.. function:: get_instructions(x, *, first_line=None, show_caches=False)
+.. function:: get_instructions(x, *, first_line=None, show_caches=False, adaptive=False)
 
    Return an iterator over the instructions in the supplied function, method,
    source code string or code object.
@@ -264,10 +278,12 @@ operation is being performed, so the intermediate analysis object isn't useful:
    source line information (if any) is taken directly from the disassembled code
    object.
 
+   The *show_caches* and *adaptive* parameters work as they do in :func:`dis`.
+
    .. versionadded:: 3.4
 
    .. versionchanged:: 3.11
-      Added the ``show_caches`` parameter.
+      Added the *show_caches* and *adaptive* parameters.
 
 
 .. function:: findlinestarts(code)
diff --git a/Doc/library/enum.rst b/Doc/library/enum.rst
index 241d19d3bf..d666fa96e7 100644
--- a/Doc/library/enum.rst
+++ b/Doc/library/enum.rst
@@ -92,6 +92,11 @@ Module Contents
       the bitwise operators without losing their :class:`IntFlag` membership.
       :class:`IntFlag` members are also subclasses of :class:`int`. (`Notes`_)
 
+   :class:`ReprEnum`
+
+      Used by :class:`IntEnum`, :class:`StrEnum`, and :class:`IntFlag`
+      to keep the :class:`str() <str>` of the mixed-in type.
+
    :class:`EnumCheck`
 
       An enumeration with the values ``CONTINUOUS``, ``NAMED_FLAGS``, and
@@ -132,9 +137,20 @@ Module Contents
 
       Do not make ``obj`` a member.  Can be used as a decorator.
 
+   :func:`global_enum`
+
+      Modify the :class:`str() <str>` and :func:`repr` of an enum
+      to show its members as belonging to the module instead of its class.
+      Should only be used if the enum members will be exported to the
+      module global namespace.
+
+   :func:`show_flag_values`
+
+      Return a list of all power-of-two integers contained in a flag.
+
 
 .. versionadded:: 3.6  ``Flag``, ``IntFlag``, ``auto``
-.. versionadded:: 3.11  ``StrEnum``, ``EnumCheck``, ``FlagBoundary``, ``property``, ``member``, ``nonmember``
+.. versionadded:: 3.11  ``StrEnum``, ``EnumCheck``, ``ReprEnum``, ``FlagBoundary``, ``property``, ``member``, ``nonmember``, ``global_enum``, ``show_flag_values``
 
 ---------------
 
@@ -418,7 +434,7 @@ Data Types
 
    .. note:: There are places in the stdlib that check for an exact :class:`str`
              instead of a :class:`str` subclass (i.e. ``type(unknown) == str``
-             instead of ``isinstance(str, unknown)``), and in those locations you
+             instead of ``isinstance(unknown, str)``), and in those locations you
              will need to use ``str(StrEnum.member)``.
 
    .. note::
@@ -580,6 +596,20 @@ Data Types
       better support the *replacement of existing constants* use-case.
       :meth:`__format__` was already :func:`int.__format__` for that same reason.
 
+.. class:: ReprEnum
+
+   :class:`!ReprEum` uses the :meth:`repr() <Enum.__repr__>` of :class:`Enum`,
+   but the :class:`str() <str>` of the mixed-in data type:
+
+      * :meth:`!int.__str__` for :class:`IntEnum` and :class:`IntFlag`
+      * :meth:`!str.__str__` for :class:`StrEnum`
+
+   Inherit from :class:`!ReprEnum` to keep the :class:`str() <str> / :func:`format`
+   of the mixed-in data type instead of using the
+   :class:`Enum`-default :meth:`str() <Enum.__str__>`.
+
+
+   .. versionadded:: 3.11
 
 .. class:: EnumCheck
 
@@ -815,6 +845,22 @@ Utilities and Decorators
 
    .. versionadded:: 3.11
 
+.. decorator:: global_enum
+
+   A decorator to change the :class:`str() <str>` and :func:`repr` of an enum
+   to show its members as belonging to the module instead of its class.
+   Should only be used when the enum members are exported
+   to the module global namespace (see :class:`re.RegexFlag` for an example).
+
+
+   .. versionadded:: 3.11
+
+.. function:: show_flag_values(value)
+
+   Return a list of all power-of-two integers contained in a flag *value*.
+
+   .. versionadded:: 3.11
+
 ---------------
 
 Notes
diff --git a/Doc/library/errno.rst b/Doc/library/errno.rst
index 035340e256..5122c69697 100644
--- a/Doc/library/errno.rst
+++ b/Doc/library/errno.rst
@@ -657,3 +657,12 @@ defined by the module.  The specific list of defined symbols is available as
    Interface output queue is full
 
    .. versionadded:: 3.11
+
+.. data:: ENOTCAPABLE
+
+   Capabilities insufficient. This error is mapped to the exception
+   :exc:`PermissionError`.
+
+   .. availability:: WASI, FreeBSD
+
+   .. versionadded:: 3.11.1
diff --git a/Doc/library/exceptions.rst b/Doc/library/exceptions.rst
index 2eccbd17c4..fc856277d6 100644
--- a/Doc/library/exceptions.rst
+++ b/Doc/library/exceptions.rst
@@ -746,7 +746,12 @@ depending on the system error code.
 
    Raised when trying to run an operation without the adequate access
    rights - for example filesystem permissions.
-   Corresponds to :c:data:`errno` :py:data:`~errno.EACCES` and :py:data:`~errno.EPERM`.
+   Corresponds to :c:data:`errno` :py:data:`~errno.EACCES`,
+   :py:data:`~errno.EPERM`, and :py:data:`~errno.ENOTCAPABLE`.
+
+   .. versionchanged:: 3.11.1
+      WASI's :py:data:`~errno.ENOTCAPABLE` is now mapped to
+      :exc:`PermissionError`.
 
 .. exception:: ProcessLookupError
 
diff --git a/Doc/library/http.cookiejar.rst b/Doc/library/http.cookiejar.rst
index e6c59810dc..87ef156a0b 100644
--- a/Doc/library/http.cookiejar.rst
+++ b/Doc/library/http.cookiejar.rst
@@ -322,8 +322,8 @@ writing.
 .. class:: MozillaCookieJar(filename=None, delayload=None, policy=None)
 
    A :class:`FileCookieJar` that can load from and save cookies to disk in the
-   Mozilla ``cookies.txt`` file format (which is also used by the Lynx and Netscape
-   browsers).
+   Mozilla ``cookies.txt`` file format (which is also used by curl and the Lynx
+   and Netscape browsers).
 
    .. note::
 
diff --git a/Doc/library/itertools.rst b/Doc/library/itertools.rst
index 16b12044a1..3d93c2c057 100644
--- a/Doc/library/itertools.rst
+++ b/Doc/library/itertools.rst
@@ -10,6 +10,10 @@
 .. testsetup::
 
    from itertools import *
+   import collections
+   import math
+   import operator
+   import random
 
 --------------
 
@@ -132,10 +136,9 @@ loops that truncate the stream.
     There are a number of uses for the *func* argument.  It can be set to
     :func:`min` for a running minimum, :func:`max` for a running maximum, or
     :func:`operator.mul` for a running product.  Amortization tables can be
-    built by accumulating interest and applying payments.  First-order
-    `recurrence relations <https://en.wikipedia.org/wiki/Recurrence_relation>`_
-    can be modeled by supplying the initial value in the iterable and using only
-    the accumulated total in *func* argument::
+    built by accumulating interest and applying payments:
+
+    .. doctest::
 
       >>> data = [3, 4, 6, 2, 1, 9, 0, 7, 5, 8]
       >>> list(accumulate(data, operator.mul))     # running product
@@ -148,17 +151,6 @@ loops that truncate the stream.
       >>> list(accumulate(cashflows, lambda bal, pmt: bal*1.05 + pmt))
       [1000, 960.0, 918.0, 873.9000000000001, 827.5950000000001]
 
-      # Chaotic recurrence relation https://en.wikipedia.org/wiki/Logistic_map
-      >>> logistic_map = lambda x, _:  r * x * (1 - x)
-      >>> r = 3.8
-      >>> x0 = 0.4
-      >>> inputs = repeat(x0, 36)     # only the initial value is used
-      >>> [format(x, '.2f') for x in accumulate(inputs, logistic_map)]
-      ['0.40', '0.91', '0.30', '0.81', '0.60', '0.92', '0.29', '0.79', '0.63',
-       '0.88', '0.39', '0.90', '0.33', '0.84', '0.52', '0.95', '0.18', '0.57',
-       '0.93', '0.25', '0.71', '0.79', '0.63', '0.88', '0.39', '0.91', '0.32',
-       '0.83', '0.54', '0.95', '0.20', '0.60', '0.91', '0.30', '0.80', '0.60']
-
     See :func:`functools.reduce` for a similar function that returns only the
     final accumulated value.
 
@@ -202,10 +194,10 @@ loops that truncate the stream.
 
    The combination tuples are emitted in lexicographic ordering according to
    the order of the input *iterable*. So, if the input *iterable* is sorted,
-   the combination tuples will be produced in sorted order.
+   the output tuples will be produced in sorted order.
 
    Elements are treated as unique based on their position, not on their
-   value.  So if the input elements are unique, there will be no repeat
+   value.  So if the input elements are unique, there will be no repeated
    values in each combination.
 
    Roughly equivalent to::
@@ -251,7 +243,7 @@ loops that truncate the stream.
 
    The combination tuples are emitted in lexicographic ordering according to
    the order of the input *iterable*. So, if the input *iterable* is sorted,
-   the combination tuples will be produced in sorted order.
+   the output tuples will be produced in sorted order.
 
    Elements are treated as unique based on their position, not on their
    value.  So if the input elements are unique, the generated combinations
@@ -410,14 +402,17 @@ loops that truncate the stream.
       class groupby:
           # [k for k, g in groupby('AAAABBBCCDAABBB')] --> A B C D A B
           # [list(g) for k, g in groupby('AAAABBBCCD')] --> AAAA BBB CC D
+
           def __init__(self, iterable, key=None):
               if key is None:
                   key = lambda x: x
               self.keyfunc = key
               self.it = iter(iterable)
               self.tgtkey = self.currkey = self.currvalue = object()
+
           def __iter__(self):
               return self
+
           def __next__(self):
               self.id = object()
               while self.currkey == self.tgtkey:
@@ -425,6 +420,7 @@ loops that truncate the stream.
                   self.currkey = self.keyfunc(self.currvalue)
               self.tgtkey = self.currkey
               return (self.currkey, self._grouper(self.tgtkey, self.id))
+
           def _grouper(self, tgtkey, id):
               while self.id is id and self.currkey == tgtkey:
                   yield self.currvalue
@@ -443,10 +439,17 @@ loops that truncate the stream.
    Afterward, elements are returned consecutively unless *step* is set higher than
    one which results in items being skipped.  If *stop* is ``None``, then iteration
    continues until the iterator is exhausted, if at all; otherwise, it stops at the
-   specified position.  Unlike regular slicing, :func:`islice` does not support
-   negative values for *start*, *stop*, or *step*.  Can be used to extract related
-   fields from data where the internal structure has been flattened (for example, a
-   multi-line report may list a name field on every third line).  Roughly equivalent to::
+   specified position.
+
+   If *start* is ``None``, then iteration starts at zero. If *step* is ``None``,
+   then the step defaults to one.
+
+   Unlike regular slicing, :func:`islice` does not support negative values for
+   *start*, *stop*, or *step*.  Can be used to extract related fields from
+   data where the internal structure has been flattened (for example, a
+   multi-line report may list a name field on every third line).
+
+   Roughly equivalent to::
 
       def islice(iterable, *args):
           # islice('ABCDEFG', 2) --> A B
@@ -473,8 +476,6 @@ loops that truncate the stream.
               for i, element in zip(range(i + 1, stop), iterable):
                   pass
 
-   If *start* is ``None``, then iteration starts at zero. If *step* is ``None``,
-   then the step defaults to one.
 
 .. function:: pairwise(iterable)
 
@@ -503,13 +504,13 @@ loops that truncate the stream.
    of the *iterable* and all possible full-length permutations
    are generated.
 
-   The permutation tuples are emitted in lexicographic ordering according to
+   The permutation tuples are emitted in lexicographic order according to
    the order of the input *iterable*. So, if the input *iterable* is sorted,
-   the combination tuples will be produced in sorted order.
+   the output tuples will be produced in sorted order.
 
    Elements are treated as unique based on their position, not on their
-   value.  So if the input elements are unique, there will be no repeat
-   values in each permutation.
+   value.  So if the input elements are unique, there will be no repeated
+   values within a permutation.
 
    Roughly equivalent to::
 
@@ -589,9 +590,7 @@ loops that truncate the stream.
 .. function:: repeat(object[, times])
 
    Make an iterator that returns *object* over and over again. Runs indefinitely
-   unless the *times* argument is specified. Used as argument to :func:`map` for
-   invariant parameters to the called function.  Also used with :func:`zip` to
-   create an invariant part of a tuple record.
+   unless the *times* argument is specified.
 
    Roughly equivalent to::
 
@@ -605,7 +604,9 @@ loops that truncate the stream.
                   yield object
 
    A common use for *repeat* is to supply a stream of constant values to *map*
-   or *zip*::
+   or *zip*:
+
+   .. doctest::
 
       >>> list(map(pow, range(10), repeat(2)))
       [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]
@@ -614,9 +615,12 @@ loops that truncate the stream.
 
    Make an iterator that computes the function using arguments obtained from
    the iterable.  Used instead of :func:`map` when argument parameters are already
-   grouped in tuples from a single iterable (the data has been "pre-zipped").  The
-   difference between :func:`map` and :func:`starmap` parallels the distinction
-   between ``function(a,b)`` and ``function(*c)``. Roughly equivalent to::
+   grouped in tuples from a single iterable (when the data has been
+   "pre-zipped").
+
+   The difference between :func:`map` and :func:`starmap` parallels the
+   distinction between ``function(a,b)`` and ``function(*c)``. Roughly
+   equivalent to::
 
       def starmap(function, iterable):
           # starmap(pow, [(2,5), (3,2), (10,3)]) --> 32 9 1000
@@ -644,9 +648,7 @@ loops that truncate the stream.
 
    The following Python code helps explain what *tee* does (although the actual
    implementation is more complex and uses only a single underlying
-   :abbr:`FIFO (first-in, first-out)` queue).
-
-   Roughly equivalent to::
+   :abbr:`FIFO (first-in, first-out)` queue)::
 
         def tee(iterable, n=2):
             it = iter(iterable)
@@ -663,7 +665,7 @@ loops that truncate the stream.
                     yield mydeque.popleft()
             return tuple(gen(d) for d in deques)
 
-   Once :func:`tee` has made a split, the original *iterable* should not be
+   Once a :func:`tee` has been created, the original *iterable* should not be
    used anywhere else; otherwise, the *iterable* could get advanced without
    the tee objects being informed.
 
@@ -717,14 +719,28 @@ Itertools Recipes
 This section shows recipes for creating an extended toolset using the existing
 itertools as building blocks.
 
+The primary purpose of the itertools recipes is educational.  The recipes show
+various ways of thinking about individual tools  for example, that
+``chain.from_iterable`` is related to the concept of flattening.  The recipes
+also give ideas about ways that the tools can be combined  for example, how
+``compress()`` and ``range()`` can work together.  The recipes also show patterns
+for using itertools with the :mod:`operator` and :mod:`collections` modules as
+well as with the built-in itertools such as ``map()``, ``filter()``,
+``reversed()``, and ``enumerate()``.
+
+A secondary purpose of the recipes is to serve as an incubator.  The
+``accumulate()``, ``compress()``, and ``pairwise()`` itertools started out as
+recipes.  Currently, the ``iter_index()`` recipe is being tested to see
+whether it proves its worth.
+
 Substantially all of these recipes and many, many others can be installed from
 the `more-itertools project <https://pypi.org/project/more-itertools/>`_ found
 on the Python Package Index::
 
     python -m pip install more-itertools
 
-The extended tools offer the same high performance as the underlying toolset.
-The superior memory performance is kept by processing elements one at a time
+Many of the recipes offer the same high performance as the underlying toolset.
+Superior memory performance is kept by processing elements one at a time
 rather than bringing the whole iterable into memory all at once. Code volume is
 kept small by linking the tools together in a functional style which helps
 eliminate temporary variables.  High speed is retained by preferring
@@ -809,15 +825,36 @@ which incur interpreter overhead.
            for k in range(len(roots) + 1)
        ]
 
+   def iter_index(iterable, value, start=0):
+       "Return indices where a value occurs in a sequence or iterable."
+       # iter_index('AABCADEAF', 'A') --> 0 1 4 7
+       try:
+           seq_index = iterable.index
+       except AttributeError:
+           # Slow path for general iterables
+           it = islice(iterable, start, None)
+           for i, element in enumerate(it, start):
+               if element is value or element == value:
+                   yield i
+       else:
+           # Fast path for sequences
+           i = start - 1
+           try:
+               while True:
+                   yield (i := seq_index(value, i+1))
+           except ValueError:
+               pass
+
    def sieve(n):
-      "Primes less than n"
-      # sieve(30) --> 2 3 5 7 11 13 17 19 23 29
-      data = bytearray([1]) * n
-      data[:2] = 0, 0
-      limit = math.isqrt(n) + 1
-      for p in compress(count(), islice(data, limit)):
-         data[p+p : n : p] = bytearray(len(range(p+p, n, p)))
-      return compress(count(), data)
+       "Primes less than n"
+       # sieve(30) --> 2 3 5 7 11 13 17 19 23 29
+       data = bytearray((0, 1)) * (n // 2)
+       data[:3] = 0, 0, 0
+       limit = math.isqrt(n) + 1
+       for p in compress(range(limit), data):
+           data[p*p : n : p+p] = bytes(len(range(p*p, n, p+p)))
+       data[2] = 1
+       return iter_index(data, 1) if n > 2 else iter([])
 
    def flatten(list_of_lists):
        "Flatten one level of nesting"
@@ -850,6 +887,8 @@ which incur interpreter overhead.
    def batched(iterable, n):
        "Batch data into lists of length n. The last batch may be shorter."
        # batched('ABCDEFG', 3) --> ABC DEF G
+       if n < 1:
+           raise ValueError('n must be at least one')
        it = iter(iterable)
        while (batch := list(islice(it, n))):
            yield batch
@@ -935,16 +974,19 @@ which incur interpreter overhead.
        # unique_everseen('AAAABBBCCDAABBB') --> A B C D
        # unique_everseen('ABBCcAD', str.lower) --> A B C D
        seen = set()
-       seen_add = seen.add
        if key is None:
            for element in filterfalse(seen.__contains__, iterable):
-               seen_add(element)
+               seen.add(element)
                yield element
+           # Note: The steps shown above are intended to demonstrate
+           # filterfalse(). For order preserving deduplication,
+           # a better solution is:
+           #     yield from dict.fromkeys(iterable)
        else:
            for element in iterable:
                k = key(element)
                if k not in seen:
-                   seen_add(k)
+                   seen.add(k)
                    yield element
 
    def unique_justseen(iterable, key=None):
@@ -989,31 +1031,6 @@ which incur interpreter overhead.
        # first_true([a,b], x, f) --> a if f(a) else b if f(b) else x
        return next(filter(pred, iterable), default)
 
-   def random_product(*args, repeat=1):
-       "Random selection from itertools.product(*args, **kwds)"
-       pools = [tuple(pool) for pool in args] * repeat
-       return tuple(map(random.choice, pools))
-
-   def random_permutation(iterable, r=None):
-       "Random selection from itertools.permutations(iterable, r)"
-       pool = tuple(iterable)
-       r = len(pool) if r is None else r
-       return tuple(random.sample(pool, r))
-
-   def random_combination(iterable, r):
-       "Random selection from itertools.combinations(iterable, r)"
-       pool = tuple(iterable)
-       n = len(pool)
-       indices = sorted(random.sample(range(n), r))
-       return tuple(pool[i] for i in indices)
-
-   def random_combination_with_replacement(iterable, r):
-       "Random selection from itertools.combinations_with_replacement(iterable, r)"
-       pool = tuple(iterable)
-       n = len(pool)
-       indices = sorted(random.choices(range(n), k=r))
-       return tuple(pool[i] for i in indices)
-
    def nth_combination(iterable, r, index):
        "Equivalent to list(combinations(iterable, r))[index]"
        pool = tuple(iterable)
@@ -1170,8 +1187,32 @@ which incur interpreter overhead.
     >>> all(factored(x) == expanded(x) for x in range(-10, 11))
     True
 
+    >>> list(iter_index('AABCADEAF', 'A'))
+    [0, 1, 4, 7]
+    >>> list(iter_index('AABCADEAF', 'B'))
+    [2]
+    >>> list(iter_index('AABCADEAF', 'X'))
+    []
+    >>> list(iter_index('', 'X'))
+    []
+    >>> list(iter_index('AABCADEAF', 'A', 1))
+    [1, 4, 7]
+    >>> list(iter_index(iter('AABCADEAF'), 'A', 1))
+    [1, 4, 7]
+    >>> list(iter_index('AABCADEAF', 'A', 2))
+    [4, 7]
+    >>> list(iter_index(iter('AABCADEAF'), 'A', 2))
+    [4, 7]
+    >>> list(iter_index('AABCADEAF', 'A', 10))
+    []
+    >>> list(iter_index(iter('AABCADEAF'), 'A', 10))
+    []
+
     >>> list(sieve(30))
     [2, 3, 5, 7, 11, 13, 17, 19, 23, 29]
+    >>> small_primes = [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97]
+    >>> all(list(sieve(n)) == [p for p in small_primes if p < n] for n in range(101))
+    True
     >>> len(list(sieve(100)))
     25
     >>> len(list(sieve(1_000)))
@@ -1182,6 +1223,9 @@ which incur interpreter overhead.
     9592
     >>> len(list(sieve(1_000_000)))
     78498
+    >>> carmichael = {561, 1105, 1729, 2465, 2821, 6601, 8911}  # https://oeis.org/A002997
+    >>> set(sieve(10_000)).isdisjoint(carmichael)
+    True
 
     >>> list(flatten([('a', 'b'), (), ('c', 'd', 'e'), ('f',), ('g', 'h', 'i')]))
     ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i']
@@ -1230,12 +1274,6 @@ which incur interpreter overhead.
     [['A', 'B'], ['C', 'D'], ['E', 'F'], ['G']]
     >>> list(batched('ABCDEFG', 1))
     [['A'], ['B'], ['C'], ['D'], ['E'], ['F'], ['G']]
-    >>> list(batched('ABCDEFG', 0))
-    []
-    >>> list(batched('ABCDEFG', -1))
-    Traceback (most recent call last):
-      ...
-    ValueError: Stop argument for islice() must be None or an integer: 0 <= x <= sys.maxsize.
     >>> s = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'
     >>> all(list(flatten(batched(s[:n], 5))) == list(s[:n]) for n in range(len(s)))
     True
diff --git a/Doc/library/logging.handlers.rst b/Doc/library/logging.handlers.rst
index 8ab76ab93b..b645529827 100644
--- a/Doc/library/logging.handlers.rst
+++ b/Doc/library/logging.handlers.rst
@@ -650,6 +650,17 @@ supports sending logging messages to a remote or local Unix syslog.
 
       Closes the socket to the remote host.
 
+   .. method:: createSocket()
+
+      Tries to create a socket and, if it's not a datagram socket, connect it
+      to the other end. This method is called during handler initialization,
+      but it's not regarded as an error if the other end isn't listening at
+      this point - the method will be called again when emitting an event, if
+      but it's not regarded as an error if the other end isn't listening yet
+      --- the method will be called again when emitting an event,
+      if there is no socket at that point.
+
+      .. versionadded:: 3.11
 
    .. method:: emit(record)
 
diff --git a/Doc/library/mailbox.rst b/Doc/library/mailbox.rst
index ff3da416a3..56908dedea 100644
--- a/Doc/library/mailbox.rst
+++ b/Doc/library/mailbox.rst
@@ -614,7 +614,7 @@ Supported mailbox formats are Maildir, mbox, MH, Babyl, and MMDF.
 
 .. seealso::
 
-   `nmh - Message Handling System <http://www.nongnu.org/nmh/>`_
+   `nmh - Message Handling System <https://www.nongnu.org/nmh/>`_
       Home page of :program:`nmh`, an updated version of the original :program:`mh`.
 
    `MH & nmh: Email for Users & Programmers <https://rand-mh.sourceforge.io/book/>`_
diff --git a/Doc/library/multiprocessing.shared_memory.rst b/Doc/library/multiprocessing.shared_memory.rst
index 127a82d47a..76046b3461 100644
--- a/Doc/library/multiprocessing.shared_memory.rst
+++ b/Doc/library/multiprocessing.shared_memory.rst
@@ -125,7 +125,7 @@ instances::
 
 
 The following example demonstrates a practical use of the :class:`SharedMemory`
-class with `NumPy arrays <https://www.numpy.org/>`_, accessing the
+class with `NumPy arrays <https://numpy.org/>`_, accessing the
 same ``numpy.ndarray`` from two distinct Python shells:
 
 .. doctest::
diff --git a/Doc/library/os.rst b/Doc/library/os.rst
index 633cd0869d..74125aef05 100644
--- a/Doc/library/os.rst
+++ b/Doc/library/os.rst
@@ -3208,7 +3208,8 @@ features:
    filenames)``.
 
    *dirpath* is a string, the path to the directory.  *dirnames* is a list of the
-   names of the subdirectories in *dirpath* (excluding ``'.'`` and ``'..'``).
+   names of the subdirectories in *dirpath* (including symlinks to directories,
+   and excluding ``'.'`` and ``'..'``).
    *filenames* is a list of the names of the non-directory files in *dirpath*.
    Note that the names in the lists contain no path components.  To get a full path
    (which begins with *top*) to a file or directory in *dirpath*, do
diff --git a/Doc/library/pathlib.rst b/Doc/library/pathlib.rst
index 5012150b86..843513c5fc 100644
--- a/Doc/library/pathlib.rst
+++ b/Doc/library/pathlib.rst
@@ -391,7 +391,7 @@ Pure paths provide the following methods and properties:
 
       If you want to walk an arbitrary filesystem path upwards, it is
       recommended to first call :meth:`Path.resolve` so as to resolve
-      symlinks and eliminate `".."` components.
+      symlinks and eliminate ``".."`` components.
 
 
 .. data:: PurePath.name
diff --git a/Doc/library/pickle.rst b/Doc/library/pickle.rst
index 41b0f48f46..79476b04cd 100644
--- a/Doc/library/pickle.rst
+++ b/Doc/library/pickle.rst
@@ -90,7 +90,7 @@ Comparison with ``json``
 ^^^^^^^^^^^^^^^^^^^^^^^^
 
 There are fundamental differences between the pickle protocols and
-`JSON (JavaScript Object Notation) <http://json.org>`_:
+`JSON (JavaScript Object Notation) <https://json.org>`_:
 
 * JSON is a text serialization format (it outputs unicode text, although
   most of the time it is then encoded to ``utf-8``), while pickle is
diff --git a/Doc/library/random.rst b/Doc/library/random.rst
index 661f7c9548..2b87a36f7c 100644
--- a/Doc/library/random.rst
+++ b/Doc/library/random.rst
@@ -548,7 +548,7 @@ Simulation of arrival times and service deliveries for a multiserver queue::
    including simulation, sampling, shuffling, and cross-validation.
 
    `Economics Simulation
-   <http://nbviewer.jupyter.org/url/norvig.com/ipython/Economics.ipynb>`_
+   <https://nbviewer.jupyter.org/url/norvig.com/ipython/Economics.ipynb>`_
    a simulation of a marketplace by
    `Peter Norvig <https://norvig.com/bio.html>`_ that shows effective
    use of many of the tools and distributions provided by this module
@@ -564,6 +564,37 @@ Simulation of arrival times and service deliveries for a multiserver queue::
 Recipes
 -------
 
+These recipes show how to efficiently make random selections
+from the combinatoric iterators in the :mod:`itertools` module:
+
+.. testcode::
+   import random
+
+   def random_product(*args, repeat=1):
+       "Random selection from itertools.product(*args, **kwds)"
+       pools = [tuple(pool) for pool in args] * repeat
+       return tuple(map(random.choice, pools))
+
+   def random_permutation(iterable, r=None):
+       "Random selection from itertools.permutations(iterable, r)"
+       pool = tuple(iterable)
+       r = len(pool) if r is None else r
+       return tuple(random.sample(pool, r))
+
+   def random_combination(iterable, r):
+       "Random selection from itertools.combinations(iterable, r)"
+       pool = tuple(iterable)
+       n = len(pool)
+       indices = sorted(random.sample(range(n), r))
+       return tuple(pool[i] for i in indices)
+
+   def random_combination_with_replacement(iterable, r):
+       "Random selection from itertools.combinations_with_replacement(iterable, r)"
+       pool = tuple(iterable)
+       n = len(pool)
+       indices = sorted(random.choices(range(n), k=r))
+       return tuple(pool[i] for i in indices)
+
 The default :func:`.random` returns multiples of 2 in the range
 *0.0  x < 1.0*.  All such numbers are evenly spaced and are exactly
 representable as Python floats.  However, many other representable
diff --git a/Doc/library/re.rst b/Doc/library/re.rst
index 3a6e2e7f89..a9e6ac30d1 100644
--- a/Doc/library/re.rst
+++ b/Doc/library/re.rst
@@ -481,6 +481,9 @@ The special characters are:
    some fixed length.  Patterns which start with negative lookbehind assertions may
    match at the beginning of the string being searched.
 
+.. _re-conditional-expression:
+.. index:: single: (?(; in regular expressions
+
 ``(?(id/name)yes-pattern|no-pattern)``
    Will try to match with ``yes-pattern`` if the group with given *id* or
    *name* exists, and with ``no-pattern`` if it doesn't. ``no-pattern`` is
diff --git a/Doc/library/sndhdr.rst b/Doc/library/sndhdr.rst
index e1dbe4a1a3..fa9323e18d 100644
--- a/Doc/library/sndhdr.rst
+++ b/Doc/library/sndhdr.rst
@@ -54,3 +54,51 @@ be the sample size in bits or ``'A'`` for A-LAW or ``'U'`` for u-LAW.
    .. versionchanged:: 3.5
       Result changed from a tuple to a namedtuple.
 
+The following sound header types are recognized, as listed below with the return value
+from :func:`whathdr`: and :func:`what`:
+
++------------+------------------------------------+
+| Value      | Sound header format                |
++============+====================================+
+| ``'aifc'`` | Compressed Audio Interchange Files |
++------------+------------------------------------+
+| ``'aiff'`` | Audio Interchange Files            |
++------------+------------------------------------+
+| ``'au'``   | Au Files                           |
++------------+------------------------------------+
+| ``'hcom'`` | HCOM Files                         |
++------------+------------------------------------+
+| ``'sndt'`` | Sndtool Sound Files                |
++------------+------------------------------------+
+| ``'voc'``  | Creative Labs Audio Files          |
++------------+------------------------------------+
+| ``'wav'``  | Waveform Audio File Format Files   |
++------------+------------------------------------+
+| ``'8svx'`` | 8-Bit Sampled Voice Files          |
++------------+------------------------------------+
+| ``'sb'``   | Signed Byte Audio Data Files       |
++------------+------------------------------------+
+| ``'ub'``   | UB Files                           |
++------------+------------------------------------+
+| ``'ul'``   | uLAW Audio Files                   |
++------------+------------------------------------+
+
+.. data:: tests
+
+   A list of functions performing the individual tests.  Each function takes two
+   arguments: the byte-stream and an open file-like object. When :func:`what` is
+   called with a byte-stream, the file-like object will be ``None``.
+
+   The test function should return a string describing the image type if the test
+   succeeded, or ``None`` if it failed.
+
+Example:
+
+.. code-block:: pycon
+
+   >>> import sndhdr
+   >>> imghdr.what('bass.wav')
+   'wav'
+   >>> imghdr.whathdr('bass.wav')
+   'wav'
+
diff --git a/Doc/library/sqlite3.rst b/Doc/library/sqlite3.rst
index 8fdb753495..116a2ce78f 100644
--- a/Doc/library/sqlite3.rst
+++ b/Doc/library/sqlite3.rst
@@ -564,7 +564,7 @@ Connection objects
       supplied, this must be a callable returning an instance of :class:`Cursor`
       or its subclasses.
 
-   .. method:: blobopen(table, column, row, /, \*, readonly=False, name="main")
+   .. method:: blobopen(table, column, row, /, *, readonly=False, name="main")
 
       Open a :class:`Blob` handle to an existing
       :abbr:`BLOB (Binary Large OBject)`.
@@ -634,7 +634,7 @@ Connection objects
       :meth:`~Cursor.executescript` on it with the given *sql_script*.
       Return the new cursor object.
 
-   .. method:: create_function(name, narg, func, \*, deterministic=False)
+   .. method:: create_function(name, narg, func, *, deterministic=False)
 
       Create or remove a user-defined SQL function.
 
@@ -1027,7 +1027,7 @@ Connection objects
          con.close()
 
 
-   .. method:: backup(target, \*, pages=-1, progress=None, name="main", sleep=0.250)
+   .. method:: backup(target, *, pages=-1, progress=None, name="main", sleep=0.250)
 
       Create a backup of an SQLite database.
 
@@ -1156,7 +1156,7 @@ Connection objects
    .. _SQLite limit category: https://www.sqlite.org/c3ref/c_limit_attached.html
 
 
-   .. method:: serialize(\*, name="main")
+   .. method:: serialize(*, name="main")
 
       Serialize a database into a :class:`bytes` object.  For an
       ordinary on-disk database file, the serialization is just a copy of the
@@ -1178,7 +1178,7 @@ Connection objects
       .. versionadded:: 3.11
 
 
-   .. method:: deserialize(data, /, \*, name="main")
+   .. method:: deserialize(data, /, *, name="main")
 
       Deserialize a :meth:`serialized <serialize>` database into a
       :class:`Connection`.
diff --git a/Doc/library/stdtypes.rst b/Doc/library/stdtypes.rst
index 14d2a27a87..68b333acd8 100644
--- a/Doc/library/stdtypes.rst
+++ b/Doc/library/stdtypes.rst
@@ -4370,11 +4370,9 @@ type, the :dfn:`dictionary`.  (For other containers see the built-in
 A dictionary's keys are *almost* arbitrary values.  Values that are not
 :term:`hashable`, that is, values containing lists, dictionaries or other
 mutable types (that are compared by value rather than by object identity) may
-not be used as keys.  Numeric types used for keys obey the normal rules for
-numeric comparison: if two numbers compare equal (such as ``1`` and ``1.0``)
-then they can be used interchangeably to index the same dictionary entry.  (Note
-however, that since computers store floating-point numbers as approximations it
-is usually unwise to use them as dictionary keys.)
+not be used as keys.
+Values that compare equal (such as ``1``, ``1.0``, and ``True``)
+can be used interchangeably to index the same dictionary entry.
 
 .. class:: dict(**kwargs)
            dict(mapping, **kwargs)
diff --git a/Doc/library/struct.rst b/Doc/library/struct.rst
index d12a5732fa..620f50376b 100644
--- a/Doc/library/struct.rst
+++ b/Doc/library/struct.rst
@@ -194,7 +194,7 @@ platform-dependent.
 +--------+--------------------------+--------------------+----------------+------------+
 | Format | C Type                   | Python type        | Standard size  | Notes      |
 +========+==========================+====================+================+============+
-| ``x``  | pad byte                 | no value           |                |            |
+| ``x``  | pad byte                 | no value           |                | \(7)       |
 +--------+--------------------------+--------------------+----------------+------------+
 | ``c``  | :c:expr:`char`           | bytes of length 1  | 1              |            |
 +--------+--------------------------+--------------------+----------------+------------+
@@ -291,6 +291,9 @@ Notes:
    operations. See the Wikipedia page on the `half-precision floating-point
    format <half precision format_>`_ for more information.
 
+(7)
+   For padding, ``x`` inserts null bytes.
+
 
 A format character may be preceded by an integral repeat count.  For example,
 the format string ``'4h'`` means exactly the same as ``'hhhh'``.
diff --git a/Doc/library/subprocess.rst b/Doc/library/subprocess.rst
index dee5bd879d..51b9e38b7b 100644
--- a/Doc/library/subprocess.rst
+++ b/Doc/library/subprocess.rst
@@ -829,7 +829,7 @@ Instances of the :class:`Popen` class have the following methods:
 
       On Windows, SIGTERM is an alias for :meth:`terminate`. CTRL_C_EVENT and
       CTRL_BREAK_EVENT can be sent to processes started with a *creationflags*
-      parameter which includes `CREATE_NEW_PROCESS_GROUP`.
+      parameter which includes ``CREATE_NEW_PROCESS_GROUP``.
 
 
 .. method:: Popen.terminate()
diff --git a/Doc/library/sys.rst b/Doc/library/sys.rst
index 542b08b187..0417d27526 100644
--- a/Doc/library/sys.rst
+++ b/Doc/library/sys.rst
@@ -1178,7 +1178,7 @@ always available.
      string, which means the current working directory.
 
    To not prepend this potentially unsafe path, use the :option:`-P` command
-   line option or the :envvar:`PYTHONSAFEPATH` environment variable?
+   line option or the :envvar:`PYTHONSAFEPATH` environment variable.
 
    A program is free to modify this list for its own purposes.  Only strings
    should be added to :data:`sys.path`; all other data types are
diff --git a/Doc/library/typing.rst b/Doc/library/typing.rst
index 04f63f6f54..9513842d1a 100644
--- a/Doc/library/typing.rst
+++ b/Doc/library/typing.rst
@@ -319,7 +319,7 @@ single type parameter ``T`` . This also makes ``T`` valid as a type within the
 class body.
 
 The :class:`Generic` base class defines :meth:`~object.__class_getitem__` so
-that ``LoggedVar[t]`` is valid as a type::
+that ``LoggedVar[T]`` is valid as a type::
 
    from collections.abc import Iterable
 
@@ -760,8 +760,8 @@ These can be used as types in annotations using ``[]``, each having a unique syn
    is equivalent to ``Tuple[Any, ...]``, and in turn to :class:`tuple`.
 
    .. deprecated:: 3.9
-      :class:`builtins.tuple <tuple>` now supports ``[]``. See :pep:`585` and
-      :ref:`types-genericalias`.
+      :class:`builtins.tuple <tuple>` now supports subscripting (``[]``).
+      See :pep:`585` and :ref:`types-genericalias`.
 
 .. data:: Union
 
@@ -849,8 +849,8 @@ These can be used as types in annotations using ``[]``, each having a unique syn
    respectively.
 
    .. deprecated:: 3.9
-      :class:`collections.abc.Callable` now supports ``[]``. See :pep:`585` and
-      :ref:`types-genericalias`.
+      :class:`collections.abc.Callable` now supports subscripting (``[]``).
+      See :pep:`585` and :ref:`types-genericalias`.
 
    .. versionchanged:: 3.10
       ``Callable`` now supports :class:`ParamSpec` and :data:`Concatenate`.
@@ -957,8 +957,8 @@ These can be used as types in annotations using ``[]``, each having a unique syn
    .. versionadded:: 3.5.2
 
    .. deprecated:: 3.9
-      :class:`builtins.type <type>` now supports ``[]``. See :pep:`585` and
-      :ref:`types-genericalias`.
+      :class:`builtins.type <type>` now supports subscripting (``[]``).
+      See :pep:`585` and :ref:`types-genericalias`.
 
 .. data:: Literal
 
@@ -1351,7 +1351,7 @@ These are not used in annotations. They are building blocks for creating generic
         Shape = TypeVarTuple('Shape')
         class Array(Generic[*Shape]):
             def __getitem__(self, key: tuple[*Shape]) -> float: ...
-            def __abs__(self) -> Array[*Shape]: ...
+            def __abs__(self) -> "Array[*Shape]": ...
             def get_shape(self) -> tuple[*Shape]: ...
 
     Type variable tuples can be happily combined with normal type variables::
@@ -1896,8 +1896,8 @@ Corresponding to built-in types
           ...
 
    .. deprecated:: 3.9
-      :class:`builtins.dict <dict>` now supports ``[]``. See :pep:`585` and
-      :ref:`types-genericalias`.
+      :class:`builtins.dict <dict>` now supports subscripting (``[]``).
+      See :pep:`585` and :ref:`types-genericalias`.
 
 .. class:: List(list, MutableSequence[T])
 
@@ -1917,8 +1917,8 @@ Corresponding to built-in types
           return [item for item in vector if item > 0]
 
    .. deprecated:: 3.9
-      :class:`builtins.list <list>` now supports ``[]``. See :pep:`585` and
-      :ref:`types-genericalias`.
+      :class:`builtins.list <list>` now supports subscripting (``[]``).
+      See :pep:`585` and :ref:`types-genericalias`.
 
 .. class:: Set(set, MutableSet[T])
 
@@ -1927,16 +1927,17 @@ Corresponding to built-in types
    to use an abstract collection type such as :class:`AbstractSet`.
 
    .. deprecated:: 3.9
-      :class:`builtins.set <set>` now supports ``[]``. See :pep:`585` and
-      :ref:`types-genericalias`.
+      :class:`builtins.set <set>` now supports subscripting (``[]``).
+      See :pep:`585` and :ref:`types-genericalias`.
 
 .. class:: FrozenSet(frozenset, AbstractSet[T_co])
 
    A generic version of :class:`builtins.frozenset <frozenset>`.
 
    .. deprecated:: 3.9
-      :class:`builtins.frozenset <frozenset>` now supports ``[]``. See
-      :pep:`585` and :ref:`types-genericalias`.
+      :class:`builtins.frozenset <frozenset>`
+      now supports subscripting (``[]``).
+      See :pep:`585` and :ref:`types-genericalias`.
 
 .. note:: :data:`Tuple` is a special form.
 
@@ -1950,8 +1951,8 @@ Corresponding to types in :mod:`collections`
    .. versionadded:: 3.5.2
 
    .. deprecated:: 3.9
-      :class:`collections.defaultdict` now supports ``[]``. See :pep:`585` and
-      :ref:`types-genericalias`.
+      :class:`collections.defaultdict` now supports subscripting (``[]``).
+      See :pep:`585` and :ref:`types-genericalias`.
 
 .. class:: OrderedDict(collections.OrderedDict, MutableMapping[KT, VT])
 
@@ -1960,8 +1961,8 @@ Corresponding to types in :mod:`collections`
    .. versionadded:: 3.7.2
 
    .. deprecated:: 3.9
-      :class:`collections.OrderedDict` now supports ``[]``. See :pep:`585` and
-      :ref:`types-genericalias`.
+      :class:`collections.OrderedDict` now supports subscripting (``[]``).
+      See :pep:`585` and :ref:`types-genericalias`.
 
 .. class:: ChainMap(collections.ChainMap, MutableMapping[KT, VT])
 
@@ -1971,8 +1972,8 @@ Corresponding to types in :mod:`collections`
    .. versionadded:: 3.6.1
 
    .. deprecated:: 3.9
-      :class:`collections.ChainMap` now supports ``[]``. See :pep:`585` and
-      :ref:`types-genericalias`.
+      :class:`collections.ChainMap` now supports subscripting (``[]``).
+      See :pep:`585` and :ref:`types-genericalias`.
 
 .. class:: Counter(collections.Counter, Dict[T, int])
 
@@ -1982,8 +1983,8 @@ Corresponding to types in :mod:`collections`
    .. versionadded:: 3.6.1
 
    .. deprecated:: 3.9
-      :class:`collections.Counter` now supports ``[]``. See :pep:`585` and
-      :ref:`types-genericalias`.
+      :class:`collections.Counter` now supports subscripting (``[]``).
+      See :pep:`585` and :ref:`types-genericalias`.
 
 .. class:: Deque(deque, MutableSequence[T])
 
@@ -1993,8 +1994,8 @@ Corresponding to types in :mod:`collections`
    .. versionadded:: 3.6.1
 
    .. deprecated:: 3.9
-      :class:`collections.deque` now supports ``[]``. See :pep:`585` and
-      :ref:`types-genericalias`.
+      :class:`collections.deque` now supports subscripting (``[]``).
+      See :pep:`585` and :ref:`types-genericalias`.
 
 Other concrete types
 """"""""""""""""""""
@@ -2008,7 +2009,7 @@ Other concrete types
    represent the types of I/O streams such as returned by
    :func:`open`.
 
-   .. deprecated-removed:: 3.8 3.12
+   .. deprecated-removed:: 3.8 3.13
       The ``typing.io`` namespace is deprecated and will be removed.
       These types should be directly imported from ``typing`` instead.
 
@@ -2022,7 +2023,7 @@ Other concrete types
    ``Pattern[str]``, ``Pattern[bytes]``, ``Match[str]``, or
    ``Match[bytes]``.
 
-   .. deprecated-removed:: 3.8 3.12
+   .. deprecated-removed:: 3.8 3.13
       The ``typing.re`` namespace is deprecated and will be removed.
       These types should be directly imported from ``typing`` instead.
 
@@ -2056,13 +2057,13 @@ Abstract Base Classes
 Corresponding to collections in :mod:`collections.abc`
 """"""""""""""""""""""""""""""""""""""""""""""""""""""
 
-.. class:: AbstractSet(Sized, Collection[T_co])
+.. class:: AbstractSet(Collection[T_co])
 
    A generic version of :class:`collections.abc.Set`.
 
    .. deprecated:: 3.9
-      :class:`collections.abc.Set` now supports ``[]``. See :pep:`585` and
-      :ref:`types-genericalias`.
+      :class:`collections.abc.Set` now supports subscripting (``[]``).
+      See :pep:`585` and :ref:`types-genericalias`.
 
 .. class:: ByteString(Sequence[int])
 
@@ -2075,8 +2076,8 @@ Corresponding to collections in :mod:`collections.abc`
    annotate arguments of any of the types mentioned above.
 
    .. deprecated:: 3.9
-      :class:`collections.abc.ByteString` now supports ``[]``. See :pep:`585`
-      and :ref:`types-genericalias`.
+      :class:`collections.abc.ByteString` now supports subscripting (``[]``).
+      See :pep:`585` and :ref:`types-genericalias`.
 
 .. class:: Collection(Sized, Iterable[T_co], Container[T_co])
 
@@ -2085,34 +2086,34 @@ Corresponding to collections in :mod:`collections.abc`
    .. versionadded:: 3.6.0
 
    .. deprecated:: 3.9
-      :class:`collections.abc.Collection` now supports ``[]``. See :pep:`585`
-      and :ref:`types-genericalias`.
+      :class:`collections.abc.Collection` now supports subscripting (``[]``).
+      See :pep:`585` and :ref:`types-genericalias`.
 
 .. class:: Container(Generic[T_co])
 
    A generic version of :class:`collections.abc.Container`.
 
    .. deprecated:: 3.9
-      :class:`collections.abc.Container` now supports ``[]``. See :pep:`585`
-      and :ref:`types-genericalias`.
+      :class:`collections.abc.Container` now supports subscripting (``[]``).
+      See :pep:`585` and :ref:`types-genericalias`.
 
-.. class:: ItemsView(MappingView, Generic[KT_co, VT_co])
+.. class:: ItemsView(MappingView, AbstractSet[tuple[KT_co, VT_co]])
 
    A generic version of :class:`collections.abc.ItemsView`.
 
    .. deprecated:: 3.9
-      :class:`collections.abc.ItemsView` now supports ``[]``. See :pep:`585`
-      and :ref:`types-genericalias`.
+      :class:`collections.abc.ItemsView` now supports subscripting (``[]``).
+      See :pep:`585` and :ref:`types-genericalias`.
 
-.. class:: KeysView(MappingView[KT_co], AbstractSet[KT_co])
+.. class:: KeysView(MappingView, AbstractSet[KT_co])
 
    A generic version of :class:`collections.abc.KeysView`.
 
    .. deprecated:: 3.9
-      :class:`collections.abc.KeysView` now supports ``[]``. See :pep:`585`
-      and :ref:`types-genericalias`.
+      :class:`collections.abc.KeysView` now supports subscripting (``[]``).
+      See :pep:`585` and :ref:`types-genericalias`.
 
-.. class:: Mapping(Sized, Collection[KT], Generic[VT_co])
+.. class:: Mapping(Collection[KT], Generic[KT, VT_co])
 
    A generic version of :class:`collections.abc.Mapping`.
    This type can be used as follows::
@@ -2121,56 +2122,58 @@ Corresponding to collections in :mod:`collections.abc`
          return word_list[word]
 
    .. deprecated:: 3.9
-      :class:`collections.abc.Mapping` now supports ``[]``. See :pep:`585`
-      and :ref:`types-genericalias`.
+      :class:`collections.abc.Mapping` now supports subscripting (``[]``).
+      See :pep:`585` and :ref:`types-genericalias`.
 
-.. class:: MappingView(Sized, Iterable[T_co])
+.. class:: MappingView(Sized)
 
    A generic version of :class:`collections.abc.MappingView`.
 
    .. deprecated:: 3.9
-      :class:`collections.abc.MappingView` now supports ``[]``. See :pep:`585`
-      and :ref:`types-genericalias`.
+      :class:`collections.abc.MappingView` now supports subscripting (``[]``).
+      See :pep:`585` and :ref:`types-genericalias`.
 
 .. class:: MutableMapping(Mapping[KT, VT])
 
    A generic version of :class:`collections.abc.MutableMapping`.
 
    .. deprecated:: 3.9
-      :class:`collections.abc.MutableMapping` now supports ``[]``. See
-      :pep:`585` and :ref:`types-genericalias`.
+      :class:`collections.abc.MutableMapping`
+      now supports subscripting (``[]``).
+      See :pep:`585` and :ref:`types-genericalias`.
 
 .. class:: MutableSequence(Sequence[T])
 
    A generic version of :class:`collections.abc.MutableSequence`.
 
    .. deprecated:: 3.9
-      :class:`collections.abc.MutableSequence` now supports ``[]``. See
-      :pep:`585` and :ref:`types-genericalias`.
+      :class:`collections.abc.MutableSequence`
+      now supports subscripting (``[]``).
+      See :pep:`585` and :ref:`types-genericalias`.
 
 .. class:: MutableSet(AbstractSet[T])
 
    A generic version of :class:`collections.abc.MutableSet`.
 
    .. deprecated:: 3.9
-      :class:`collections.abc.MutableSet` now supports ``[]``. See :pep:`585`
-      and :ref:`types-genericalias`.
+      :class:`collections.abc.MutableSet` now supports subscripting (``[]``).
+      See :pep:`585` and :ref:`types-genericalias`.
 
 .. class:: Sequence(Reversible[T_co], Collection[T_co])
 
    A generic version of :class:`collections.abc.Sequence`.
 
    .. deprecated:: 3.9
-      :class:`collections.abc.Sequence` now supports ``[]``. See :pep:`585`
-      and :ref:`types-genericalias`.
+      :class:`collections.abc.Sequence` now supports subscripting (``[]``).
+      See :pep:`585` and :ref:`types-genericalias`.
 
-.. class:: ValuesView(MappingView[VT_co])
+.. class:: ValuesView(MappingView, Collection[_VT_co])
 
    A generic version of :class:`collections.abc.ValuesView`.
 
    .. deprecated:: 3.9
-      :class:`collections.abc.ValuesView` now supports ``[]``. See :pep:`585`
-      and :ref:`types-genericalias`.
+      :class:`collections.abc.ValuesView` now supports subscripting (``[]``).
+      See :pep:`585` and :ref:`types-genericalias`.
 
 Corresponding to other types in :mod:`collections.abc`
 """"""""""""""""""""""""""""""""""""""""""""""""""""""
@@ -2180,16 +2183,16 @@ Corresponding to other types in :mod:`collections.abc`
    A generic version of :class:`collections.abc.Iterable`.
 
    .. deprecated:: 3.9
-      :class:`collections.abc.Iterable` now supports ``[]``. See :pep:`585`
-      and :ref:`types-genericalias`.
+      :class:`collections.abc.Iterable` now supports subscripting (``[]``).
+      See :pep:`585` and :ref:`types-genericalias`.
 
 .. class:: Iterator(Iterable[T_co])
 
    A generic version of :class:`collections.abc.Iterator`.
 
    .. deprecated:: 3.9
-      :class:`collections.abc.Iterator` now supports ``[]``. See :pep:`585`
-      and :ref:`types-genericalias`.
+      :class:`collections.abc.Iterator` now supports subscripting (``[]``).
+      See :pep:`585` and :ref:`types-genericalias`.
 
 .. class:: Generator(Iterator[T_co], Generic[T_co, T_contra, V_co])
 
@@ -2223,8 +2226,8 @@ Corresponding to other types in :mod:`collections.abc`
               start += 1
 
    .. deprecated:: 3.9
-      :class:`collections.abc.Generator` now supports ``[]``. See :pep:`585`
-      and :ref:`types-genericalias`.
+      :class:`collections.abc.Generator` now supports subscripting (``[]``).
+      See :pep:`585` and :ref:`types-genericalias`.
 
 .. class:: Hashable
 
@@ -2235,8 +2238,8 @@ Corresponding to other types in :mod:`collections.abc`
    A generic version of :class:`collections.abc.Reversible`.
 
    .. deprecated:: 3.9
-      :class:`collections.abc.Reversible` now supports ``[]``. See :pep:`585`
-      and :ref:`types-genericalias`.
+      :class:`collections.abc.Reversible` now supports subscripting (``[]``).
+      See :pep:`585` and :ref:`types-genericalias`.
 
 .. class:: Sized
 
@@ -2260,8 +2263,8 @@ Asynchronous programming
    .. versionadded:: 3.5.3
 
    .. deprecated:: 3.9
-      :class:`collections.abc.Coroutine` now supports ``[]``. See :pep:`585`
-      and :ref:`types-genericalias`.
+      :class:`collections.abc.Coroutine` now supports subscripting (``[]``).
+      See :pep:`585` and :ref:`types-genericalias`.
 
 .. class:: AsyncGenerator(AsyncIterator[T_co], Generic[T_co, T_contra])
 
@@ -2297,8 +2300,9 @@ Asynchronous programming
    .. versionadded:: 3.6.1
 
    .. deprecated:: 3.9
-      :class:`collections.abc.AsyncGenerator` now supports ``[]``. See
-      :pep:`585` and :ref:`types-genericalias`.
+      :class:`collections.abc.AsyncGenerator`
+      now supports subscripting (``[]``).
+      See :pep:`585` and :ref:`types-genericalias`.
 
 .. class:: AsyncIterable(Generic[T_co])
 
@@ -2307,8 +2311,8 @@ Asynchronous programming
    .. versionadded:: 3.5.2
 
    .. deprecated:: 3.9
-      :class:`collections.abc.AsyncIterable` now supports ``[]``. See :pep:`585`
-      and :ref:`types-genericalias`.
+      :class:`collections.abc.AsyncIterable` now supports subscripting (``[]``).
+      See :pep:`585` and :ref:`types-genericalias`.
 
 .. class:: AsyncIterator(AsyncIterable[T_co])
 
@@ -2317,8 +2321,8 @@ Asynchronous programming
    .. versionadded:: 3.5.2
 
    .. deprecated:: 3.9
-      :class:`collections.abc.AsyncIterator` now supports ``[]``. See :pep:`585`
-      and :ref:`types-genericalias`.
+      :class:`collections.abc.AsyncIterator` now supports subscripting (``[]``).
+      See :pep:`585` and :ref:`types-genericalias`.
 
 .. class:: Awaitable(Generic[T_co])
 
@@ -2327,8 +2331,8 @@ Asynchronous programming
    .. versionadded:: 3.5.2
 
    .. deprecated:: 3.9
-      :class:`collections.abc.Awaitable` now supports ``[]``. See :pep:`585`
-      and :ref:`types-genericalias`.
+      :class:`collections.abc.Awaitable` now supports subscripting (``[]``).
+      See :pep:`585` and :ref:`types-genericalias`.
 
 
 Context manager types
@@ -2342,8 +2346,9 @@ Context manager types
    .. versionadded:: 3.6.0
 
    .. deprecated:: 3.9
-      :class:`contextlib.AbstractContextManager` now supports ``[]``. See
-      :pep:`585` and :ref:`types-genericalias`.
+      :class:`contextlib.AbstractContextManager`
+      now supports subscripting (``[]``).
+      See :pep:`585` and :ref:`types-genericalias`.
 
 .. class:: AsyncContextManager(Generic[T_co])
 
@@ -2353,8 +2358,9 @@ Context manager types
    .. versionadded:: 3.6.2
 
    .. deprecated:: 3.9
-      :class:`contextlib.AbstractAsyncContextManager` now supports ``[]``. See
-      :pep:`585` and :ref:`types-genericalias`.
+      :class:`contextlib.AbstractAsyncContextManager`
+      now supports subscripting (``[]``).
+      See :pep:`585` and :ref:`types-genericalias`.
 
 Protocols
 ---------
@@ -2856,7 +2862,7 @@ convenience. This is subject to change, and not all deprecations are listed.
 +----------------------------------+---------------+-------------------+----------------+
 |  Feature                         | Deprecated in | Projected removal | PEP/issue      |
 +==================================+===============+===================+================+
-|  ``typing.io`` and ``typing.re`` | 3.8           | 3.12              | :issue:`38291` |
+|  ``typing.io`` and ``typing.re`` | 3.8           | 3.13              | :issue:`38291` |
 |  submodules                      |               |                   |                |
 +----------------------------------+---------------+-------------------+----------------+
 |  ``typing`` versions of standard | 3.9           | Undecided         | :pep:`585`     |
diff --git a/Doc/library/venv.rst b/Doc/library/venv.rst
index 3bed25645a..adc6cd339a 100644
--- a/Doc/library/venv.rst
+++ b/Doc/library/venv.rst
@@ -15,14 +15,22 @@
 
 --------------
 
-The :mod:`venv` module provides support for creating lightweight "virtual
-environments" with their own site directories, optionally isolated from system
-site directories.  Each virtual environment has its own Python binary (which
-matches the version of the binary that was used to create this environment) and
-can have its own independent set of installed Python packages in its site
-directories.
+.. _venv-def:
+.. _venv-intro:
+
+The :mod:`!venv` module supports creating lightweight "virtual environments",
+each with their own independent set of Python packages installed in
+their :mod:`site` directories.
+A virtual environment is created on top of an existing
+Python installation, known as the virtual environment's "base" Python, and may
+optionally be isolated from the packages in the base environment,
+so only those explicitly installed in the virtual environment are available.
+
+When used from within a virtual environment, common installation tools such as
+`pip`_ will install Python packages into a virtual environment
+without needing to be told to do so explicitly.
 
-See :pep:`405` for more information about Python virtual environments.
+See :pep:`405` for more background on Python virtual environments.
 
 .. seealso::
 
@@ -36,54 +44,72 @@ Creating virtual environments
 
 .. include:: /using/venv-create.inc
 
+.. _venv-explanation:
 
-.. _venv-def:
+How venvs work
+--------------
 
-.. note:: A virtual environment is a Python environment such that the Python
-   interpreter, libraries and scripts installed into it are isolated from those
-   installed in other virtual environments, and (by default) any libraries
-   installed in a "system" Python, i.e., one which is installed as part of your
-   operating system.
-
-   A virtual environment is a directory tree which contains Python executable
-   files and other files which indicate that it is a virtual environment.
-
-   Common installation tools such as setuptools_ and pip_ work as
-   expected with virtual environments. In other words, when a virtual
-   environment is active, they install Python packages into the virtual
-   environment without needing to be told to do so explicitly.
-
-   When a virtual environment is active (i.e., the virtual environment's Python
-   interpreter is running), the attributes :attr:`sys.prefix` and
-   :attr:`sys.exec_prefix` point to the base directory of the virtual
-   environment, whereas :attr:`sys.base_prefix` and
-   :attr:`sys.base_exec_prefix` point to the non-virtual environment Python
-   installation which was used to create the virtual environment. If a virtual
-   environment is not active, then :attr:`sys.prefix` is the same as
-   :attr:`sys.base_prefix` and :attr:`sys.exec_prefix` is the same as
-   :attr:`sys.base_exec_prefix` (they all point to a non-virtual environment
-   Python installation).
-
-   When a virtual environment is active, any options that change the
-   installation path will be ignored from all :mod:`distutils` configuration
-   files to prevent projects being inadvertently installed outside of the
-   virtual environment.
-
-   When working in a command shell, users can make a virtual environment active
-   by running an ``activate`` script in the virtual environment's executables
-   directory (the precise filename and command to use the file is
-   shell-dependent), which prepends the virtual environment's directory for
-   executables to the ``PATH`` environment variable for the running shell. There
-   should be no need in other circumstances to activate a virtual
-   environment; scripts installed into virtual environments have a "shebang"
-   line which points to the virtual environment's Python interpreter. This means
-   that the script will run with that interpreter regardless of the value of
-   ``PATH``. On Windows, "shebang" line processing is supported if you have the
-   Python Launcher for Windows installed (this was added to Python in 3.3 - see
-   :pep:`397` for more details). Thus, double-clicking an installed script in a
-   Windows Explorer window should run the script with the correct interpreter
-   without there needing to be any reference to its virtual environment in
-   ``PATH``.
+When a Python interpreter is running from a virtual environment,
+:data:`sys.prefix` and :data:`sys.exec_prefix`
+point to the directories of the virtual environment,
+whereas :data:`sys.base_prefix` and :data:`sys.base_exec_prefix`
+point to those of the base Python used to create the environment.
+It is sufficient to check
+``sys.prefix == sys.base_prefix`` to determine if the current interpreter is
+running from a virtual environment.
+
+A virtual environment may be "activated" using a script in its binary directory
+(``bin`` on POSIX; ``Scripts`` on Windows).
+This will prepend that directory to your :envvar:`!PATH`, so that running
+:program:`!python` will invoke the environment's Python interpreter
+and you can run installed scripts without having to use their full path.
+The invocation of the activation script is platform-specific
+(:samp:`{<venv>}` must be replaced by the path to the directory
+containing the virtual environment):
+
++-------------+------------+--------------------------------------------------+
+| Platform    | Shell      | Command to activate virtual environment          |
++=============+============+==================================================+
+| POSIX       | bash/zsh   | :samp:`$ source {<venv>}/bin/activate`           |
+|             +------------+--------------------------------------------------+
+|             | fish       | :samp:`$ source {<venv>}/bin/activate.fish`      |
+|             +------------+--------------------------------------------------+
+|             | csh/tcsh   | :samp:`$ source {<venv>}/bin/activate.csh`       |
+|             +------------+--------------------------------------------------+
+|             | PowerShell | :samp:`$ {<venv>}/bin/Activate.ps1`              |
++-------------+------------+--------------------------------------------------+
+| Windows     | cmd.exe    | :samp:`C:\\> {<venv>}\\Scripts\\activate.bat`    |
+|             +------------+--------------------------------------------------+
+|             | PowerShell | :samp:`PS C:\\> {<venv>}\\Scripts\\Activate.ps1` |
++-------------+------------+--------------------------------------------------+
+
+.. versionadded:: 3.4
+   :program:`!fish` and :program:`!csh` activation scripts.
+
+.. versionadded:: 3.8
+   PowerShell activation scripts installed under POSIX for PowerShell Core
+   support.
+
+You don't specifically *need* to activate a virtual environment,
+as you can just specify the full path to that environment's
+Python interpreter when invoking Python.
+Furthermore, all scripts installed in the environment
+should be runnable without activating it.
+
+In order to achieve this, scripts installed into virtual environments have
+a "shebang" line which points to the environment's Python interpreter,
+i.e. :samp:`#!/{<path-to-venv>}/bin/python`.
+This means that the script will run with that interpreter regardless of the
+value of :envvar:`!PATH`. On Windows, "shebang" line processing is supported if
+you have the :ref:`launcher` installed. Thus, double-clicking an installed
+script in a Windows Explorer window should run it with the correct interpreter
+without the environment needing to be activated or on the :envvar:`!PATH`.
+
+When a virtual environment has been activated, the :envvar:`!VIRTUAL_ENV`
+environment variable is set to the path of the environment.
+Since explicitly activating a virtual environment is not required to use it,
+:envvar:`!VIRTUAL_ENV` cannot be relied upon to determine
+whether a virtual environment is being used.
 
 .. warning:: Because scripts installed in environments should not expect the
    environment to be activated, their shebang lines contain the absolute paths
@@ -99,6 +125,11 @@ Creating virtual environments
    environment in its new location. Otherwise, software installed into the
    environment may not work as expected.
 
+You can deactivate a virtual environment by typing ``deactivate`` in your shell.
+The exact mechanism is platform-specific and is an internal implementation
+detail (typically, a script or shell function will be used).
+
+
 .. _venv-api:
 
 API
@@ -191,6 +222,45 @@ creation according to their needs, the :class:`EnvBuilder` class.
         ``clear=True``, contents of the environment directory will be cleared
         and then all necessary subdirectories will be recreated.
 
+        The returned context object is a :class:`types.SimpleNamespace` with the
+        following attributes:
+
+        * ``env_dir`` - The location of the virtual environment. Used for
+          ``__VENV_DIR__`` in activation scripts (see :meth:`install_scripts`).
+
+        * ``env_name`` - The name of the virtual environment. Used for
+          ``__VENV_NAME__`` in activation scripts (see :meth:`install_scripts`).
+
+        * ``prompt`` - The prompt to be used by the activation scripts. Used for
+          ``__VENV_PROMPT__`` in activation scripts (see :meth:`install_scripts`).
+
+        * ``executable`` - The underlying Python executable used by the virtual
+          environment. This takes into account the case where a virtual environment
+          is created from another virtual environment.
+
+        * ``inc_path`` - The include path for the virtual environment.
+
+        * ``lib_path`` - The purelib path for the virtual environment.
+
+        * ``bin_path`` - The script path for the virtual environment.
+
+        * ``bin_name`` - The name of the script path relative to the virtual
+          environment location. Used for ``__VENV_BIN_NAME__`` in activation
+          scripts (see :meth:`install_scripts`).
+
+        * ``env_exe`` - The name of the Python interpreter in the virtual
+          environment. Used for ``__VENV_PYTHON__`` in activation scripts
+          (see :meth:`install_scripts`).
+
+        * ``env_exec_cmd`` - The name of the Python interpreter, taking into
+          account filesystem redirections. This can be used to run Python in
+          the virtual environment.
+
+
+        .. versionchanged:: 3.12
+           The attribute ``lib_path`` was added to the context, and the context
+           object was documented.
+
         .. versionchanged:: 3.11
            The *venv*
            :ref:`sysconfig installation scheme <installation_paths>`
diff --git a/Doc/library/weakref.rst b/Doc/library/weakref.rst
index 8397de4fb4..a1e542b1e9 100644
--- a/Doc/library/weakref.rst
+++ b/Doc/library/weakref.rst
@@ -146,6 +146,9 @@ See :ref:`__slots__ documentation <slots>` for details.
    prevent their use as dictionary keys.  *callback* is the same as the parameter
    of the same name to the :func:`ref` function.
 
+   Accessing an attribute of the proxy object after the referent is
+   garbage collected raises :exc:`ReferenceError`.
+
    .. versionchanged:: 3.8
       Extended the operator support on proxy objects to include the matrix
       multiplication operators ``@`` and ``@=``.
diff --git a/Doc/license.rst b/Doc/license.rst
index 00691b30ba..ea1edc4325 100644
--- a/Doc/license.rst
+++ b/Doc/license.rst
@@ -984,3 +984,28 @@ https://www.w3.org/TR/xml-c14n2-testcases/ and is distributed under the
    THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
    (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
    OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+Audioop
+-------
+The audioop module uses the code base in g771.c file of the SoX project::
+    Programming the AdLib/Sound Blaster
+    FM Music Chips
+    Version 2.0 (24 Feb 1992)
+    Copyright (c) 1991, 1992 by Jeffrey S. Lee
+    jlee@smylex.uucp
+    Warranty and Copyright Policy
+    This document is provided on an "as-is" basis, and its author makes
+    no warranty or representation, express or implied, with respect to
+    its quality performance or fitness for a particular purpose.  In no
+    event will the author of this document be liable for direct, indirect,
+    special, incidental, or consequential damages arising out of the use
+    or inability to use the information contained within.  Use of this
+    document is at your own risk.
+    This file may be used and copied freely so long as the applicable
+    copyright notices are retained, and no modifications are made to the
+    text of the document.  No money shall be charged for its distribution
+    beyond reasonable shipping, handling and duplication costs, nor shall
+    proprietary changes be made to this document so that it cannot be
+    distributed freely.  This document may not be included in published
+    material or commercial packages without the written consent of its
+    author.
diff --git a/Doc/reference/compound_stmts.rst b/Doc/reference/compound_stmts.rst
index 9acad500a4..9e09515f50 100644
--- a/Doc/reference/compound_stmts.rst
+++ b/Doc/reference/compound_stmts.rst
@@ -343,7 +343,7 @@ the case of :keyword:`except`, but in the case of exception groups we can have
 partial matches when the type matches some of the exceptions in the group.
 This means that multiple :keyword:`!except*` clauses can execute,
 each handling part of the exception group.
-Each clause executes once and handles an exception group
+Each clause executes at most once and handles an exception group
 of all matching exceptions.  Each exception in the group is handled by at most
 one :keyword:`!except*` clause, the first that matches it. ::
 
@@ -364,16 +364,28 @@ one :keyword:`!except*` clause, the first that matches it. ::
        | ValueError: 1
        +------------------------------------
 
-   Any remaining exceptions that were not handled by any :keyword:`!except*`
-   clause are re-raised at the end, combined into an exception group along with
-   all exceptions that were raised from within :keyword:`!except*` clauses.
 
-   An :keyword:`!except*` clause must have a matching type,
-   and this type cannot be a subclass of :exc:`BaseExceptionGroup`.
-   It is not possible to mix :keyword:`except` and :keyword:`!except*`
-   in the same :keyword:`try`.
-   :keyword:`break`, :keyword:`continue` and :keyword:`return`
-   cannot appear in an :keyword:`!except*` clause.
+Any remaining exceptions that were not handled by any :keyword:`!except*`
+clause are re-raised at the end, combined into an exception group along with
+all exceptions that were raised from within :keyword:`!except*` clauses.
+
+If the raised exception is not an exception group and its type matches
+one of the :keyword:`!except*` clauses, it is caught and wrapped by an
+exception group with an empty message string. ::
+
+   >>> try:
+   ...     raise BlockingIOError
+   ... except* BlockingIOError as e:
+   ...     print(repr(e))
+   ...
+   ExceptionGroup('', (BlockingIOError()))
+
+An :keyword:`!except*` clause must have a matching type,
+and this type cannot be a subclass of :exc:`BaseExceptionGroup`.
+It is not possible to mix :keyword:`except` and :keyword:`!except*`
+in the same :keyword:`try`.
+:keyword:`break`, :keyword:`continue` and :keyword:`return`
+cannot appear in an :keyword:`!except*` clause.
 
 
 .. index::
@@ -581,6 +593,7 @@ The :keyword:`!match` statement
    keyword: if
    keyword: as
    pair: match; case
+   single: as; match statement
    single: : (colon); compound statement
 
 .. versionadded:: 3.10
diff --git a/Doc/reference/datamodel.rst b/Doc/reference/datamodel.rst
index f2465cdf40..70021c47c3 100644
--- a/Doc/reference/datamodel.rst
+++ b/Doc/reference/datamodel.rst
@@ -1904,6 +1904,8 @@ Attribute lookup speed can be significantly improved as well.
    and *__weakref__* for each instance.
 
 
+.. _datamodel-note-slots:
+
 Notes on using *__slots__*
 """"""""""""""""""""""""""
 
diff --git a/Doc/reference/expressions.rst b/Doc/reference/expressions.rst
index cc969752d5..0cdf91e75b 100644
--- a/Doc/reference/expressions.rst
+++ b/Doc/reference/expressions.rst
@@ -154,7 +154,7 @@ tuple may or may not yield the same object).
    single: , (comma)
 
 Note that tuples are not formed by the parentheses, but rather by use of the
-comma operator.  The exception is the empty tuple, for which parentheses *are*
+comma.  The exception is the empty tuple, for which parentheses *are*
 required --- allowing unparenthesized "nothing" in expressions would cause
 ambiguities and allow common typos to pass uncaught.
 
diff --git a/Doc/requirements.txt b/Doc/requirements.txt
index 7f82dc3211..958665db69 100644
--- a/Doc/requirements.txt
+++ b/Doc/requirements.txt
@@ -7,10 +7,7 @@ sphinx==4.5.0
 
 blurb
 
-# sphinx-lint 0.6.2 yields many default role errors due to the new regular
-# expression used for default role detection, so we don't use the version
-# until the errors are fixed.
-sphinx-lint==0.6.4
+sphinx-lint==0.6.7
 
 # The theme used by the documentation is stored separately, so we need
 # to install that as well.
diff --git a/Doc/tutorial/controlflow.rst b/Doc/tutorial/controlflow.rst
index 99a77e7add..52db51e84c 100644
--- a/Doc/tutorial/controlflow.rst
+++ b/Doc/tutorial/controlflow.rst
@@ -840,8 +840,9 @@ will always bind to the first parameter. For example::
 
 But using ``/`` (positional only arguments), it is possible since it allows ``name`` as a positional argument and ``'name'`` as a key in the keyword arguments::
 
-    def foo(name, /, **kwds):
-        return 'name' in kwds
+    >>> def foo(name, /, **kwds):
+    ...     return 'name' in kwds
+    ...
     >>> foo(1, **{'name': 2})
     True
 
diff --git a/Doc/tutorial/datastructures.rst b/Doc/tutorial/datastructures.rst
index 12b00be379..c8e89d9b79 100644
--- a/Doc/tutorial/datastructures.rst
+++ b/Doc/tutorial/datastructures.rst
@@ -122,7 +122,7 @@ An example that uses most of the list methods::
 
 You might have noticed that methods like ``insert``, ``remove`` or ``sort`` that
 only modify the list have no return value printed -- they return the default
-``None``. [1]_  This is a design principle for all mutable data structures in
+``None``. [#]_  This is a design principle for all mutable data structures in
 Python.
 
 Another thing you might notice is that not all data can be sorted or
@@ -731,5 +731,5 @@ interpreter will raise a :exc:`TypeError` exception.
 
 .. rubric:: Footnotes
 
-.. [1] Other languages may return the mutated object, which allows method
+.. [#] Other languages may return the mutated object, which allows method
        chaining, such as ``d->insert("a")->remove("b")->sort();``.
diff --git a/Doc/tutorial/inputoutput.rst b/Doc/tutorial/inputoutput.rst
index de84ab7fac..3581b3727a 100644
--- a/Doc/tutorial/inputoutput.rst
+++ b/Doc/tutorial/inputoutput.rst
@@ -478,7 +478,7 @@ becomes complicated.
 Rather than having users constantly writing and debugging code to save
 complicated data types to files, Python allows you to use the popular data
 interchange format called `JSON (JavaScript Object Notation)
-<http://json.org>`_.  The standard module called :mod:`json` can take Python
+<https://json.org>`_.  The standard module called :mod:`json` can take Python
 data hierarchies, and convert them to string representations; this process is
 called :dfn:`serializing`.  Reconstructing the data from the string representation
 is called :dfn:`deserializing`.  Between serializing and deserializing, the
diff --git a/Doc/using/venv-create.inc b/Doc/using/venv-create.inc
index b978583286..0422cd2e4e 100644
--- a/Doc/using/venv-create.inc
+++ b/Doc/using/venv-create.inc
@@ -16,8 +16,8 @@ re-used.
 
 .. deprecated:: 3.6
    ``pyvenv`` was the recommended tool for creating virtual environments for
-   Python 3.3 and 3.4, and is `deprecated in Python 3.6
-   <https://docs.python.org/dev/whatsnew/3.6.html#id8>`_.
+   Python 3.3 and 3.4, and is
+   :ref:`deprecated in Python 3.6 <whatsnew36-venv>`.
 
 .. versionchanged:: 3.5
    The use of ``venv`` is now recommended for creating virtual environments.
@@ -105,45 +105,3 @@ Multiple paths can be given to ``venv``, in which case an identical virtual
 environment will be created, according to the given options, at each provided
 path.
 
-Once a virtual environment has been created, it can be "activated" using a
-script in the virtual environment's binary directory. The invocation of the
-script is platform-specific (`<venv>` must be replaced by the path of the
-directory containing the virtual environment):
-
-+-------------+-----------------+-----------------------------------------+
-| Platform    | Shell           | Command to activate virtual environment |
-+=============+=================+=========================================+
-| POSIX       | bash/zsh        | $ source <venv>/bin/activate            |
-+-------------+-----------------+-----------------------------------------+
-|             | fish            | $ source <venv>/bin/activate.fish       |
-+-------------+-----------------+-----------------------------------------+
-|             | csh/tcsh        | $ source <venv>/bin/activate.csh        |
-+-------------+-----------------+-----------------------------------------+
-|             | PowerShell Core | $ <venv>/bin/Activate.ps1               |
-+-------------+-----------------+-----------------------------------------+
-| Windows     | cmd.exe         | C:\\> <venv>\\Scripts\\activate.bat     |
-+-------------+-----------------+-----------------------------------------+
-|             | PowerShell      | PS C:\\> <venv>\\Scripts\\Activate.ps1  |
-+-------------+-----------------+-----------------------------------------+
-
-When a virtual environment is active, the :envvar:`VIRTUAL_ENV` environment
-variable is set to the path of the virtual environment. This can be used to
-check if one is running inside a virtual environment.
-
-You don't specifically *need* to activate an environment; activation just
-prepends the virtual environment's binary directory to your path, so that
-"python" invokes the virtual environment's Python interpreter and you can run
-installed scripts without having to use their full path. However, all scripts
-installed in a virtual environment should be runnable without activating it,
-and run with the virtual environment's Python automatically.
-
-You can deactivate a virtual environment by typing "deactivate" in your shell.
-The exact mechanism is platform-specific and is an internal implementation
-detail (typically a script or shell function will be used).
-
-.. versionadded:: 3.4
-   ``fish`` and ``csh`` activation scripts.
-
-.. versionadded:: 3.8
-   PowerShell activation scripts installed under POSIX for PowerShell Core
-   support.
diff --git a/Doc/using/windows.rst b/Doc/using/windows.rst
index 4ab68e140b..4526dc3487 100644
--- a/Doc/using/windows.rst
+++ b/Doc/using/windows.rst
@@ -853,7 +853,6 @@ minor version. I.e. ``/usr/bin/python3.7-32`` will request usage of the
    not provably i386/32-bit". To request a specific environment, use the new
    ``-V:<TAG>`` argument with the complete tag.
 
-
 The ``/usr/bin/env`` form of shebang line has one further special property.
 Before looking for installed Python interpreters, this form will search the
 executable :envvar:`PATH` for a Python executable. This corresponds to the
@@ -863,6 +862,13 @@ be found, it will be handled as described below. Additionally, the environment
 variable :envvar:`PYLAUNCHER_NO_SEARCH_PATH` may be set (to any value) to skip
 this additional search.
 
+Shebang lines that do not match any of these patterns are treated as **Windows**
+paths that are absolute or relative to the directory containing the script file.
+This is a convenience for Windows-only scripts, such as those generated by an
+installer, since the behavior is not compatible with Unix-style shells.
+These paths may be quoted, and may include multiple arguments, after which the
+path to the script and any additional arguments will be appended.
+
 
 Arguments in shebang lines
 --------------------------
diff --git a/Doc/whatsnew/2.2.rst b/Doc/whatsnew/2.2.rst
index 39997661bb..0c3bfda193 100644
--- a/Doc/whatsnew/2.2.rst
+++ b/Doc/whatsnew/2.2.rst
@@ -395,7 +395,7 @@ This section has just been a quick overview of the new features, giving enough
 of an explanation to start you programming, but many details have been
 simplified or ignored.  Where should you go to get a more complete picture?
 
-https://docs.python.org/dev/howto/descriptor.html is a lengthy tutorial introduction to
+The :ref:`descriptorhowto` is a lengthy tutorial introduction to
 the descriptor features, written by Guido van Rossum. If my description has
 whetted your appetite, go read this tutorial next, because it goes into much
 more detail about the new features while still remaining quite easy to read.
diff --git a/Doc/whatsnew/2.6.rst b/Doc/whatsnew/2.6.rst
index b96dfe9159..34f2656f76 100644
--- a/Doc/whatsnew/2.6.rst
+++ b/Doc/whatsnew/2.6.rst
@@ -217,7 +217,7 @@ the time required to finish the job.
 During the 2.6 development cycle, Georg Brandl put a lot of effort
 into building a new toolchain for processing the documentation.  The
 resulting package is called Sphinx, and is available from
-http://sphinx-doc.org/.
+https://www.sphinx-doc.org/.
 
 Sphinx concentrates on HTML output, producing attractively styled and
 modern HTML; printed output is still supported through conversion to
@@ -235,7 +235,7 @@ have adopted Sphinx as their documentation tool.
    `Documenting Python <https://devguide.python.org/documenting/>`__
        Describes how to write for Python's documentation.
 
-   `Sphinx <http://sphinx-doc.org/>`__
+   `Sphinx <https://www.sphinx-doc.org/>`__
      Documentation and code for the Sphinx toolchain.
 
    `Docutils <https://docutils.sourceforge.io>`__
@@ -1926,7 +1926,7 @@ changes, or look through the Subversion logs for all the details.
   the left to six places.  (Contributed by Skip Montanaro; :issue:`1158`.)
 
 * The :mod:`decimal` module was updated to version 1.66 of
-  `the General Decimal Specification <http://speleotrove.com/decimal/decarith.html>`__.  New features
+  `the General Decimal Specification <https://speleotrove.com/decimal/decarith.html>`__.  New features
   include some methods for some basic mathematical functions such as
   :meth:`exp` and :meth:`log10`::
 
diff --git a/Doc/whatsnew/3.1.rst b/Doc/whatsnew/3.1.rst
index 6ce6358d49..fba8816bb2 100644
--- a/Doc/whatsnew/3.1.rst
+++ b/Doc/whatsnew/3.1.rst
@@ -451,7 +451,7 @@ Major performance enhancements have been added:
 * The :mod:`json` module now has a C extension to substantially improve
   its performance.  In addition, the API was modified so that json works
   only with :class:`str`, not with :class:`bytes`.  That change makes the
-  module closely match the `JSON specification <http://json.org/>`_
+  module closely match the `JSON specification <https://json.org/>`_
   which is defined in terms of Unicode.
 
   (Contributed by Bob Ippolito and converted to Py3.1 by Antoine Pitrou
diff --git a/Doc/whatsnew/3.10.rst b/Doc/whatsnew/3.10.rst
index 24d5bba66e..549fdda3aa 100644
--- a/Doc/whatsnew/3.10.rst
+++ b/Doc/whatsnew/3.10.rst
@@ -2151,8 +2151,7 @@ Porting to Python 3.10
 * The ``PY_SSIZE_T_CLEAN`` macro must now be defined to use
   :c:func:`PyArg_ParseTuple` and :c:func:`Py_BuildValue` formats which use
   ``#``: ``es#``, ``et#``, ``s#``, ``u#``, ``y#``, ``z#``, ``U#`` and ``Z#``.
-  See :ref:`Parsing arguments and building values
-  <arg-parsing>` and the :pep:`353`.
+  See :ref:`arg-parsing` and :pep:`353`.
   (Contributed by Victor Stinner in :issue:`40943`.)
 
 * Since :c:func:`Py_REFCNT()` is changed to the inline static function,
@@ -2183,8 +2182,7 @@ Porting to Python 3.10
   :c:func:`Py_GetProgramFullPath`, :c:func:`Py_GetPythonHome` and
   :c:func:`Py_GetProgramName` functions now return ``NULL`` if called before
   :c:func:`Py_Initialize` (before Python is initialized). Use the new
-  :ref:`Python Initialization Configuration API <init-config>` to get the
-  :ref:`Python Path Configuration.  <init-path-config>`.
+  :ref:`init-config` API to get the :ref:`init-path-config`.
   (Contributed by Victor Stinner in :issue:`42260`.)
 
 * :c:func:`PyList_SET_ITEM`, :c:func:`PyTuple_SET_ITEM` and
@@ -2198,7 +2196,7 @@ Porting to Python 3.10
   ``picklebufobject.h``, ``pyarena.h``, ``pyctype.h``, ``pydebug.h``,
   ``pyfpe.h``, and ``pytime.h`` have been moved to the ``Include/cpython``
   directory. These files must not be included directly, as they are already
-  included in ``Python.h``: :ref:`Include Files <api-includes>`. If they have
+  included in ``Python.h``; see :ref:`api-includes`. If they have
   been included directly, consider including ``Python.h`` instead.
   (Contributed by Nicholas Sim in :issue:`35134`.)
 
diff --git a/Doc/whatsnew/3.11.rst b/Doc/whatsnew/3.11.rst
index 8f3ef3ffc1..f09ccb133f 100644
--- a/Doc/whatsnew/3.11.rst
+++ b/Doc/whatsnew/3.11.rst
@@ -4,6 +4,7 @@
 
 :Release: |release|
 :Date: |today|
+:Editor: Pablo Galindo Salgado
 
 .. Rules for maintenance:
 
@@ -614,12 +615,18 @@ asyncio
   These are primarily intended for internal use,
   notably by :class:`~asyncio.TaskGroup`.
 
+
+.. _whatsnew311-contextlib:
+
 contextlib
 ----------
 
-Added non parallel-safe :func:`~contextlib.chdir` context manager to change
-the current working directory and then restore it on exit. Simple wrapper
-around :func:`~os.chdir`. (Contributed by Filipe Lans in :issue:`25625`)
+* Added non parallel-safe :func:`~contextlib.chdir` context manager to change
+  the current working directory and then restore it on exit. Simple wrapper
+  around :func:`~os.chdir`. (Contributed by Filipe Lans in :issue:`25625`)
+
+
+.. _whatsnew311-dataclasses:
 
 dataclasses
 -----------
@@ -629,11 +636,15 @@ dataclasses
   :class:`dict`, :class:`list` or :class:`set`. (Contributed by Eric V. Smith in
   :issue:`44674`.)
 
+
+.. _whatsnew311-datetime:
+
 datetime
 --------
 
 * Add :attr:`datetime.UTC`, a convenience alias for
   :attr:`datetime.timezone.utc`. (Contributed by Kabir Kwatra in :gh:`91973`.)
+
 * :meth:`datetime.date.fromisoformat`, :meth:`datetime.time.fromisoformat` and
   :meth:`datetime.datetime.fromisoformat` can now be used to parse most ISO 8601
   formats (barring only those that support fractional hours and minutes).
@@ -658,7 +669,7 @@ enum
   (used by :func:`str`, :func:`format` and :term:`f-string`\s).
 
 * Changed :class:`~enum.IntEnum`, :class:`~enum.IntFlag` and :class:`~enum.StrEnum`
-  to now inherit from :class:`ReprEnum`,
+  to now inherit from :class:`~enum.ReprEnum`,
   so their :func:`str` output now matches :func:`format`
   (both ``str(AnIntEnum.ONE)`` and ``format(AnIntEnum.ONE)`` return ``'1'``,
   whereas before ``str(AnIntEnum.ONE)`` returned ``'AnIntEnum.ONE'``.
@@ -708,6 +719,18 @@ enum
   inverted flags are coerced to their positive equivalent.
 
 
+.. _whatsnew311-fcntl:
+
+fcntl
+-----
+
+* On FreeBSD, the :data:`!F_DUP2FD` and :data:`!F_DUP2FD_CLOEXEC` flags respectively
+  are supported, the former equals to ``dup2`` usage while the latter set
+  the ``FD_CLOEXEC`` flag in addition.
+
+
+.. _whatsnew311-fractions:
+
 fractions
 ---------
 
@@ -718,6 +741,9 @@ fractions
   that an ``isinstance(some_fraction, typing.SupportsInt)`` check passes.
   (Contributed by Mark Dickinson in :issue:`44547`.)
 
+
+.. _whatsnew311-functools:
+
 functools
 ---------
 
@@ -748,6 +774,9 @@ functools
 
   (Contributed by Yurii Karabas in :issue:`46014`.)
 
+
+.. _whatsnew311-hashlib:
+
 hashlib
 -------
 
@@ -766,6 +795,9 @@ hashlib
   of files or file-like objects.
   (Contributed by Christian Heimes in :gh:`89313`.)
 
+
+.. _whatsnew311-idle:
+
 IDLE and idlelib
 ----------------
 
@@ -803,6 +835,9 @@ inspect
 
   (Contributed by Pablo Galindo in :gh:`88116`.)
 
+
+.. _whatsnew311-locale:
+
 locale
 ------
 
@@ -830,6 +865,8 @@ logging
   (Contributed by Kirill Pinchuk in :gh:`88457`.)
 
 
+.. _whatsnew311-math:
+
 math
 ----
 
@@ -849,6 +886,8 @@ math
   (Contributed by Victor Stinner in :issue:`46917`.)
 
 
+.. _whatsnew311-operator:
+
 operator
 --------
 
@@ -857,6 +896,8 @@ operator
   (Contributed by Antony Lee in :issue:`44019`.)
 
 
+.. _whatsnew311-os:
+
 os
 --
 
@@ -865,6 +906,8 @@ os
   (Contributed by Dong-hee Na in :issue:`44611`.)
 
 
+.. _whatsnew311-pathlib:
+
 pathlib
 -------
 
@@ -873,6 +916,9 @@ pathlib
   :data:`~os.sep` or :data:`~os.altsep`.
   (Contributed by Eisuke Kawasima in :issue:`22276` and :issue:`33392`.)
 
+
+.. _whatsnew311-re:
+
 re
 --
 
@@ -880,6 +926,9 @@ re
   ``?+``, ``{m,n}+``) are now supported in regular expressions.
   (Contributed by Jeffrey C. Jacobs and Serhiy Storchaka in :issue:`433030`.)
 
+
+.. _whatsnew311-shutil:
+
 shutil
 ------
 
@@ -887,6 +936,8 @@ shutil
   (Contributed by Serhiy Storchaka in :issue:`46245`.)
 
 
+.. _whatsnew311-socket:
+
 socket
 ------
 
@@ -898,6 +949,9 @@ socket
   instead of only raising the last error.
   (Contributed by Irit Katriel in :issue:`29980`.)
 
+
+.. _whatsnew311-sqlite3:
+
 sqlite3
 -------
 
@@ -961,13 +1015,15 @@ string
   (Contributed by Ben Kehoe in :gh:`90465`.)
 
 
+.. _whatsnew311-sys:
+
 sys
 ---
 
 * :func:`sys.exc_info` now derives the ``type`` and ``traceback`` fields
   from the ``value`` (the exception instance), so when an exception is
   modified while it is being handled, the changes are reflected in
-  the results of subsequent calls to :func:`exc_info`.
+  the results of subsequent calls to :func:`!exc_info`.
   (Contributed by Irit Katriel in :issue:`45711`.)
 
 * Add :func:`sys.exception` which returns the active exception instance
@@ -978,6 +1034,8 @@ sys
   (Contributed by Victor Stinner in :gh:`57684`.)
 
 
+.. _whatsnew311-sysconfig:
+
 sysconfig
 ---------
 
@@ -995,6 +1053,21 @@ sysconfig
   (Contributed by Miro Hronok in :issue:`45413`.)
 
 
+.. _whatsnew311-tempfile:
+
+tempfile
+--------
+
+* :class:`~tempfile.SpooledTemporaryFile` objects now fully implement the methods
+  of :class:`io.BufferedIOBase` or :class:`io.TextIOBase`
+  (depending on file mode).
+  This lets them work correctly with APIs that expect file-like objects,
+  such as compression modules.
+  (Contributed by Carey Metcalfe in :gh:`70363`.)
+
+
+.. _whatsnew311-threading:
+
 threading
 ---------
 
@@ -1006,6 +1079,8 @@ threading
   (Contributed by Victor Stinner in :issue:`41710`.)
 
 
+.. _whatsnew311-time:
+
 time
 ----
 
@@ -1023,6 +1098,18 @@ time
   (Contributed by Benjamin Szke, Dong-hee Na, Eryk Sun and Victor Stinner in :issue:`21302` and :issue:`45429`.)
 
 
+.. _whatsnew311-tkinter:
+
+tkinter
+-------
+
+* Added method ``info_patchlevel()`` which returns the exact version of
+  the Tcl library as a named tuple similar to :data:`sys.version_info`.
+  (Contributed by Serhiy Storchaka in :gh:`91827`.)
+
+
+.. _whatsnew311-traceback:
+
 traceback
 ---------
 
@@ -1036,6 +1123,8 @@ traceback
   (Contributed by Irit Katriel in :issue:`33809`.)
 
 
+.. _whatsnew311-typing:
+
 typing
 ------
 
@@ -1076,7 +1165,7 @@ For major changes, see :ref:`new-feat-related-type-hints-311`.
   to clear all registered overloads of a function.
   (Contributed by Jelle Zijlstra in :gh:`89263`.)
 
-* The :meth:`__init__` method of :class:`~typing.Protocol` subclasses
+* The :meth:`~object.__init__` method of :class:`~typing.Protocol` subclasses
   is now preserved. (Contributed by Adrian Garcia Badarasco in :gh:`88970`.)
 
 * The representation of empty tuple types (``Tuple[()]``) is simplified.
@@ -1105,19 +1194,16 @@ For major changes, see :ref:`new-feat-related-type-hints-311`.
   by Nikita Sobolev in :gh:`90729`.)
 
 
-tkinter
--------
-
-* Added method ``info_patchlevel()`` which returns the exact version of
-  the Tcl library as a named tuple similar to :data:`sys.version_info`.
-  (Contributed by Serhiy Storchaka in :gh:`91827`.)
-
+.. _whatsnew311-unicodedata:
 
 unicodedata
 -----------
 
-* The Unicode database has been updated to version 14.0.0. (Contributed by  Benjamin Peterson in :issue:`45190`).
+* The Unicode database has been updated to version 14.0.0.
+  (Contributed by Benjamin Peterson in :issue:`45190`).
+
 
+.. _whatsnew311-unittest:
 
 unittest
 --------
@@ -1131,6 +1217,8 @@ unittest
   (Contributed by Serhiy Storchaka in :issue:`45046`.)
 
 
+.. _whatsnew311-venv:
+
 venv
 ----
 
@@ -1144,6 +1232,9 @@ venv
   Third party code that also creates new virtual environments should do the same.
   (Contributed by Miro Hronok in :issue:`45413`.)
 
+
+.. _whatsnew311-warnings:
+
 warnings
 --------
 
@@ -1170,14 +1261,6 @@ zipfile
   (Contributed by Miguel Brito in :gh:`88261`.)
 
 
-fcntl
------
-
-* On FreeBSD, the :attr:`F_DUP2FD` and :attr:`F_DUP2FD_CLOEXEC` flags respectively
-  are supported, the former equals to ``dup2`` usage while the latter set
-  the ``FD_CLOEXEC`` flag in addition.
-
-
 .. _whatsnew311-optimizations:
 
 Optimizations
@@ -1481,58 +1564,100 @@ contributors are volunteers from the community.
 CPython bytecode changes
 ========================
 
-* The bytecode now contains inline cache entries, which take the form of
-  :opcode:`CACHE` instructions. Many opcodes expect to be followed by an exact
-  number of caches, and instruct the interpreter to skip over them at runtime.
-  Populated caches can look like arbitrary instructions, so great care should be
-  taken when reading or modifying raw, adaptive bytecode containing quickened
-  data.
+The bytecode now contains inline cache entries,
+which take the form of the newly-added :opcode:`CACHE` instructions.
+Many opcodes expect to be followed by an exact number of caches,
+and instruct the interpreter to skip over them at runtime.
+Populated caches can look like arbitrary instructions,
+so great care should be taken when reading or modifying
+raw, adaptive bytecode containing quickened data.
 
-* Replaced all numeric ``BINARY_*`` and ``INPLACE_*`` instructions with a single
-  :opcode:`BINARY_OP` implementation.
 
-* Replaced the three call instructions: :opcode:`CALL_FUNCTION`,
-  :opcode:`CALL_FUNCTION_KW` and :opcode:`CALL_METHOD` with
-  :opcode:`PUSH_NULL`, :opcode:`PRECALL`, :opcode:`CALL`,
-  and :opcode:`KW_NAMES`.
-  This decouples the argument shifting for methods from the handling of
-  keyword arguments and allows better specialization of calls.
+.. _whatsnew311-added-opcodes:
 
-* Removed ``COPY_DICT_WITHOUT_KEYS`` and ``GEN_START``.
+New opcodes
+-----------
 
-* :opcode:`MATCH_CLASS` and :opcode:`MATCH_KEYS` no longer push an additional
-  boolean value indicating whether the match succeeded or failed. Instead, they
-  indicate failure with :const:`None` (where a tuple of extracted values would
-  otherwise be).
+* :opcode:`ASYNC_GEN_WRAP`, :opcode:`RETURN_GENERATOR` and :opcode:`SEND`,
+  used in generators and co-routines.
 
-* Replace several stack manipulation instructions (``DUP_TOP``, ``DUP_TOP_TWO``,
-  ``ROT_TWO``, ``ROT_THREE``, ``ROT_FOUR``, and ``ROT_N``) with new
-  :opcode:`COPY` and :opcode:`SWAP` instructions.
+* :opcode:`COPY_FREE_VARS`,
+  which avoids needing special caller-side code for closures.
 
-* Replaced :opcode:`JUMP_IF_NOT_EXC_MATCH` by :opcode:`CHECK_EXC_MATCH` which
-  performs the check but does not jump.
+* :opcode:`JUMP_BACKWARD_NO_INTERRUPT`,
+  for use in certain loops where handling interrupts is undesirable.
 
-* Replaced :opcode:`JUMP_IF_NOT_EG_MATCH` by :opcode:`CHECK_EG_MATCH` which
-  performs the check but does not jump.
+* :opcode:`MAKE_CELL`, to create :ref:`cell-objects`.
 
-* Replaced :opcode:`JUMP_ABSOLUTE` by the relative :opcode:`JUMP_BACKWARD`.
+* :opcode:`CHECK_EG_MATCH`  and  :opcode:`PREP_RERAISE_STAR`,
+  to handle the :ref:`new exception groups and except* <whatsnew311-pep654>`
+  added in :pep:`654`.
 
-* Added :opcode:`JUMP_BACKWARD_NO_INTERRUPT`, which is used in certain loops where it
-  is undesirable to handle interrupts.
+* :opcode:`PUSH_EXC_INFO`, for use in exception handlers.
 
-* Replaced :opcode:`POP_JUMP_IF_TRUE` and :opcode:`POP_JUMP_IF_FALSE` by
-  the relative :opcode:`POP_JUMP_FORWARD_IF_TRUE`, :opcode:`POP_JUMP_BACKWARD_IF_TRUE`,
-  :opcode:`POP_JUMP_FORWARD_IF_FALSE` and :opcode:`POP_JUMP_BACKWARD_IF_FALSE`.
+* :opcode:`RESUME`, a no-op,
+  for internal tracing, debugging and optimization checks.
 
-* Added :opcode:`POP_JUMP_FORWARD_IF_NOT_NONE`, :opcode:`POP_JUMP_BACKWARD_IF_NOT_NONE`,
-  :opcode:`POP_JUMP_FORWARD_IF_NONE` and :opcode:`POP_JUMP_BACKWARD_IF_NONE`
-  opcodes to speed up conditional jumps.
 
-* :opcode:`JUMP_IF_TRUE_OR_POP` and :opcode:`JUMP_IF_FALSE_OR_POP` are now
-  relative rather than absolute.
+.. _whatsnew311-replaced-opcodes:
 
-* :opcode:`RESUME` has been added. It is a no-op. Performs internal tracing,
-  debugging and optimization checks.
+Replaced opcodes
+----------------
+
++------------------------------------+-----------------------------------+-----------------------------------------+
+| Replaced Opcode(s)                 | New Opcode(s)                     | Notes                                   |
++====================================+===================================+=========================================+
+| | :opcode:`!BINARY_*`              | :opcode:`BINARY_OP`               | Replaced all numeric binary/in-place    |
+| | :opcode:`!INPLACE_*`             |                                   | opcodes with a single opcode            |
++------------------------------------+-----------------------------------+-----------------------------------------+
+| | :opcode:`!CALL_FUNCTION`         | | :opcode:`CALL`                  | Decouples argument shifting for methods |
+| | :opcode:`!CALL_FUNCTION_KW`      | | :opcode:`KW_NAMES`              | from handling of keyword arguments;     |
+| | :opcode:`!CALL_METHOD`           | | :opcode:`PRECALL`               | allows better specialization of calls   |
+|                                    | | :opcode:`PUSH_NULL`             |                                         |
++------------------------------------+-----------------------------------+-----------------------------------------+
+| | :opcode:`!DUP_TOP`               | | :opcode:`COPY`                  | Stack manipulation instructions         |
+| | :opcode:`!DUP_TOP_TWO`           | | :opcode:`SWAP`                  |                                         |
+| | :opcode:`!ROT_TWO`               |                                   |                                         |
+| | :opcode:`!ROT_THREE`             |                                   |                                         |
+| | :opcode:`!ROT_FOUR`              |                                   |                                         |
+| | :opcode:`!ROT_N`                 |                                   |                                         |
++------------------------------------+-----------------------------------+-----------------------------------------+
+| | :opcode:`!JUMP_IF_NOT_EXC_MATCH` | | :opcode:`CHECK_EXC_MATCH`       | Now performs check but doesn't jump     |
++------------------------------------+-----------------------------------+-----------------------------------------+
+| | :opcode:`!JUMP_ABSOLUTE`         | | :opcode:`JUMP_BACKWARD`         | See [#bytecode-jump]_;                  |
+| | :opcode:`!POP_JUMP_IF_FALSE`     | | :opcode:`POP_JUMP_BACKWARD_IF_* | ``TRUE``, ``FALSE``,                    |
+| | :opcode:`!POP_JUMP_IF_TRUE`      |   <POP_JUMP_BACKWARD_IF_TRUE>`    | ``NONE`` and ``NOT_NONE`` variants      |
+|                                    | | :opcode:`POP_JUMP_FORWARD_IF_*  | for each direction                      |
+|                                    |   <POP_JUMP_FORWARD_IF_TRUE>`     |                                         |
++------------------------------------+-----------------------------------+-----------------------------------------+
+| | :opcode:`!SETUP_WITH`            | :opcode:`BEFORE_WITH`             | :keyword:`with` block setup             |
+| | :opcode:`!SETUP_ASYNC_WITH`      |                                   |                                         |
++------------------------------------+-----------------------------------+-----------------------------------------+
+
+.. [#bytecode-jump] All jump opcodes are now relative, including the
+   existing :opcode:`JUMP_IF_TRUE_OR_POP` and :opcode:`JUMP_IF_FALSE_OR_POP`.
+   The argument is now an offset from the current instruction
+   rather than an absolute location.
+
+
+.. _whatsnew311-changed-opcodes:
+.. _whatsnew311-removed-opcodes:
+.. _whatsnew311-changed-removed-opcodes:
+
+Changed/removed opcodes
+-----------------------
+
+* Changed :opcode:`MATCH_CLASS` and :opcode:`MATCH_KEYS`
+  to no longer push an additional boolean value to indicate success/failure.
+  Instead, ``None`` is pushed on failure
+  in place of the tuple of extracted values.
+
+* Changed opcodes that work with exceptions to reflect them
+  now being represented as one item on the stack instead of three
+  (see :gh:`89874`).
+
+* Removed :opcode:`!COPY_DICT_WITHOUT_KEYS`, :opcode:`!GEN_START`,
+  :opcode:`!POP_BLOCK`, :opcode:`!SETUP_FINALLY` and :opcode:`!YIELD_FROM`.
 
 
 .. _whatsnew311-deprecated:
@@ -1545,78 +1670,107 @@ This section lists Python APIs that have been deprecated in Python 3.11.
 
 Deprecated C APIs are :ref:`listed separately <whatsnew311-c-api-deprecated>`.
 
+
+.. _whatsnew311-deprecated-language:
+.. _whatsnew311-deprecated-builtins:
+
+Language/Builtins
+-----------------
+
 * Chaining :class:`classmethod` descriptors (introduced in :issue:`19072`)
   is now deprecated.  It can no longer be used to wrap other descriptors
   such as :class:`property`.  The core design of this feature was flawed
   and caused a number of downstream problems.  To "pass-through" a
-  :class:`classmethod`, consider using the ``__wrapped__`` attribute
+  :class:`classmethod`, consider using the :attr:`!__wrapped__` attribute
   that was added in Python 3.10.
   (Contributed by Raymond Hettinger in :gh:`89519`.)
 
-* Octal escapes in string and bytes literals with value larger than ``0o377`` now
-  produce :exc:`DeprecationWarning`.
-  In a future Python version they will be a :exc:`SyntaxWarning` and
+* Octal escapes in string and bytes literals with values larger than ``0o377``
+  (255 in decimal) now produce a :exc:`DeprecationWarning`.
+  In a future Python version, they will raise a :exc:`SyntaxWarning` and
   eventually a :exc:`SyntaxError`.
   (Contributed by Serhiy Storchaka in :gh:`81548`.)
 
-* The :mod:`lib2to3` package and ``2to3`` tool are now deprecated and may not
-  be able to parse Python 3.10 or newer. See the :pep:`617` (New PEG parser for
-  CPython).  (Contributed by Victor Stinner in :issue:`40360`.)
+* The delegation of :func:`int` to :meth:`~object.__trunc__` is now deprecated.
+  Calling ``int(a)`` when ``type(a)`` implements :meth:`!__trunc__` but not
+  :meth:`~object.__int__` or :meth:`~object.__index__` now raises
+  a :exc:`DeprecationWarning`.
+  (Contributed by Zackery Spytz in :issue:`44977`.)
 
-* Undocumented modules ``sre_compile``, ``sre_constants`` and ``sre_parse``
-  are now deprecated.
-  (Contributed by Serhiy Storchaka in :issue:`47152`.)
 
-* :class:`webbrowser.MacOSX` is deprecated and will be removed in Python 3.13.
-  It is untested and undocumented and also not used by webbrowser itself.
-  (Contributed by Dong-hee Na in :issue:`42255`.)
+.. _whatsnew311-deprecated-modules:
 
-* The behavior of returning a value from a :class:`~unittest.TestCase` and
-  :class:`~unittest.IsolatedAsyncioTestCase` test methods (other than the
-  default ``None`` value), is now deprecated.
+Modules
+-------
 
-* Deprecated the following :mod:`unittest` functions, scheduled for removal in
-  Python 3.13:
+.. _whatsnew311-pep594:
 
-  * :func:`unittest.findTestCases`
-  * :func:`unittest.makeSuite`
-  * :func:`unittest.getTestCaseNames`
+* :pep:`594` led to the deprecations of the following modules
+  slated for removal in Python 3.13:
 
-  Use :class:`~unittest.TestLoader` method instead:
+  +---------------------+---------------------+---------------------+---------------------+---------------------+
+  | :mod:`aifc`         | :mod:`chunk`        | :mod:`msilib`       | :mod:`pipes`        | :mod:`telnetlib`    |
+  +---------------------+---------------------+---------------------+---------------------+---------------------+
+  | :mod:`audioop`      | :mod:`crypt`        | :mod:`nis`          | :mod:`sndhdr`       | :mod:`uu`           |
+  +---------------------+---------------------+---------------------+---------------------+---------------------+
+  | :mod:`cgi`          | :mod:`imghdr`       | :mod:`nntplib`      | :mod:`spwd`         | :mod:`xdrlib`       |
+  +---------------------+---------------------+---------------------+---------------------+---------------------+
+  | :mod:`cgitb`        | :mod:`mailcap`      | :mod:`ossaudiodev`  | :mod:`sunau`        |                     |
+  +---------------------+---------------------+---------------------+---------------------+---------------------+
 
-  * :meth:`unittest.TestLoader.loadTestsFromModule`
-  * :meth:`unittest.TestLoader.loadTestsFromTestCase`
-  * :meth:`unittest.TestLoader.getTestCaseNames`
+  (Contributed by Brett Cannon in :issue:`47061` and Victor Stinner in
+  :gh:`68966`.)
 
-  (Contributed by Erlend E. Aasland in :issue:`5846`.)
+* The :mod:`asynchat`, :mod:`asyncore` and  :mod:`smtpd` modules have been
+  deprecated since at least Python 3.6. Their documentation and deprecation
+  warnings have now been updated to note they will be removed in Python 3.12.
+  (Contributed by Hugo van Kemenade in :issue:`47022`.)
 
-* The :meth:`turtle.RawTurtle.settiltangle` is deprecated since Python 3.1,
-  it now emits a deprecation warning and will be removed in Python 3.13. Use
-  :meth:`turtle.RawTurtle.tiltangle` instead (it was earlier incorrectly marked
-  as deprecated, its docstring is now corrected).
-  (Contributed by Hugo van Kemenade in :issue:`45837`.)
+* The :mod:`lib2to3` package and :ref:`2to3 <2to3-reference>` tool
+  are now deprecated and may not be able to parse Python 3.10 or newer.
+  See :pep:`617`, introducing the new PEG parser, for details.
+  (Contributed by Victor Stinner in :issue:`40360`.)
 
-* The delegation of :func:`int` to :meth:`__trunc__` is now deprecated. Calling
-  ``int(a)`` when ``type(a)`` implements :meth:`__trunc__` but not
-  :meth:`__int__` or :meth:`__index__` now raises a :exc:`DeprecationWarning`.
-  (Contributed by Zackery Spytz in :issue:`44977`.)
+* Undocumented modules :mod:`!sre_compile`, :mod:`!sre_constants`
+  and :mod:`!sre_parse` are now deprecated.
+  (Contributed by Serhiy Storchaka in :issue:`47152`.)
+
+
+.. _whatsnew311-deprecated-stdlib:
+
+Standard Library
+----------------
 
 * The following have been deprecated in :mod:`configparser` since Python 3.2.
-  Their deprecation warnings have now been updated to note they will removed in
-  Python 3.12:
+  Their deprecation warnings have now been updated to note they will be removed
+  in Python 3.12:
 
-  * the :class:`configparser.SafeConfigParser` class
-  * the :attr:`configparser.ParsingError.filename` property
+  * the :class:`!configparser.SafeConfigParser` class
+  * the :attr:`!configparser.ParsingError.filename` property
   * the :meth:`configparser.RawConfigParser.readfp` method
 
   (Contributed by Hugo van Kemenade in :issue:`45173`.)
 
-* :class:`configparser.LegacyInterpolation` has been deprecated in the docstring
-  since Python 3.2. It now emits a :exc:`DeprecationWarning` and will be removed
+* :class:`!configparser.LegacyInterpolation` has been deprecated in the docstring
+  since Python 3.2, and is not listed in the :mod:`configparser` documentation.
+  It now emits a :exc:`DeprecationWarning` and will be removed
   in Python 3.13. Use :class:`configparser.BasicInterpolation` or
   :class:`configparser.ExtendedInterpolation` instead.
   (Contributed by Hugo van Kemenade in :issue:`46607`.)
 
+* The older set of :mod:`importlib.resources` functions were deprecated
+  in favor of the replacements added in Python 3.9
+  and will be removed in a future Python version,
+  due to not supporting resources located within package subdirectories:
+
+  * :func:`importlib.resources.contents`
+  * :func:`importlib.resources.is_resource`
+  * :func:`importlib.resources.open_binary`
+  * :func:`importlib.resources.open_text`
+  * :func:`importlib.resources.read_binary`
+  * :func:`importlib.resources.read_text`
+  * :func:`importlib.resources.path`
+
 * The :func:`locale.getdefaultlocale` function is deprecated and will be
   removed in Python 3.13. Use :func:`locale.setlocale`,
   :func:`locale.getpreferredencoding(False) <locale.getpreferredencoding>` and
@@ -1627,46 +1781,25 @@ Deprecated C APIs are :ref:`listed separately <whatsnew311-c-api-deprecated>`.
   removed in Python 3.13. Use ``locale.setlocale(locale.LC_ALL, "")`` instead.
   (Contributed by Victor Stinner in :gh:`90817`.)
 
-.. _whatsnew311-pep594:
-
-* :pep:`594` led to the deprecations of the following modules which are
-  slated for removal in Python 3.13:
-
-  * :mod:`aifc`
-  * :mod:`audioop`
-  * :mod:`cgi`
-  * :mod:`cgitb`
-  * :mod:`chunk`
-  * :mod:`crypt`
-  * :mod:`imghdr`
-  * :mod:`mailcap`
-  * :mod:`msilib`
-  * :mod:`nis`
-  * :mod:`nntplib`
-  * :mod:`ossaudiodev`
-  * :mod:`pipes`
-  * :mod:`sndhdr`
-  * :mod:`spwd`
-  * :mod:`sunau`
-  * :mod:`telnetlib`
-  * :mod:`uu`
-  * :mod:`xdrlib`
-
-  (Contributed by Brett Cannon in :issue:`47061` and Victor Stinner in
-  :gh:`68966`.)
+* Stricter rules will now be applied for numerical group references
+  and group names in :ref:`regular expressions <re-syntax>`.
+  Only sequences of ASCII digits will now be accepted as a numerical reference,
+  and the group name in :class:`bytes` patterns and replacement strings
+  can only contain ASCII letters, digits and underscores.
+  For now, a deprecation warning is raised for syntax violating these rules.
+  (Contributed by Serhiy Storchaka in :gh:`91760`.)
 
-* The :mod:`asynchat`, :mod:`asyncore` and  :mod:`smtpd` modules have been
-  deprecated since at least Python 3.6. Their documentation and deprecation
-  warnings have now been updated to note they will removed in Python 3.12.
-  (Contributed by Hugo van Kemenade in :issue:`47022`.)
+* In the :mod:`re` module, the :func:`!re.template` function
+  and the corresponding :data:`!re.TEMPLATE` and :data:`!re.T` flags
+  are deprecated, as they were undocumented and lacked an obvious purpose.
+  They will be removed in Python 3.13.
+  (Contributed by Serhiy Storchaka and Miro Hronok in :gh:`92728`.)
 
-* More strict rules will be applied now applied for numerical group references
-  and group names in regular expressions in future Python versions.
-  Only sequence of ASCII digits will be now accepted as a numerical reference.
-  The group name in bytes patterns and replacement strings could only
-  contain ASCII letters and digits and underscore.
-  For now, a deprecation warning is raised for such syntax.
-  (Contributed by Serhiy Storchaka in :gh:`91760`.)
+* :func:`turtle.settiltangle` has been deprecated since Python 3.1;
+  it now emits a deprecation warning and will be removed in Python 3.13. Use
+  :func:`turtle.tiltangle` instead (it was earlier incorrectly marked
+  as deprecated, and its docstring is now corrected).
+  (Contributed by Hugo van Kemenade in :issue:`45837`.)
 
 * :class:`typing.Text`, which exists solely to provide compatibility support
   between Python 2 and Python 3 code, is now deprecated. Its removal is
@@ -1674,14 +1807,32 @@ Deprecated C APIs are :ref:`listed separately <whatsnew311-c-api-deprecated>`.
   wherever possible.
   (Contributed by Alex Waygood in :gh:`92332`.)
 
-* The keyword argument syntax for constructing :data:`~typing.TypedDict` types
+* The keyword argument syntax for constructing :data:`typing.TypedDict` types
   is now deprecated. Support will be removed in Python 3.13. (Contributed by
   Jingchen Ye in :gh:`90224`.)
 
-* The :func:`re.template` function and the corresponding :const:`re.TEMPLATE`
-  and :const:`re.T` flags are deprecated, as they were undocumented and
-  lacked an obvious purpose. They will be removed in Python 3.13.
-  (Contributed by Serhiy Storchaka and Miro Hronok in :gh:`92728`.)
+* :class:`!webbrowser.MacOSX` is deprecated and will be removed in Python 3.13.
+  It is untested, undocumented, and not used by :mod:`webbrowser` itself.
+  (Contributed by Dong-hee Na in :issue:`42255`.)
+
+* The behavior of returning a value from a :class:`~unittest.TestCase` and
+  :class:`~unittest.IsolatedAsyncioTestCase` test methods (other than the
+  default ``None`` value) is now deprecated.
+
+* Deprecated the following not-formally-documented :mod:`unittest` functions,
+  scheduled for removal in Python 3.13:
+
+  * :func:`!unittest.findTestCases`
+  * :func:`!unittest.makeSuite`
+  * :func:`!unittest.getTestCaseNames`
+
+  Use :class:`~unittest.TestLoader` methods instead:
+
+  * :meth:`unittest.TestLoader.loadTestsFromModule`
+  * :meth:`unittest.TestLoader.loadTestsFromTestCase`
+  * :meth:`unittest.TestLoader.getTestCaseNames`
+
+  (Contributed by Erlend E. Aasland in :issue:`5846`.)
 
 
 .. _whatsnew311-pending-removal:
@@ -1696,33 +1847,56 @@ and will be removed in Python 3.12.
 C APIs pending removal are
 :ref:`listed separately <whatsnew311-c-api-pending-removal>`.
 
-* :class:`pkgutil.ImpImporter`
-* :class:`pkgutil.ImpLoader`
-* :envvar:`PYTHONTHREADDEBUG`
+* The :mod:`asynchat` module
+* The :mod:`asyncore` module
+* The :ref:`entire distutils package <distutils-deprecated>`
+* The :mod:`imp` module
+* The :class:`typing.io <typing.IO>` namespace
+* The :class:`typing.re <typing.Pattern>` namespace
+* :func:`!cgi.log`
 * :func:`importlib.find_loader`
-* :func:`importlib.util.module_for_loader`
-* :func:`importlib.util.set_loader_wrapper`
-* :func:`importlib.util.set_package_wrapper`
 * :meth:`importlib.abc.Loader.module_repr`
-* :meth:`importlib.abc.Loadermodule_repr`
-* :meth:`importlib.abc.MetaPathFinder.find_module`
 * :meth:`importlib.abc.MetaPathFinder.find_module`
 * :meth:`importlib.abc.PathEntryFinder.find_loader`
 * :meth:`importlib.abc.PathEntryFinder.find_module`
-* :meth:`importlib.machinery.BuiltinImporter.find_module`
-* :meth:`importlib.machinery.BuiltinLoader.module_repr`
-* :meth:`importlib.machinery.FileFinder.find_loader`
-* :meth:`importlib.machinery.FileFinder.find_module`
-* :meth:`importlib.machinery.FrozenImporter.find_module`
-* :meth:`importlib.machinery.FrozenLoader.module_repr`
+* :meth:`!importlib.machinery.BuiltinImporter.find_module`
+* :meth:`!importlib.machinery.BuiltinLoader.module_repr`
+* :meth:`!importlib.machinery.FileFinder.find_loader`
+* :meth:`!importlib.machinery.FileFinder.find_module`
+* :meth:`!importlib.machinery.FrozenImporter.find_module`
+* :meth:`!importlib.machinery.FrozenLoader.module_repr`
 * :meth:`importlib.machinery.PathFinder.find_module`
-* :meth:`importlib.machinery.WindowsRegistryFinder.find_module`
+* :meth:`!importlib.machinery.WindowsRegistryFinder.find_module`
+* :func:`importlib.util.module_for_loader`
+* :func:`!importlib.util.set_loader_wrapper`
+* :func:`!importlib.util.set_package_wrapper`
+* :class:`pkgutil.ImpImporter`
+* :class:`pkgutil.ImpLoader`
 * :meth:`pathlib.Path.link_to`
-* The entire :ref:`distutils namespace <distutils-deprecated>`
-* :func:`cgi.log`
-* :func:`sqlite3.OptimizedUnicode`
-* :func:`sqlite3.enable_shared_cache`
-
+* :func:`!sqlite3.enable_shared_cache`
+* :func:`!sqlite3.OptimizedUnicode`
+* :envvar:`PYTHONTHREADDEBUG` environment variable
+* The following deprecated aliases in :mod:`unittest`:
+
+    ============================ =============================== ===============
+       Deprecated alias           Method Name                     Deprecated in
+    ============================ =============================== ===============
+     ``failUnless``               :meth:`.assertTrue`             3.1
+     ``failIf``                   :meth:`.assertFalse`            3.1
+     ``failUnlessEqual``          :meth:`.assertEqual`            3.1
+     ``failIfEqual``              :meth:`.assertNotEqual`         3.1
+     ``failUnlessAlmostEqual``    :meth:`.assertAlmostEqual`      3.1
+     ``failIfAlmostEqual``        :meth:`.assertNotAlmostEqual`   3.1
+     ``failUnlessRaises``         :meth:`.assertRaises`           3.1
+     ``assert_``                  :meth:`.assertTrue`             3.2
+     ``assertEquals``             :meth:`.assertEqual`            3.2
+     ``assertNotEquals``          :meth:`.assertNotEqual`         3.2
+     ``assertAlmostEquals``       :meth:`.assertAlmostEqual`      3.2
+     ``assertNotAlmostEquals``    :meth:`.assertNotAlmostEqual`   3.2
+     ``assertRegexpMatches``      :meth:`.assertRegex`            3.2
+     ``assertRaisesRegexp``       :meth:`.assertRaisesRegex`      3.2
+     ``assertNotRegexpMatches``   :meth:`.assertNotRegex`         3.5
+    ============================ =============================== ===============
 
 .. _whatsnew311-removed:
 .. _whatsnew311-python-api-removed:
@@ -1730,7 +1904,7 @@ C APIs pending removal are
 Removed
 =======
 
-This section lists Python APIs that have been removed in Python 3.12.
+This section lists Python APIs that have been removed in Python 3.11.
 
 Removed C APIs are :ref:`listed separately <whatsnew311-c-api-removed>`.
 
diff --git a/Doc/whatsnew/3.6.rst b/Doc/whatsnew/3.6.rst
index 70e4525865..f138fa5c0e 100644
--- a/Doc/whatsnew/3.6.rst
+++ b/Doc/whatsnew/3.6.rst
@@ -2052,6 +2052,8 @@ tkinter
 The :mod:`tkinter.tix` module is now deprecated.  :mod:`tkinter` users
 should use :mod:`tkinter.ttk` instead.
 
+.. _whatsnew36-venv:
+
 venv
 ~~~~
 
diff --git a/Doc/whatsnew/3.8.rst b/Doc/whatsnew/3.8.rst
index 7f85ff3ffa..4e2dbe3b53 100644
--- a/Doc/whatsnew/3.8.rst
+++ b/Doc/whatsnew/3.8.rst
@@ -122,8 +122,8 @@ Positional-only parameters
 There is a new function parameter syntax ``/`` to indicate that some
 function parameters must be specified positionally and cannot be used as
 keyword arguments.  This is the same notation shown by ``help()`` for C
-functions annotated with Larry Hastings' `Argument Clinic
-<https://docs.python.org/3/howto/clinic.html>`_ tool.
+functions annotated with Larry Hastings'
+:ref:`Argument Clinic <howto-clinic>` tool.
 
 In the following example, parameters *a* and *b* are positional-only,
 while *c* or *d* can be positional or keyword, and *e* or *f* are
diff --git a/Include/dynamic_annotations.h b/Include/dynamic_annotations.h
index 0bd1a833c2..4d4def9bf8 100644
--- a/Include/dynamic_annotations.h
+++ b/Include/dynamic_annotations.h
@@ -44,7 +44,7 @@
    Actual implementation of these macros may differ depending on the
    dynamic analysis tool being used.
 
-   See http://code.google.com/p/data-race-test/  for more information.
+   See https://code.google.com/p/data-race-test/  for more information.
 
    This file supports the following dynamic analysis tools:
    - None (DYNAMIC_ANNOTATIONS_ENABLED is not defined or zero).
@@ -140,7 +140,7 @@
      of the mutex's critical sections individually using the annotations above.
      This annotation makes sense only for hybrid race detectors. For pure
      happens-before detectors this is a no-op. For more details see
-     http://code.google.com/p/data-race-test/wiki/PureHappensBeforeVsHybrid . */
+     https://code.google.com/p/data-race-test/wiki/PureHappensBeforeVsHybrid . */
 #define _Py_ANNOTATE_PURE_HAPPENS_BEFORE_MUTEX(mu) \
     AnnotateMutexIsUsedAsCondVar(__FILE__, __LINE__, mu)
 
diff --git a/Include/patchlevel.h b/Include/patchlevel.h
index 627401409a..c37154baa2 100644
--- a/Include/patchlevel.h
+++ b/Include/patchlevel.h
@@ -23,7 +23,7 @@
 #define PY_RELEASE_SERIAL       0
 
 /* Version as a string */
-#define PY_VERSION              "3.11.0"
+#define PY_VERSION              "3.11.0+"
 /*--end constants--*/
 
 /* Version as a single 4-byte hex number, e.g. 0x010502B2 == 1.5.2b2.
diff --git a/LICENSE b/LICENSE
index 02a5145f0e..9838d443f9 100644
--- a/LICENSE
+++ b/LICENSE
@@ -2,12 +2,12 @@ A. HISTORY OF THE SOFTWARE
 ==========================
 
 Python was created in the early 1990s by Guido van Rossum at Stichting
-Mathematisch Centrum (CWI, see http://www.cwi.nl) in the Netherlands
+Mathematisch Centrum (CWI, see https://www.cwi.nl) in the Netherlands
 as a successor of a language called ABC.  Guido remains Python's
 principal author, although it includes many contributions from others.
 
 In 1995, Guido continued his work on Python at the Corporation for
-National Research Initiatives (CNRI, see http://www.cnri.reston.va.us)
+National Research Initiatives (CNRI, see https://www.cnri.reston.va.us)
 in Reston, Virginia where he released several versions of the
 software.
 
@@ -19,7 +19,7 @@ https://www.python.org/psf/) was formed, a non-profit organization
 created specifically to own Python-related Intellectual Property.
 Zope Corporation was a sponsoring member of the PSF.
 
-All Python releases are Open Source (see http://www.opensource.org for
+All Python releases are Open Source (see https://opensource.org for
 the Open Source Definition).  Historically, most, but not all, Python
 releases have also been GPL-compatible; the table below summarizes
 the various releases.
diff --git a/Lib/ast.py b/Lib/ast.py
index b0e1c41709..8c10d08002 100644
--- a/Lib/ast.py
+++ b/Lib/ast.py
@@ -53,10 +53,12 @@ def parse(source, filename='<unknown>', mode='exec', *,
 
 def literal_eval(node_or_string):
     """
-    Safely evaluate an expression node or a string containing a Python
+    Evaluate an expression node or a string containing only a Python
     expression.  The string or node provided may only consist of the following
     Python literal structures: strings, bytes, numbers, tuples, lists, dicts,
     sets, booleans, and None.
+
+    Caution: A complex expression can overflow the C stack and cause a crash.
     """
     if isinstance(node_or_string, str):
         node_or_string = parse(node_or_string.lstrip(" \t"), mode='eval')
diff --git a/Lib/asyncio/base_events.py b/Lib/asyncio/base_events.py
index fa00bf9a2c..9b8167d7a1 100644
--- a/Lib/asyncio/base_events.py
+++ b/Lib/asyncio/base_events.py
@@ -577,9 +577,11 @@ async def shutdown_default_executor(self):
     def _do_shutdown(self, future):
         try:
             self._default_executor.shutdown(wait=True)
-            self.call_soon_threadsafe(future.set_result, None)
+            if not self.is_closed():
+                self.call_soon_threadsafe(future.set_result, None)
         except Exception as ex:
-            self.call_soon_threadsafe(future.set_exception, ex)
+            if not self.is_closed():
+                self.call_soon_threadsafe(future.set_exception, ex)
 
     def _check_running(self):
         if self.is_running():
@@ -593,12 +595,13 @@ def run_forever(self):
         self._check_closed()
         self._check_running()
         self._set_coroutine_origin_tracking(self._debug)
-        self._thread_id = threading.get_ident()
 
         old_agen_hooks = sys.get_asyncgen_hooks()
-        sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,
-                               finalizer=self._asyncgen_finalizer_hook)
         try:
+            self._thread_id = threading.get_ident()
+            sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,
+                                   finalizer=self._asyncgen_finalizer_hook)
+
             events._set_running_loop(self)
             while True:
                 self._run_once()
diff --git a/Lib/asyncio/base_subprocess.py b/Lib/asyncio/base_subprocess.py
index 14d5051922..e15bb4141f 100644
--- a/Lib/asyncio/base_subprocess.py
+++ b/Lib/asyncio/base_subprocess.py
@@ -215,13 +215,11 @@ def _process_exited(self, returncode):
             # object. On Python 3.6, it is required to avoid a ResourceWarning.
             self._proc.returncode = returncode
         self._call(self._protocol.process_exited)
-        self._try_finish()
+        for p in self._pipes.values():
+            if p is not None:
+                p.pipe.close()
 
-        # wake up futures waiting for wait()
-        for waiter in self._exit_waiters:
-            if not waiter.cancelled():
-                waiter.set_result(returncode)
-        self._exit_waiters = None
+        self._try_finish()
 
     async def _wait(self):
         """Wait until the process exit and return the process return code.
@@ -247,6 +245,11 @@ def _call_connection_lost(self, exc):
         try:
             self._protocol.connection_lost(exc)
         finally:
+            # wake up futures waiting for wait()
+            for waiter in self._exit_waiters:
+                if not waiter.cancelled():
+                    waiter.set_result(self._returncode)
+            self._exit_waiters = None
             self._loop = None
             self._proc = None
             self._protocol = None
diff --git a/Lib/asyncio/futures.py b/Lib/asyncio/futures.py
index be2458acb9..3a6b44a091 100644
--- a/Lib/asyncio/futures.py
+++ b/Lib/asyncio/futures.py
@@ -398,6 +398,8 @@ def _call_set_state(source):
         if dest_loop is None or dest_loop is source_loop:
             _set_state(destination, source)
         else:
+            if dest_loop.is_closed():
+                return
             dest_loop.call_soon_threadsafe(_set_state, destination, source)
 
     destination.add_done_callback(_call_check_cancel)
diff --git a/Lib/asyncio/proactor_events.py b/Lib/asyncio/proactor_events.py
index ddb9daca02..c6aab408fc 100644
--- a/Lib/asyncio/proactor_events.py
+++ b/Lib/asyncio/proactor_events.py
@@ -60,6 +60,7 @@ def __init__(self, loop, sock, protocol, waiter=None,
         self._pending_write = 0
         self._conn_lost = 0
         self._closing = False  # Set when close() called.
+        self._called_connection_lost = False
         self._eof_written = False
         if self._server is not None:
             self._server._attach()
@@ -136,7 +137,7 @@ def _force_close(self, exc):
                 self._empty_waiter.set_result(None)
             else:
                 self._empty_waiter.set_exception(exc)
-        if self._closing:
+        if self._closing and self._called_connection_lost:
             return
         self._closing = True
         self._conn_lost += 1
@@ -151,6 +152,8 @@ def _force_close(self, exc):
         self._loop.call_soon(self._call_connection_lost, exc)
 
     def _call_connection_lost(self, exc):
+        if self._called_connection_lost:
+            return
         try:
             self._protocol.connection_lost(exc)
         finally:
@@ -166,6 +169,7 @@ def _call_connection_lost(self, exc):
             if server is not None:
                 server._detach()
                 self._server = None
+            self._called_connection_lost = True
 
     def get_write_buffer_size(self):
         size = self._pending_write
diff --git a/Lib/asyncio/sslproto.py b/Lib/asyncio/sslproto.py
index de00953cc1..5cb5cd3588 100644
--- a/Lib/asyncio/sslproto.py
+++ b/Lib/asyncio/sslproto.py
@@ -107,8 +107,11 @@ def close(self):
         protocol's connection_lost() method will (eventually) called
         with None as its argument.
         """
-        self._closed = True
-        self._ssl_protocol._start_shutdown()
+        if not self._closed:
+            self._closed = True
+            self._ssl_protocol._start_shutdown()
+        else:
+            self._ssl_protocol = None
 
     def __del__(self, _warnings=warnings):
         if not self._closed:
diff --git a/Lib/asyncio/taskgroups.py b/Lib/asyncio/taskgroups.py
index 5d5e2a8a85..911419e176 100644
--- a/Lib/asyncio/taskgroups.py
+++ b/Lib/asyncio/taskgroups.py
@@ -128,11 +128,11 @@ async def __aexit__(self, et, exc, tb):
             # Exceptions are heavy objects that can have object
             # cycles (bad for GC); let's not keep a reference to
             # a bunch of them.
-            errors = self._errors
-            self._errors = None
-
-            me = BaseExceptionGroup('unhandled errors in a TaskGroup', errors)
-            raise me from None
+            try:
+                me = BaseExceptionGroup('unhandled errors in a TaskGroup', self._errors)
+                raise me from None
+            finally:
+                self._errors = None
 
     def create_task(self, coro, *, name=None, context=None):
         if not self._entered:
diff --git a/Lib/asyncio/unix_events.py b/Lib/asyncio/unix_events.py
index cf7683fee6..0495f332f3 100644
--- a/Lib/asyncio/unix_events.py
+++ b/Lib/asyncio/unix_events.py
@@ -223,7 +223,8 @@ async def _make_subprocess_transport(self, protocol, args, shell,
         return transp
 
     def _child_watcher_callback(self, pid, returncode, transp):
-        self.call_soon_threadsafe(transp._process_exited, returncode)
+        # Skip one iteration for callbacks to be executed
+        self.call_soon_threadsafe(self.call_soon, transp._process_exited, returncode)
 
     async def create_unix_connection(
             self, protocol_factory, path=None, *,
@@ -799,12 +800,11 @@ class _UnixSubprocessTransport(base_subprocess.BaseSubprocessTransport):
 
     def _start(self, args, shell, stdin, stdout, stderr, bufsize, **kwargs):
         stdin_w = None
-        if stdin == subprocess.PIPE:
-            # Use a socket pair for stdin, since not all platforms
+        if stdin == subprocess.PIPE and sys.platform.startswith('aix'):
+            # Use a socket pair for stdin on AIX, since it does not
             # support selecting read events on the write end of a
             # socket (which we use in order to detect closing of the
-            # other end).  Notably this is needed on AIX, and works
-            # just fine on other platforms.
+            # other end).
             stdin, stdin_w = socket.socketpair()
         try:
             self._proc = subprocess.Popen(
diff --git a/Lib/codecs.py b/Lib/codecs.py
index e6ad6e3a05..3b173b6121 100644
--- a/Lib/codecs.py
+++ b/Lib/codecs.py
@@ -878,7 +878,8 @@ def open(filename, mode='r', encoding=None, errors='strict', buffering=-1):
         codecs. Output is also codec dependent and will usually be
         Unicode as well.
 
-        Underlying encoded files are always opened in binary mode.
+        If encoding is not None, then the
+        underlying encoded files are always opened in binary mode.
         The default file mode is 'r', meaning to open the file in read mode.
 
         encoding specifies the encoding which is to be used for the
diff --git a/Lib/codeop.py b/Lib/codeop.py
index 45a378baba..2213b69f23 100644
--- a/Lib/codeop.py
+++ b/Lib/codeop.py
@@ -56,22 +56,22 @@ def _maybe_compile(compiler, source, filename, symbol):
         if symbol != "eval":
             source = "pass"     # Replace it with a 'pass' statement
 
-    try:
-        return compiler(source, filename, symbol)
-    except SyntaxError:  # Let other compile() errors propagate.
-        pass
-
-    # Catch syntax warnings after the first compile
-    # to emit warnings (SyntaxWarning, DeprecationWarning) at most once.
+    # Disable compiler warnings when checking for incomplete input.
     with warnings.catch_warnings():
-        warnings.simplefilter("error")
-
+        warnings.simplefilter("ignore", (SyntaxWarning, DeprecationWarning))
         try:
-            compiler(source + "\n", filename, symbol)
-        except SyntaxError as e:
-            if "incomplete input" in str(e):
+            compiler(source, filename, symbol)
+        except SyntaxError:  # Let other compile() errors propagate.
+            try:
+                compiler(source + "\n", filename, symbol)
                 return None
-            raise
+            except SyntaxError as e:
+                if "incomplete input" in str(e):
+                    return None
+                # fallthrough
+
+    return compiler(source, filename, symbol)
+
 
 def _is_syntax_error(err1, err2):
     rep1 = repr(err1)
diff --git a/Lib/dataclasses.py b/Lib/dataclasses.py
index a567a33d64..37e4ff702d 100644
--- a/Lib/dataclasses.py
+++ b/Lib/dataclasses.py
@@ -412,13 +412,11 @@ def wrapper(self):
 
 def _create_fn(name, args, body, *, globals=None, locals=None,
                return_type=MISSING):
-    # Note that we mutate locals when exec() is called.  Caller
-    # beware!  The only callers are internal to this module, so no
+    # Note that we may mutate locals. Callers beware!
+    # The only callers are internal to this module, so no
     # worries about external callers.
     if locals is None:
         locals = {}
-    if 'BUILTINS' not in locals:
-        locals['BUILTINS'] = builtins
     return_annotation = ''
     if return_type is not MISSING:
         locals['_return_type'] = return_type
@@ -444,7 +442,7 @@ def _field_assign(frozen, name, value, self_name):
     # self_name is what "self" is called in this function: don't
     # hard-code "self", since that might be a field name.
     if frozen:
-        return f'BUILTINS.object.__setattr__({self_name},{name!r},{value})'
+        return f'__dataclass_builtins_object__.__setattr__({self_name},{name!r},{value})'
     return f'{self_name}.{name}={value}'
 
 
@@ -551,6 +549,7 @@ def _init_fn(fields, std_fields, kw_only_fields, frozen, has_post_init,
     locals.update({
         'MISSING': MISSING,
         '_HAS_DEFAULT_FACTORY': _HAS_DEFAULT_FACTORY,
+        '__dataclass_builtins_object__': object,
     })
 
     body_lines = []
diff --git a/Lib/datetime.py b/Lib/datetime.py
index 00ded32cc3..c3c2568f98 100644
--- a/Lib/datetime.py
+++ b/Lib/datetime.py
@@ -1030,7 +1030,11 @@ def ctime(self):
             self._day, self._year)
 
     def strftime(self, fmt):
-        "Format using strftime()."
+        """
+        Format using strftime().
+
+        Example: "%d/%m/%Y, %H:%M:%S"
+        """
         return _wrap_strftime(self, fmt, self.timetuple())
 
     def __format__(self, fmt):
diff --git a/Lib/distutils/tests/test_sysconfig.py b/Lib/distutils/tests/test_sysconfig.py
index d1c472794c..6833d22af5 100644
--- a/Lib/distutils/tests/test_sysconfig.py
+++ b/Lib/distutils/tests/test_sysconfig.py
@@ -49,6 +49,7 @@ def test_get_config_vars(self):
         self.assertIsInstance(cvars, dict)
         self.assertTrue(cvars)
 
+    @unittest.skipIf(is_wasi, "Incompatible with WASI mapdir and OOT builds")
     def test_srcdir(self):
         # See Issues #15322, #15364.
         srcdir = sysconfig.get_config_var('srcdir')
diff --git a/Lib/enum.py b/Lib/enum.py
index ff8f5cc453..ae97334e22 100644
--- a/Lib/enum.py
+++ b/Lib/enum.py
@@ -22,14 +22,14 @@
 
 class nonmember(object):
     """
-    Protects item from becaming an Enum member during class creation.
+    Protects item from becoming an Enum member during class creation.
     """
     def __init__(self, value):
         self.value = value
 
 class member(object):
     """
-    Forces item to became an Enum member during class creation.
+    Forces item to become an Enum member during class creation.
     """
     def __init__(self, value):
         self.value = value
diff --git a/Lib/http/cookiejar.py b/Lib/http/cookiejar.py
index c514e0d382..65c45e2b17 100644
--- a/Lib/http/cookiejar.py
+++ b/Lib/http/cookiejar.py
@@ -1985,7 +1985,7 @@ class MozillaCookieJar(FileCookieJar):
 
     This class differs from CookieJar only in the format it uses to save and
     load cookies to and from a file.  This class uses the Mozilla/Netscape
-    `cookies.txt' format.  lynx uses this file format, too.
+    `cookies.txt' format.  curl and lynx use this file format, too.
 
     Don't expect cookies saved while the browser is running to be noticed by
     the browser (in fact, Mozilla on unix will overwrite your saved cookies if
diff --git a/Lib/idlelib/NEWS.txt b/Lib/idlelib/NEWS.txt
index 7fa7facf8c..e64e96f75e 100644
--- a/Lib/idlelib/NEWS.txt
+++ b/Lib/idlelib/NEWS.txt
@@ -4,6 +4,11 @@ Released on 2022-10-03
 =========================
 
 
+gh-97527: Fix a bug in the previous bugfix that caused IDLE to not
+start when run with 3.10.8, 3.12.0a1, and at least Microsoft Python
+3.10.2288.0 installed without the Lib/test package.  3.11.0 was never
+affected.
+
 gh-65802: Document handling of extensions in Save As dialogs.
 
 gh-95191: Include prompts when saving Shell (interactive input/output).
diff --git a/Lib/idlelib/config_key.py b/Lib/idlelib/config_key.py
index 9ca3a156f4..bb07231cd5 100644
--- a/Lib/idlelib/config_key.py
+++ b/Lib/idlelib/config_key.py
@@ -41,32 +41,22 @@ def translate_key(key, modifiers):
     return f'Key-{key}'
 
 
-class GetKeysDialog(Toplevel):
+class GetKeysFrame(Frame):
 
     # Dialog title for invalid key sequence
     keyerror_title = 'Key Sequence Error'
 
-    def __init__(self, parent, title, action, current_key_sequences,
-                 *, _htest=False, _utest=False):
+    def __init__(self, parent, action, current_key_sequences):
         """
         parent - parent of this dialog
-        title - string which is the title of the popup dialog
-        action - string, the name of the virtual event these keys will be
+        action - the name of the virtual event these keys will be
                  mapped to
-        current_key_sequences - list, a list of all key sequence lists
+        current_key_sequences - a list of all key sequence lists
                  currently mapped to virtual events, for overlap checking
-        _htest - bool, change box location when running htest
-        _utest - bool, do not wait when running unittest
         """
-        Toplevel.__init__(self, parent)
-        self.withdraw()  # Hide while setting geometry.
-        self.configure(borderwidth=5)
-        self.resizable(height=False, width=False)
-        self.title(title)
-        self.transient(parent)
-        _setup_dialog(self)
-        self.grab_set()
-        self.protocol("WM_DELETE_WINDOW", self.cancel)
+        super().__init__(parent)
+        self['borderwidth'] = 2
+        self['relief'] = 'sunken'
         self.parent = parent
         self.action = action
         self.current_key_sequences = current_key_sequences
@@ -82,39 +72,14 @@ def __init__(self, parent, title, action, current_key_sequences,
             self.modifier_vars.append(variable)
         self.advanced = False
         self.create_widgets()
-        self.update_idletasks()
-        self.geometry(
-                "+%d+%d" % (
-                    parent.winfo_rootx() +
-                    (parent.winfo_width()/2 - self.winfo_reqwidth()/2),
-                    parent.winfo_rooty() +
-                    ((parent.winfo_height()/2 - self.winfo_reqheight()/2)
-                    if not _htest else 150)
-                ) )  # Center dialog over parent (or below htest box).
-        if not _utest:
-            self.deiconify()  # Geometry set, unhide.
-            self.wait_window()
 
     def showerror(self, *args, **kwargs):
         # Make testing easier.  Replace in #30751.
         messagebox.showerror(*args, **kwargs)
 
     def create_widgets(self):
-        self.frame = frame = Frame(self, borderwidth=2, relief='sunken')
-        frame.pack(side='top', expand=True, fill='both')
-
-        frame_buttons = Frame(self)
-        frame_buttons.pack(side='bottom', fill='x')
-
-        self.button_ok = Button(frame_buttons, text='OK',
-                                width=8, command=self.ok)
-        self.button_ok.grid(row=0, column=0, padx=5, pady=5)
-        self.button_cancel = Button(frame_buttons, text='Cancel',
-                                   width=8, command=self.cancel)
-        self.button_cancel.grid(row=0, column=1, padx=5, pady=5)
-
         # Basic entry key sequence.
-        self.frame_keyseq_basic = Frame(frame, name='keyseq_basic')
+        self.frame_keyseq_basic = Frame(self, name='keyseq_basic')
         self.frame_keyseq_basic.grid(row=0, column=0, sticky='nsew',
                                       padx=5, pady=5)
         basic_title = Label(self.frame_keyseq_basic,
@@ -127,7 +92,7 @@ def create_widgets(self):
         basic_keys.pack(ipadx=5, ipady=5, fill='x')
 
         # Basic entry controls.
-        self.frame_controls_basic = Frame(frame)
+        self.frame_controls_basic = Frame(self)
         self.frame_controls_basic.grid(row=1, column=0, sticky='nsew', padx=5)
 
         # Basic entry modifiers.
@@ -169,7 +134,7 @@ def create_widgets(self):
         self.button_clear.grid(row=2, column=0, columnspan=4)
 
         # Advanced entry key sequence.
-        self.frame_keyseq_advanced = Frame(frame, name='keyseq_advanced')
+        self.frame_keyseq_advanced = Frame(self, name='keyseq_advanced')
         self.frame_keyseq_advanced.grid(row=0, column=0, sticky='nsew',
                                          padx=5, pady=5)
         advanced_title = Label(self.frame_keyseq_advanced, justify='left',
@@ -181,7 +146,7 @@ def create_widgets(self):
         self.advanced_keys.pack(fill='x')
 
         # Advanced entry help text.
-        self.frame_help_advanced = Frame(frame)
+        self.frame_help_advanced = Frame(self)
         self.frame_help_advanced.grid(row=1, column=0, sticky='nsew', padx=5)
         help_advanced = Label(self.frame_help_advanced, justify='left',
             text="Key bindings are specified using Tkinter keysyms as\n"+
@@ -196,7 +161,7 @@ def create_widgets(self):
         help_advanced.grid(row=0, column=0, sticky='nsew')
 
         # Switch between basic and advanced.
-        self.button_level = Button(frame, command=self.toggle_level,
+        self.button_level = Button(self, command=self.toggle_level,
                                   text='<< Basic Key Binding Entry')
         self.button_level.grid(row=2, column=0, stick='ew', padx=5, pady=5)
         self.toggle_level()
@@ -257,7 +222,8 @@ def clear_key_seq(self):
             variable.set('')
         self.key_string.set('')
 
-    def ok(self, event=None):
+    def ok(self):
+        self.result = ''
         keys = self.key_string.get().strip()
         if not keys:
             self.showerror(title=self.keyerror_title, parent=self,
@@ -265,13 +231,7 @@ def ok(self, event=None):
             return
         if (self.advanced or self.keys_ok(keys)) and self.bind_ok(keys):
             self.result = keys
-        self.grab_release()
-        self.destroy()
-
-    def cancel(self, event=None):
-        self.result = ''
-        self.grab_release()
-        self.destroy()
+        return
 
     def keys_ok(self, keys):
         """Validity check on user's 'basic' keybinding selection.
@@ -319,6 +279,73 @@ def bind_ok(self, keys):
             return True
 
 
+class GetKeysWindow(Toplevel):
+
+    def __init__(self, parent, title, action, current_key_sequences,
+                 *, _htest=False, _utest=False):
+        """
+        parent - parent of this dialog
+        title - string which is the title of the popup dialog
+        action - string, the name of the virtual event these keys will be
+                 mapped to
+        current_key_sequences - list, a list of all key sequence lists
+                 currently mapped to virtual events, for overlap checking
+        _htest - bool, change box location when running htest
+        _utest - bool, do not wait when running unittest
+        """
+        super().__init__(parent)
+        self.withdraw()  # Hide while setting geometry.
+        self['borderwidth'] = 5
+        self.resizable(height=False, width=False)
+        # Needed for winfo_reqwidth().
+        self.update_idletasks()
+        # Center dialog over parent (or below htest box).
+        x = (parent.winfo_rootx() +
+             (parent.winfo_width()//2 - self.winfo_reqwidth()//2))
+        y = (parent.winfo_rooty() +
+             ((parent.winfo_height()//2 - self.winfo_reqheight()//2)
+              if not _htest else 150))
+        self.geometry(f"+{x}+{y}")
+
+        self.title(title)
+        self.frame = frame = GetKeysFrame(self, action, current_key_sequences)
+        self.protocol("WM_DELETE_WINDOW", self.cancel)
+        frame_buttons = Frame(self)
+        self.button_ok = Button(frame_buttons, text='OK',
+                                width=8, command=self.ok)
+        self.button_cancel = Button(frame_buttons, text='Cancel',
+                                   width=8, command=self.cancel)
+        self.button_ok.grid(row=0, column=0, padx=5, pady=5)
+        self.button_cancel.grid(row=0, column=1, padx=5, pady=5)
+        frame.pack(side='top', expand=True, fill='both')
+        frame_buttons.pack(side='bottom', fill='x')
+
+        self.transient(parent)
+        _setup_dialog(self)
+        self.grab_set()
+        if not _utest:
+            self.deiconify()  # Geometry set, unhide.
+            self.wait_window()
+
+    @property
+    def result(self):
+        return self.frame.result
+
+    @result.setter
+    def result(self, value):
+        self.frame.result = value
+
+    def ok(self, event=None):
+        self.frame.ok()
+        self.grab_release()
+        self.destroy()
+
+    def cancel(self, event=None):
+        self.result = ''
+        self.grab_release()
+        self.destroy()
+
+
 if __name__ == '__main__':
     from unittest import main
     main('idlelib.idle_test.test_config_key', verbosity=2, exit=False)
diff --git a/Lib/idlelib/configdialog.py b/Lib/idlelib/configdialog.py
index 8e478d743f..cda7966d55 100644
--- a/Lib/idlelib/configdialog.py
+++ b/Lib/idlelib/configdialog.py
@@ -24,7 +24,7 @@
 from tkinter import messagebox
 
 from idlelib.config import idleConf, ConfigChanges
-from idlelib.config_key import GetKeysDialog
+from idlelib.config_key import GetKeysWindow
 from idlelib.dynoption import DynOptionMenu
 from idlelib import macosx
 from idlelib.query import SectionName, HelpSource
@@ -1397,7 +1397,7 @@ def get_new_keys(self):
             for event in key_set_changes:
                 current_bindings[event] = key_set_changes[event].split()
         current_key_sequences = list(current_bindings.values())
-        new_keys = GetKeysDialog(self, 'Get New Keys', bind_name,
+        new_keys = GetKeysWindow(self, 'Get New Keys', bind_name,
                 current_key_sequences).result
         if new_keys:
             if self.keyset_source.get():  # Current key set is a built-in.
diff --git a/Lib/idlelib/idle_test/test_config_key.py b/Lib/idlelib/idle_test/test_config_key.py
index bf66cadf57..32f878b842 100644
--- a/Lib/idlelib/idle_test/test_config_key.py
+++ b/Lib/idlelib/idle_test/test_config_key.py
@@ -13,15 +13,13 @@
 from idlelib.idle_test.mock_idle import Func
 from idlelib.idle_test.mock_tk import Mbox_func
 
-gkd = config_key.GetKeysDialog
-
 
 class ValidationTest(unittest.TestCase):
     "Test validation methods: ok, keys_ok, bind_ok."
 
-    class Validator(gkd):
+    class Validator(config_key.GetKeysFrame):
         def __init__(self, *args, **kwargs):
-            config_key.GetKeysDialog.__init__(self, *args, **kwargs)
+            super().__init__(*args, **kwargs)
             class list_keys_final:
                 get = Func()
             self.list_keys_final = list_keys_final
@@ -34,15 +32,14 @@ def setUpClass(cls):
         cls.root = Tk()
         cls.root.withdraw()
         keylist = [['<Key-F12>'], ['<Control-Key-x>', '<Control-Key-X>']]
-        cls.dialog = cls.Validator(
-            cls.root, 'Title', '<<Test>>', keylist, _utest=True)
+        cls.dialog = cls.Validator(cls.root, '<<Test>>', keylist)
 
     @classmethod
     def tearDownClass(cls):
-        cls.dialog.cancel()
+        del cls.dialog
         cls.root.update_idletasks()
         cls.root.destroy()
-        del cls.dialog, cls.root
+        del cls.root
 
     def setUp(self):
         self.dialog.showerror.message = ''
@@ -111,14 +108,14 @@ def setUpClass(cls):
         requires('gui')
         cls.root = Tk()
         cls.root.withdraw()
-        cls.dialog = gkd(cls.root, 'Title', '<<Test>>', [], _utest=True)
+        cls.dialog = config_key.GetKeysFrame(cls.root, '<<Test>>', [])
 
     @classmethod
     def tearDownClass(cls):
-        cls.dialog.cancel()
+        del cls.dialog
         cls.root.update_idletasks()
         cls.root.destroy()
-        del cls.dialog, cls.root
+        del cls.root
 
     def test_toggle_level(self):
         dialog = self.dialog
@@ -130,7 +127,7 @@ def stackorder():
             this can be used to check whether a frame is above or
             below another one.
             """
-            for index, child in enumerate(dialog.frame.winfo_children()):
+            for index, child in enumerate(dialog.winfo_children()):
                 if child._name == 'keyseq_basic':
                     basic = index
                 if child._name == 'keyseq_advanced':
@@ -161,7 +158,7 @@ def stackorder():
 class KeySelectionTest(unittest.TestCase):
     "Test selecting key on Basic frames."
 
-    class Basic(gkd):
+    class Basic(config_key.GetKeysFrame):
         def __init__(self, *args, **kwargs):
             super().__init__(*args, **kwargs)
             class list_keys_final:
@@ -179,14 +176,14 @@ def setUpClass(cls):
         requires('gui')
         cls.root = Tk()
         cls.root.withdraw()
-        cls.dialog = cls.Basic(cls.root, 'Title', '<<Test>>', [], _utest=True)
+        cls.dialog = cls.Basic(cls.root, '<<Test>>', [])
 
     @classmethod
     def tearDownClass(cls):
-        cls.dialog.cancel()
+        del cls.dialog
         cls.root.update_idletasks()
         cls.root.destroy()
-        del cls.dialog, cls.root
+        del cls.root
 
     def setUp(self):
         self.dialog.clear_key_seq()
@@ -206,7 +203,7 @@ def test_get_modifiers(self):
         dialog.modifier_checkbuttons['foo'].invoke()
         eq(gm(), ['BAZ'])
 
-    @mock.patch.object(gkd, 'get_modifiers')
+    @mock.patch.object(config_key.GetKeysFrame, 'get_modifiers')
     def test_build_key_string(self, mock_modifiers):
         dialog = self.dialog
         key = dialog.list_keys_final
@@ -227,7 +224,7 @@ def test_build_key_string(self, mock_modifiers):
         dialog.build_key_string()
         eq(string(), '<mymod-test>')
 
-    @mock.patch.object(gkd, 'get_modifiers')
+    @mock.patch.object(config_key.GetKeysFrame, 'get_modifiers')
     def test_final_key_selected(self, mock_modifiers):
         dialog = self.dialog
         key = dialog.list_keys_final
@@ -240,7 +237,7 @@ def test_final_key_selected(self, mock_modifiers):
         eq(string(), '<Shift-Key-braceleft>')
 
 
-class CancelTest(unittest.TestCase):
+class CancelWindowTest(unittest.TestCase):
     "Simulate user clicking [Cancel] button."
 
     @classmethod
@@ -248,21 +245,89 @@ def setUpClass(cls):
         requires('gui')
         cls.root = Tk()
         cls.root.withdraw()
-        cls.dialog = gkd(cls.root, 'Title', '<<Test>>', [], _utest=True)
+        cls.dialog = config_key.GetKeysWindow(
+            cls.root, 'Title', '<<Test>>', [], _utest=True)
 
     @classmethod
     def tearDownClass(cls):
         cls.dialog.cancel()
+        del cls.dialog
         cls.root.update_idletasks()
         cls.root.destroy()
-        del cls.dialog, cls.root
+        del cls.root
 
-    def test_cancel(self):
+    @mock.patch.object(config_key.GetKeysFrame, 'ok')
+    def test_cancel(self, mock_frame_ok):
         self.assertEqual(self.dialog.winfo_class(), 'Toplevel')
         self.dialog.button_cancel.invoke()
         with self.assertRaises(TclError):
             self.dialog.winfo_class()
         self.assertEqual(self.dialog.result, '')
+        mock_frame_ok.assert_not_called()
+
+
+class OKWindowTest(unittest.TestCase):
+    "Simulate user clicking [OK] button."
+
+    @classmethod
+    def setUpClass(cls):
+        requires('gui')
+        cls.root = Tk()
+        cls.root.withdraw()
+        cls.dialog = config_key.GetKeysWindow(
+            cls.root, 'Title', '<<Test>>', [], _utest=True)
+
+    @classmethod
+    def tearDownClass(cls):
+        cls.dialog.cancel()
+        del cls.dialog
+        cls.root.update_idletasks()
+        cls.root.destroy()
+        del cls.root
+
+    @mock.patch.object(config_key.GetKeysFrame, 'ok')
+    def test_ok(self, mock_frame_ok):
+        self.assertEqual(self.dialog.winfo_class(), 'Toplevel')
+        self.dialog.button_ok.invoke()
+        with self.assertRaises(TclError):
+            self.dialog.winfo_class()
+        mock_frame_ok.assert_called()
+
+
+class WindowResultTest(unittest.TestCase):
+    "Test window result get and set."
+
+    @classmethod
+    def setUpClass(cls):
+        requires('gui')
+        cls.root = Tk()
+        cls.root.withdraw()
+        cls.dialog = config_key.GetKeysWindow(
+            cls.root, 'Title', '<<Test>>', [], _utest=True)
+
+    @classmethod
+    def tearDownClass(cls):
+        cls.dialog.cancel()
+        del cls.dialog
+        cls.root.update_idletasks()
+        cls.root.destroy()
+        del cls.root
+
+    def test_result(self):
+        dialog = self.dialog
+        eq = self.assertEqual
+
+        dialog.result = ''
+        eq(dialog.result, '')
+        eq(dialog.frame.result,'')
+
+        dialog.result = 'bar'
+        eq(dialog.result,'bar')
+        eq(dialog.frame.result,'bar')
+
+        dialog.frame.result = 'foo'
+        eq(dialog.result, 'foo')
+        eq(dialog.frame.result,'foo')
 
 
 class HelperTest(unittest.TestCase):
diff --git a/Lib/idlelib/idle_test/test_configdialog.py b/Lib/idlelib/idle_test/test_configdialog.py
index 3005ce08c9..e5d5b4013f 100644
--- a/Lib/idlelib/idle_test/test_configdialog.py
+++ b/Lib/idlelib/idle_test/test_configdialog.py
@@ -954,8 +954,8 @@ def test_set_keys_type(self):
     def test_get_new_keys(self):
         eq = self.assertEqual
         d = self.page
-        orig_getkeysdialog = configdialog.GetKeysDialog
-        gkd = configdialog.GetKeysDialog = Func(return_self=True)
+        orig_getkeysdialog = configdialog.GetKeysWindow
+        gkd = configdialog.GetKeysWindow = Func(return_self=True)
         gnkn = d.get_new_keys_name = Func()
 
         d.button_new_keys.state(('!disabled',))
@@ -997,7 +997,7 @@ def test_get_new_keys(self):
         eq(d.keybinding.get(), '<Key-p>')
 
         del d.get_new_keys_name
-        configdialog.GetKeysDialog = orig_getkeysdialog
+        configdialog.GetKeysWindow = orig_getkeysdialog
 
     def test_get_new_keys_name(self):
         orig_sectionname = configdialog.SectionName
diff --git a/Lib/idlelib/idle_test/test_text.py b/Lib/idlelib/idle_test/test_text.py
index 0f31179e04..43a9ba02c3 100644
--- a/Lib/idlelib/idle_test/test_text.py
+++ b/Lib/idlelib/idle_test/test_text.py
@@ -6,7 +6,7 @@
 from test.support import requires
 from _tkinter import TclError
 
-class TextTest(object):
+class TextTest:
     "Define items common to both sets of tests."
 
     hw = 'hello\nworld'  # Several tests insert this after initialization.
diff --git a/Lib/idlelib/idle_test/test_zzdummy.py b/Lib/idlelib/idle_test/test_zzdummy.py
index 1013cdc3c4..209d8564da 100644
--- a/Lib/idlelib/idle_test/test_zzdummy.py
+++ b/Lib/idlelib/idle_test/test_zzdummy.py
@@ -19,7 +19,7 @@
 }
 code_sample = """\
 
-class C1():
+class C1:
     # Class comment.
     def __init__(self, a, b):
         self.a = a
diff --git a/Lib/idlelib/macosx.py b/Lib/idlelib/macosx.py
index 53848fb079..89b645702d 100644
--- a/Lib/idlelib/macosx.py
+++ b/Lib/idlelib/macosx.py
@@ -14,12 +14,25 @@
 _tk_type = None
 
 def _init_tk_type():
-    """
-    Initializes OS X Tk variant values for
-    isAquaTk(), isCarbonTk(), isCocoaTk(), and isXQuartz().
+    """ Initialize _tk_type for isXyzTk functions.
+
+    This function is only called once, when _tk_type is still None.
     """
     global _tk_type
     if platform == 'darwin':
+
+        # When running IDLE, GUI is present, test/* may not be.
+        # When running tests, test/* is present, GUI may not be.
+        # If not, guess most common.  Does not matter for testing.
+        from idlelib.__init__ import testing
+        if testing:
+            from test.support import requires, ResourceDenied
+            try:
+                requires('gui')
+            except ResourceDenied:
+                _tk_type = "cocoa"
+                return
+
         root = tkinter.Tk()
         ws = root.tk.call('tk', 'windowingsystem')
         if 'x11' in ws:
@@ -33,6 +46,7 @@ def _init_tk_type():
         root.destroy()
     else:
         _tk_type = "other"
+    return
 
 def isAquaTk():
     """
diff --git a/Lib/inspect.py b/Lib/inspect.py
index cbc0632484..5f7574c194 100644
--- a/Lib/inspect.py
+++ b/Lib/inspect.py
@@ -1448,7 +1448,10 @@ def getargvalues(frame):
 
 def formatannotation(annotation, base_module=None):
     if getattr(annotation, '__module__', None) == 'typing':
-        return repr(annotation).replace('typing.', '')
+        def repl(match):
+            text = match.group()
+            return text.removeprefix('typing.')
+        return re.sub(r'[\w\.]+', repl, repr(annotation))
     if isinstance(annotation, types.GenericAlias):
         return str(annotation)
     if isinstance(annotation, type):
diff --git a/Lib/json/__init__.py b/Lib/json/__init__.py
index e4c21daaf3..ed2c74771e 100644
--- a/Lib/json/__init__.py
+++ b/Lib/json/__init__.py
@@ -1,4 +1,4 @@
-r"""JSON (JavaScript Object Notation) <http://json.org> is a subset of
+r"""JSON (JavaScript Object Notation) <https://json.org> is a subset of
 JavaScript syntax (ECMA-262 3rd edition) used as a lightweight data
 interchange format.
 
diff --git a/Lib/json/decoder.py b/Lib/json/decoder.py
index d7d824454e..c5d9ae2d0d 100644
--- a/Lib/json/decoder.py
+++ b/Lib/json/decoder.py
@@ -252,7 +252,7 @@ def JSONArray(s_and_end, scan_once, _w=WHITESPACE.match, _ws=WHITESPACE_STR):
 
 
 class JSONDecoder(object):
-    """Simple JSON <http://json.org> decoder
+    """Simple JSON <https://json.org> decoder
 
     Performs the following translations in decoding by default:
 
diff --git a/Lib/json/encoder.py b/Lib/json/encoder.py
index 864f46d9db..45f5477418 100644
--- a/Lib/json/encoder.py
+++ b/Lib/json/encoder.py
@@ -72,7 +72,7 @@ def replace(match):
     c_encode_basestring_ascii or py_encode_basestring_ascii)
 
 class JSONEncoder(object):
-    """Extensible JSON <http://json.org> encoder for Python data structures.
+    """Extensible JSON <https://json.org> encoder for Python data structures.
 
     Supports the following objects and types by default:
 
diff --git a/Lib/logging/handlers.py b/Lib/logging/handlers.py
index c6853e0513..f5a9760fd4 100644
--- a/Lib/logging/handlers.py
+++ b/Lib/logging/handlers.py
@@ -891,6 +891,13 @@ def _connect_unixsocket(self, address):
                 raise
 
     def createSocket(self):
+        """
+        Try to create a socket and, if it's not a datagram socket, connect it
+        to the other end. This method is called during handler initialization,
+        but it's not regarded as an error if the other end isn't listening yet
+        --- the method will be called again when emitting an event,
+        if there is no socket at that point.
+        """
         address = self.address
         socktype = self.socktype
 
@@ -898,7 +905,7 @@ def createSocket(self):
             self.unixsocket = True
             # Syslog server may be unavailable during handler initialisation.
             # C's openlog() function also ignores connection errors.
-            # Moreover, we ignore these errors while logging, so it not worse
+            # Moreover, we ignore these errors while logging, so it's not worse
             # to ignore it also here.
             try:
                 self._connect_unixsocket(address)
diff --git a/Lib/multiprocessing/resource_tracker.py b/Lib/multiprocessing/resource_tracker.py
index cc42dbdda0..ea36950729 100644
--- a/Lib/multiprocessing/resource_tracker.py
+++ b/Lib/multiprocessing/resource_tracker.py
@@ -161,10 +161,10 @@ def unregister(self, name, rtype):
     def _send(self, cmd, name, rtype):
         self.ensure_running()
         msg = '{0}:{1}:{2}\n'.format(cmd, name, rtype).encode('ascii')
-        if len(name) > 512:
+        if len(msg) > 512:
             # posix guarantees that writes to a pipe of less than PIPE_BUF
             # bytes are atomic, and that PIPE_BUF >= 512
-            raise ValueError('name too long')
+            raise ValueError('msg too long')
         nbytes = os.write(self._fd, msg)
         assert nbytes == len(msg), "nbytes {0:n} but len(msg) {1:n}".format(
             nbytes, len(msg))
diff --git a/Lib/os.py b/Lib/os.py
index 648188e0f1..fd1e774fdc 100644
--- a/Lib/os.py
+++ b/Lib/os.py
@@ -288,7 +288,8 @@ def walk(top, topdown=True, onerror=None, followlinks=False):
         dirpath, dirnames, filenames
 
     dirpath is a string, the path to the directory.  dirnames is a list of
-    the names of the subdirectories in dirpath (excluding '.' and '..').
+    the names of the subdirectories in dirpath (including symlinks to directories,
+    and excluding '.' and '..').
     filenames is a list of the names of the non-directory files in dirpath.
     Note that the names in the lists are just names, with no path components.
     To get a full path (which begins with top) to a file or directory in
diff --git a/Lib/pdb.py b/Lib/pdb.py
index fe8ddd1abb..411ce53115 100755
--- a/Lib/pdb.py
+++ b/Lib/pdb.py
@@ -1332,6 +1332,12 @@ def do_list(self, arg):
         if last is None:
             last = first + 10
         filename = self.curframe.f_code.co_filename
+        # gh-93696: stdlib frozen modules provide a useful __file__
+        # this workaround can be removed with the closure of gh-89815
+        if filename.startswith("<frozen"):
+            tmp = self.curframe.f_globals.get("__file__")
+            if isinstance(tmp, str):
+                filename = tmp
         breaklist = self.get_file_breaks(filename)
         try:
             lines = linecache.getlines(filename, self.curframe.f_globals)
diff --git a/Lib/plistlib.py b/Lib/plistlib.py
index 4862355b22..664890d252 100644
--- a/Lib/plistlib.py
+++ b/Lib/plistlib.py
@@ -152,7 +152,7 @@ def _date_to_string(d):
 def _escape(text):
     m = _controlCharPat.search(text)
     if m is not None:
-        raise ValueError("strings can't contains control characters; "
+        raise ValueError("strings can't contain control characters; "
                          "use bytes instead")
     text = text.replace("\r\n", "\n")       # convert DOS line endings
     text = text.replace("\r", "\n")         # convert Mac line endings
diff --git a/Lib/pstats.py b/Lib/pstats.py
index 8e0743f2e5..80408313e8 100644
--- a/Lib/pstats.py
+++ b/Lib/pstats.py
@@ -57,7 +57,7 @@ def __new__(cls, *values):
 
 @dataclass(unsafe_hash=True)
 class FunctionProfile:
-    ncalls: int
+    ncalls: str
     tottime: float
     percall_tottime: float
     cumtime: float
diff --git a/Lib/pydoc.py b/Lib/pydoc.py
index 434316635d..088a3ba881 100755
--- a/Lib/pydoc.py
+++ b/Lib/pydoc.py
@@ -1998,7 +1998,10 @@ def __repr__(self):
     _GoInteractive = object()
     def __call__(self, request=_GoInteractive):
         if request is not self._GoInteractive:
-            self.help(request)
+            try:
+                self.help(request)
+            except ImportError as e:
+                self.output.write(f'{e}\n')
         else:
             self.intro()
             self.interact()
diff --git a/Lib/random.py b/Lib/random.py
index 1f3530e880..f94616e048 100644
--- a/Lib/random.py
+++ b/Lib/random.py
@@ -282,10 +282,10 @@ def randbytes(self, n):
     ## -------------------- integer methods  -------------------
 
     def randrange(self, start, stop=None, step=_ONE):
-        """Choose a random item from range(start, stop[, step]).
+        """Choose a random item from range(stop) or range(start, stop[, step]).
 
-        This fixes the problem with randint() which includes the
-        endpoint; in Python this is usually not what you want.
+        Roughly equivalent to ``choice(range(start, stop, step))`` but
+        supports arbitrarily large ranges and is optimized for common cases.
 
         """
 
diff --git a/Lib/sndhdr.py b/Lib/sndhdr.py
index 98a7834482..45def9ad16 100644
--- a/Lib/sndhdr.py
+++ b/Lib/sndhdr.py
@@ -77,6 +77,7 @@ def whathdr(filename):
 tests = []
 
 def test_aifc(h, f):
+    """AIFC and AIFF files"""
     with warnings.catch_warnings():
         warnings.simplefilter('ignore', category=DeprecationWarning)
         import aifc
@@ -100,6 +101,7 @@ def test_aifc(h, f):
 
 
 def test_au(h, f):
+    """AU and SND files"""
     if h.startswith(b'.snd'):
         func = get_long_be
     elif h[:4] in (b'\0ds.', b'dns.'):
@@ -133,6 +135,7 @@ def test_au(h, f):
 
 
 def test_hcom(h, f):
+    """HCOM file"""
     if h[65:69] != b'FSSD' or h[128:132] != b'HCOM':
         return None
     divisor = get_long_be(h[144:148])
@@ -146,6 +149,7 @@ def test_hcom(h, f):
 
 
 def test_voc(h, f):
+    """VOC file"""
     if not h.startswith(b'Creative Voice File\032'):
         return None
     sbseek = get_short_le(h[20:22])
@@ -160,6 +164,7 @@ def test_voc(h, f):
 
 
 def test_wav(h, f):
+    """WAV file"""
     import wave
     # 'RIFF' <len> 'WAVE' 'fmt ' <len>
     if not h.startswith(b'RIFF') or h[8:12] != b'WAVE' or h[12:16] != b'fmt ':
@@ -176,6 +181,7 @@ def test_wav(h, f):
 
 
 def test_8svx(h, f):
+    """8SVX file"""
     if not h.startswith(b'FORM') or h[8:12] != b'8SVX':
         return None
     # Should decode it to get #channels -- assume always 1
@@ -185,6 +191,7 @@ def test_8svx(h, f):
 
 
 def test_sndt(h, f):
+    """SNDT file"""
     if h.startswith(b'SOUND'):
         nsamples = get_long_le(h[8:12])
         rate = get_short_le(h[20:22])
@@ -194,6 +201,7 @@ def test_sndt(h, f):
 
 
 def test_sndr(h, f):
+    """SNDR file"""
     if h.startswith(b'\0\0'):
         rate = get_short_le(h[2:4])
         if 4000 <= rate <= 25000:
diff --git a/Lib/socket.py b/Lib/socket.py
index a19652247a..0717c696b1 100644
--- a/Lib/socket.py
+++ b/Lib/socket.py
@@ -254,17 +254,18 @@ def __repr__(self):
                self.type,
                self.proto)
         if not closed:
+            # getsockname and getpeername may not be available on WASI.
             try:
                 laddr = self.getsockname()
                 if laddr:
                     s += ", laddr=%s" % str(laddr)
-            except error:
+            except (error, AttributeError):
                 pass
             try:
                 raddr = self.getpeername()
                 if raddr:
                     s += ", raddr=%s" % str(raddr)
-            except error:
+            except (error, AttributeError):
                 pass
         s += '>'
         return s
diff --git a/Lib/subprocess.py b/Lib/subprocess.py
index 7ae8df154b..9cadd1bf8e 100644
--- a/Lib/subprocess.py
+++ b/Lib/subprocess.py
@@ -456,7 +456,8 @@ def check_output(*popenargs, timeout=None, **kwargs):
     if 'input' in kwargs and kwargs['input'] is None:
         # Explicitly passing input=None was previously equivalent to passing an
         # empty string. That is maintained here for backwards compatibility.
-        if kwargs.get('universal_newlines') or kwargs.get('text'):
+        if kwargs.get('universal_newlines') or kwargs.get('text') or kwargs.get('encoding') \
+                or kwargs.get('errors'):
             empty = ''
         else:
             empty = b''
@@ -508,7 +509,8 @@ def run(*popenargs,
 
     The returned instance will have attributes args, returncode, stdout and
     stderr. By default, stdout and stderr are not captured, and those attributes
-    will be None. Pass stdout=PIPE and/or stderr=PIPE in order to capture them.
+    will be None. Pass stdout=PIPE and/or stderr=PIPE in order to capture them,
+    or pass capture_output=True to capture both.
 
     If check is True and the exit code was non-zero, it raises a
     CalledProcessError. The CalledProcessError object will have the return code
diff --git a/Lib/tabnanny.py b/Lib/tabnanny.py
index 7973f26f98..a47f5a96b8 100755
--- a/Lib/tabnanny.py
+++ b/Lib/tabnanny.py
@@ -23,8 +23,6 @@
 import os
 import sys
 import tokenize
-if not hasattr(tokenize, 'NL'):
-    raise ValueError("tokenize.NL doesn't exist -- tokenize module too old")
 
 __all__ = ["check", "NannyNag", "process_tokens"]
 
diff --git a/Lib/test/_test_multiprocessing.py b/Lib/test/_test_multiprocessing.py
index 599c3f2abf..3117b110db 100644
--- a/Lib/test/_test_multiprocessing.py
+++ b/Lib/test/_test_multiprocessing.py
@@ -5438,6 +5438,14 @@ def test_resource_tracker_reused(self):
 
         self.assertTrue(is_resource_tracker_reused)
 
+    def test_too_long_name_resource(self):
+        # gh-96819: Resource names that will make the length of a write to a pipe
+        # greater than PIPE_BUF are not allowed
+        rtype = "shared_memory"
+        too_long_name_resource = "a" * (512 - len(rtype))
+        with self.assertRaises(ValueError):
+            resource_tracker.register(too_long_name_resource, rtype)
+
 
 class TestSimpleQueue(unittest.TestCase):
 
diff --git a/Lib/test/audit-tests.py b/Lib/test/audit-tests.py
index 00333cc903..fea2f21774 100644
--- a/Lib/test/audit-tests.py
+++ b/Lib/test/audit-tests.py
@@ -419,6 +419,27 @@ def hook(event, args):
     sys._getframe()
 
 
+def test_syslog():
+    import syslog
+
+    def hook(event, args):
+        if event.startswith("syslog."):
+            print(event, *args)
+
+    sys.addaudithook(hook)
+    syslog.openlog('python')
+    syslog.syslog('test')
+    syslog.setlogmask(syslog.LOG_DEBUG)
+    syslog.closelog()
+    # implicit open
+    syslog.syslog('test2')
+    # open with default ident
+    syslog.openlog(logoption=syslog.LOG_NDELAY, facility=syslog.LOG_LOCAL0)
+    sys.argv = None
+    syslog.openlog()
+    syslog.closelog()
+
+
 if __name__ == "__main__":
     from test.support import suppress_msvcrt_asserts
 
diff --git a/Lib/test/clinic.test b/Lib/test/clinic.test
index 9016cffba9..0228d6be03 100644
--- a/Lib/test/clinic.test
+++ b/Lib/test/clinic.test
@@ -1803,12 +1803,12 @@ static PyObject *
 test_Py_UNICODE_converter(PyObject *module, PyObject *const *args, Py_ssize_t nargs)
 {
     PyObject *return_value = NULL;
-    const Py_UNICODE *a;
-    const Py_UNICODE *b;
-    const Py_UNICODE *c;
-    const Py_UNICODE *d;
+    const Py_UNICODE *a = NULL;
+    const Py_UNICODE *b = NULL;
+    const Py_UNICODE *c = NULL;
+    const Py_UNICODE *d = NULL;
     Py_ssize_t d_length;
-    const Py_UNICODE *e;
+    const Py_UNICODE *e = NULL;
     Py_ssize_t e_length;
 
     if (!_PyArg_ParseStack(args, nargs, "O&O&O&u#Z#:test_Py_UNICODE_converter",
@@ -1839,7 +1839,7 @@ test_Py_UNICODE_converter_impl(PyObject *module, const Py_UNICODE *a,
                                const Py_UNICODE *b, const Py_UNICODE *c,
                                const Py_UNICODE *d, Py_ssize_t d_length,
                                const Py_UNICODE *e, Py_ssize_t e_length)
-/*[clinic end generated code: output=45e92604de227552 input=064a3b68ad7f04b0]*/
+/*[clinic end generated code: output=9d41b3a38a0f6f2f input=064a3b68ad7f04b0]*/
 
 
 /*[clinic input]
diff --git a/Lib/test/pickletester.py b/Lib/test/pickletester.py
index 21419e11c8..499f80a15f 100644
--- a/Lib/test/pickletester.py
+++ b/Lib/test/pickletester.py
@@ -2776,6 +2776,15 @@ def pie(self):
                     unpickled = self.loads(self.dumps(method, proto))
                     self.assertEqual(method(obj), unpickled(obj))
 
+        descriptors = (
+            PyMethodsTest.__dict__['cheese'],  # static method descriptor
+            PyMethodsTest.__dict__['wine'],  # class method descriptor
+        )
+        for proto in range(pickle.HIGHEST_PROTOCOL + 1):
+            for descr in descriptors:
+                with self.subTest(proto=proto, descr=descr):
+                    self.assertRaises(TypeError, self.dumps, descr, proto)
+
     def test_c_methods(self):
         global Subclass
         class Subclass(tuple):
@@ -2811,6 +2820,15 @@ class Nested(str):
                     unpickled = self.loads(self.dumps(method, proto))
                     self.assertEqual(method(*args), unpickled(*args))
 
+        descriptors = (
+            bytearray.__dict__['maketrans'],  # built-in static method descriptor
+            dict.__dict__['fromkeys'],  # built-in class method descriptor
+        )
+        for proto in range(pickle.HIGHEST_PROTOCOL + 1):
+            for descr in descriptors:
+                with self.subTest(proto=proto, descr=descr):
+                    self.assertRaises(TypeError, self.dumps, descr, proto)
+
     def test_compat_pickle(self):
         tests = [
             (range(1, 7), '__builtin__', 'xrange'),
diff --git a/Lib/test/string_tests.py b/Lib/test/string_tests.py
index 0d4c7ecf4a..d69edd7bf4 100644
--- a/Lib/test/string_tests.py
+++ b/Lib/test/string_tests.py
@@ -469,6 +469,11 @@ def test_split(self):
         self.checkraises(ValueError, 'hello', 'split', '', 0)
 
     def test_rsplit(self):
+        # without arg
+        self.checkequal(['a', 'b', 'c', 'd'], 'a b c d', 'rsplit')
+        self.checkequal(['a', 'b', 'c', 'd'], 'a  b  c d', 'rsplit')
+        self.checkequal([], '', 'rsplit')
+
         # by a char
         self.checkequal(['a', 'b', 'c', 'd'], 'a|b|c|d', 'rsplit', '|')
         self.checkequal(['a|b|c', 'd'], 'a|b|c|d', 'rsplit', '|', 1)
@@ -522,6 +527,9 @@ def test_rsplit(self):
 
         # with keyword args
         self.checkequal(['a', 'b', 'c', 'd'], 'a|b|c|d', 'rsplit', sep='|')
+        self.checkequal(['a', 'b', 'c', 'd'], 'a b c d', 'rsplit', sep=None)
+        self.checkequal(['a b c', 'd'],
+                        'a b c d', 'rsplit', sep=None, maxsplit=1)
         self.checkequal(['a|b|c', 'd'],
                         'a|b|c|d', 'rsplit', '|', maxsplit=1)
         self.checkequal(['a|b|c', 'd'],
diff --git a/Lib/test/support/__init__.py b/Lib/test/support/__init__.py
index 46087a98a2..8ee8147f41 100644
--- a/Lib/test/support/__init__.py
+++ b/Lib/test/support/__init__.py
@@ -1498,7 +1498,7 @@ def _platform_specific(self):
 
             self._env = {k.upper(): os.getenv(k) for k in os.environ}
             self._env["PYTHONHOME"] = os.path.dirname(self.real)
-            if sysconfig.is_python_build(True):
+            if sysconfig.is_python_build():
                 self._env["PYTHONPATH"] = STDLIB_DIR
     else:
         def _platform_specific(self):
diff --git a/Lib/test/test_asyncio/test_futures.py b/Lib/test/test_asyncio/test_futures.py
index d71af8c13b..f8fe2e76b6 100644
--- a/Lib/test/test_asyncio/test_futures.py
+++ b/Lib/test/test_asyncio/test_futures.py
@@ -824,6 +824,21 @@ def __eq__(self, other):
 
         fut.remove_done_callback(evil())
 
+    def test_remove_done_callbacks_list_clear(self):
+        # see https://github.com/python/cpython/issues/97592 for details
+
+        fut = self._new_future()
+        fut.add_done_callback(str)
+
+        for _ in range(63):
+            fut.add_done_callback(id)
+
+        class evil:
+            def __eq__(self, other):
+                fut.remove_done_callback(other)
+
+        fut.remove_done_callback(evil())
+
     def test_schedule_callbacks_list_mutation_1(self):
         # see http://bugs.python.org/issue28963 for details
 
diff --git a/Lib/test/test_asyncio/test_proactor_events.py b/Lib/test/test_asyncio/test_proactor_events.py
index 7fca0541ee..ae30185cef 100644
--- a/Lib/test/test_asyncio/test_proactor_events.py
+++ b/Lib/test/test_asyncio/test_proactor_events.py
@@ -290,7 +290,33 @@ def test_force_close_idempotent(self):
         tr._closing = True
         tr._force_close(None)
         test_utils.run_briefly(self.loop)
+        # See https://github.com/python/cpython/issues/89237
+        # `protocol.connection_lost` should be called even if
+        # the transport was closed forcefully otherwise
+        # the resources held by protocol will never be freed
+        # and waiters will never be notified leading to hang.
+        self.assertTrue(self.protocol.connection_lost.called)
+
+    def test_force_close_protocol_connection_lost_once(self):
+        tr = self.socket_transport()
         self.assertFalse(self.protocol.connection_lost.called)
+        tr._closing = True
+        # Calling _force_close twice should not call
+        # protocol.connection_lost twice
+        tr._force_close(None)
+        tr._force_close(None)
+        test_utils.run_briefly(self.loop)
+        self.assertEqual(1, self.protocol.connection_lost.call_count)
+
+    def test_close_protocol_connection_lost_once(self):
+        tr = self.socket_transport()
+        self.assertFalse(self.protocol.connection_lost.called)
+        # Calling close twice should not call
+        # protocol.connection_lost twice
+        tr.close()
+        tr.close()
+        test_utils.run_briefly(self.loop)
+        self.assertEqual(1, self.protocol.connection_lost.call_count)
 
     def test_fatal_error_2(self):
         tr = self.socket_transport()
diff --git a/Lib/test/test_asyncio/test_sendfile.py b/Lib/test/test_asyncio/test_sendfile.py
index a10504b1c4..0198da21d7 100644
--- a/Lib/test/test_asyncio/test_sendfile.py
+++ b/Lib/test/test_asyncio/test_sendfile.py
@@ -1,6 +1,7 @@
 """Tests for sendfile functionality."""
 
 import asyncio
+import errno
 import os
 import socket
 import sys
@@ -484,8 +485,17 @@ def sendfile_native(transp, file, offset, count):
 
         srv_proto, cli_proto = self.prepare_sendfile(close_after=1024)
         with self.assertRaises(ConnectionError):
-            self.run_loop(
-                self.loop.sendfile(cli_proto.transport, self.file))
+            try:
+                self.run_loop(
+                    self.loop.sendfile(cli_proto.transport, self.file))
+            except OSError as e:
+                # macOS may raise OSError of EPROTOTYPE when writing to a
+                # socket that is in the process of closing down.
+                if e.errno == errno.EPROTOTYPE and sys.platform == "darwin":
+                    raise ConnectionError
+                else:
+                    raise
+
         self.run_loop(srv_proto.done)
 
         self.assertTrue(1024 <= srv_proto.nbytes < len(self.DATA),
diff --git a/Lib/test/test_asyncio/test_subprocess.py b/Lib/test/test_asyncio/test_subprocess.py
index 961c463f8d..4c0140d80b 100644
--- a/Lib/test/test_asyncio/test_subprocess.py
+++ b/Lib/test/test_asyncio/test_subprocess.py
@@ -1,4 +1,5 @@
 import os
+import shutil
 import signal
 import sys
 import unittest
@@ -182,6 +183,33 @@ def test_kill(self):
         else:
             self.assertEqual(-signal.SIGKILL, returncode)
 
+    def test_kill_issue43884(self):
+        if sys.platform == 'win32':
+            blocking_shell_command = f'{sys.executable} -c "import time; time.sleep(100000000)"'
+        else:
+            blocking_shell_command = 'sleep 1; sleep 1'
+        creationflags = 0
+        if sys.platform == 'win32':
+            from subprocess import CREATE_NEW_PROCESS_GROUP
+            # On windows create a new process group so that killing process
+            # kills the process and all its children.
+            creationflags = CREATE_NEW_PROCESS_GROUP
+        proc = self.loop.run_until_complete(
+            asyncio.create_subprocess_shell(blocking_shell_command, stdout=asyncio.subprocess.PIPE,
+            creationflags=creationflags)
+        )
+        self.loop.run_until_complete(asyncio.sleep(1))
+        if sys.platform == 'win32':
+            proc.send_signal(signal.CTRL_BREAK_EVENT)
+        # On windows it is an alias of terminate which sets the return code
+        proc.kill()
+        returncode = self.loop.run_until_complete(proc.wait())
+        if sys.platform == 'win32':
+            self.assertIsInstance(returncode, int)
+            # expect 1 but sometimes get 0
+        else:
+            self.assertEqual(-signal.SIGKILL, returncode)
+
     def test_terminate(self):
         args = PROGRAM_BLOCKED
         proc = self.loop.run_until_complete(
@@ -402,6 +430,26 @@ async def empty_error():
         self.assertEqual(output, None)
         self.assertEqual(exitcode, 0)
 
+    @unittest.skipIf(sys.platform != 'linux', "Don't have /dev/stdin")
+    def test_devstdin_input(self):
+
+        async def devstdin_input(message):
+            code = 'file = open("/dev/stdin"); data = file.read(); print(len(data))'
+            proc = await asyncio.create_subprocess_exec(
+                sys.executable, '-c', code,
+                stdin=asyncio.subprocess.PIPE,
+                stdout=asyncio.subprocess.PIPE,
+                stderr=asyncio.subprocess.PIPE,
+                close_fds=False,
+            )
+            stdout, stderr = await proc.communicate(message)
+            exitcode = await proc.wait()
+            return (stdout, exitcode)
+
+        output, exitcode = self.loop.run_until_complete(devstdin_input(b'abc'))
+        self.assertEqual(output.rstrip(), b'3')
+        self.assertEqual(exitcode, 0)
+
     def test_cancel_process_wait(self):
         # Issue #23140: cancel Process.wait()
 
diff --git a/Lib/test/test_asyncio/test_windows_events.py b/Lib/test/test_asyncio/test_windows_events.py
index 6b4f65c337..5033acc052 100644
--- a/Lib/test/test_asyncio/test_windows_events.py
+++ b/Lib/test/test_asyncio/test_windows_events.py
@@ -239,6 +239,17 @@ def test_read_self_pipe_restart(self):
         self.close_loop(self.loop)
         self.assertFalse(self.loop.call_exception_handler.called)
 
+    def test_address_argument_type_error(self):
+        # Regression test for https://github.com/python/cpython/issues/98793
+        proactor = self.loop._proactor
+        sock = socket.socket(type=socket.SOCK_DGRAM)
+        bad_address = None
+        with self.assertRaises(TypeError):
+            proactor.connect(sock, bad_address)
+        with self.assertRaises(TypeError):
+            proactor.sendto(sock, b'abc', addr=bad_address)
+        sock.close()
+
 
 class WinPolicyTests(test_utils.TestCase):
 
diff --git a/Lib/test/test_audit.py b/Lib/test/test_audit.py
index 18426f27a2..7cfb1d0d44 100644
--- a/Lib/test/test_audit.py
+++ b/Lib/test/test_audit.py
@@ -16,6 +16,7 @@
 
 
 class AuditTest(unittest.TestCase):
+    maxDiff = None
 
     @support.requires_subprocess()
     def do_test(self, *args):
@@ -185,5 +186,29 @@ def test_sys_getframe(self):
 
         self.assertEqual(actual, expected)
 
+    def test_syslog(self):
+        syslog = import_helper.import_module("syslog")
+
+        returncode, events, stderr = self.run_python("test_syslog")
+        if returncode:
+            self.fail(stderr)
+
+        if support.verbose:
+            print('Events:', *events, sep='\n  ')
+
+        self.assertSequenceEqual(
+            events,
+            [('syslog.openlog', ' ', f'python 0 {syslog.LOG_USER}'),
+            ('syslog.syslog', ' ', f'{syslog.LOG_INFO} test'),
+            ('syslog.setlogmask', ' ', f'{syslog.LOG_DEBUG}'),
+            ('syslog.closelog', '', ''),
+            ('syslog.syslog', ' ', f'{syslog.LOG_INFO} test2'),
+            ('syslog.openlog', ' ', f'audit-tests.py 0 {syslog.LOG_USER}'),
+            ('syslog.openlog', ' ', f'audit-tests.py {syslog.LOG_NDELAY} {syslog.LOG_LOCAL0}'),
+            ('syslog.openlog', ' ', f'None 0 {syslog.LOG_USER}'),
+            ('syslog.closelog', '', '')]
+        )
+
+
 if __name__ == "__main__":
     unittest.main()
diff --git a/Lib/test/test_baseexception.py b/Lib/test/test_baseexception.py
index 0061b3fa8e..4c3cf0b964 100644
--- a/Lib/test/test_baseexception.py
+++ b/Lib/test/test_baseexception.py
@@ -114,6 +114,31 @@ def test_interface_no_arg(self):
                 [repr(exc), exc.__class__.__name__ + '()'])
         self.interface_test_driver(results)
 
+    def test_setstate_refcount_no_crash(self):
+        # gh-97591: Acquire strong reference before calling tp_hash slot
+        # in PyObject_SetAttr.
+        import gc
+        d = {}
+        class HashThisKeyWillClearTheDict(str):
+            def __hash__(self) -> int:
+                d.clear()
+                return super().__hash__()
+        class Value(str):
+            pass
+        exc = Exception()
+
+        d[HashThisKeyWillClearTheDict()] = Value()  # refcount of Value() is 1 now
+
+        # Exception.__setstate__ should aquire a strong reference of key and
+        # value in the dict. Otherwise, Value()'s refcount would go below
+        # zero in the tp_hash call in PyObject_SetAttr(), and it would cause
+        # crash in GC.
+        exc.__setstate__(d)  # __hash__() is called again here, clearing the dict.
+
+        # This GC would crash if the refcount of Value() goes below zero.
+        gc.collect()
+
+
 class UsageTests(unittest.TestCase):
 
     """Test usage of exceptions"""
diff --git a/Lib/test/test_capi.py b/Lib/test/test_capi.py
index e157d9fdc8..a4d643fb05 100644
--- a/Lib/test/test_capi.py
+++ b/Lib/test/test_capi.py
@@ -403,6 +403,18 @@ def items(self):
         self.assertRaises(TypeError, _testcapi.get_mapping_values, bad_mapping)
         self.assertRaises(TypeError, _testcapi.get_mapping_items, bad_mapping)
 
+    def test_mapping_has_key(self):
+        dct = {'a': 1}
+        self.assertTrue(_testcapi.mapping_has_key(dct, 'a'))
+        self.assertFalse(_testcapi.mapping_has_key(dct, 'b'))
+
+        class SubDict(dict):
+            pass
+
+        dct2 = SubDict({'a': 1})
+        self.assertTrue(_testcapi.mapping_has_key(dct2, 'a'))
+        self.assertFalse(_testcapi.mapping_has_key(dct2, 'b'))
+
     @unittest.skipUnless(hasattr(_testcapi, 'negative_refcount'),
                          'need _testcapi.negative_refcount')
     def test_negative_refcount(self):
@@ -724,6 +736,56 @@ def test_export_symbols(self):
             with self.subTest(name=name):
                 self.assertTrue(hasattr(ctypes.pythonapi, name))
 
+    def test_eval_get_func_name(self):
+        def function_example(): ...
+
+        class A:
+            def method_example(self): ...
+
+        self.assertEqual(_testcapi.eval_get_func_name(function_example),
+                         "function_example")
+        self.assertEqual(_testcapi.eval_get_func_name(A.method_example),
+                         "method_example")
+        self.assertEqual(_testcapi.eval_get_func_name(A().method_example),
+                         "method_example")
+        self.assertEqual(_testcapi.eval_get_func_name(sum), "sum")  # c function
+        self.assertEqual(_testcapi.eval_get_func_name(A), "type")
+
+    def test_function_get_code(self):
+        import types
+
+        def some():
+            pass
+
+        code = _testcapi.function_get_code(some)
+        self.assertIsInstance(code, types.CodeType)
+        self.assertEqual(code, some.__code__)
+
+        with self.assertRaises(SystemError):
+            _testcapi.function_get_code(None)  # not a function
+
+    def test_function_get_globals(self):
+        def some():
+            pass
+
+        globals_ = _testcapi.function_get_globals(some)
+        self.assertIsInstance(globals_, dict)
+        self.assertEqual(globals_, some.__globals__)
+
+        with self.assertRaises(SystemError):
+            _testcapi.function_get_globals(None)  # not a function
+
+    def test_function_get_module(self):
+        def some():
+            pass
+
+        module = _testcapi.function_get_module(some)
+        self.assertIsInstance(module, str)
+        self.assertEqual(module, some.__module__)
+
+        with self.assertRaises(SystemError):
+            _testcapi.function_get_module(None)  # not a function
+
 
 class TestPendingCalls(unittest.TestCase):
 
diff --git a/Lib/test/test_code.py b/Lib/test/test_code.py
index 2386cf6b59..d3e20129ee 100644
--- a/Lib/test/test_code.py
+++ b/Lib/test/test_code.py
@@ -132,6 +132,7 @@
 import unittest
 import textwrap
 import weakref
+import dis
 
 try:
     import ctypes
@@ -671,6 +672,38 @@ def test_lines(self):
         self.check_lines(misshappen)
         self.check_lines(bug93662)
 
+    @cpython_only
+    def test_code_new_empty(self):
+        # If this test fails, it means that the construction of PyCode_NewEmpty
+        # needs to be modified! Please update this test *and* PyCode_NewEmpty,
+        # so that they both stay in sync.
+        def f():
+            pass
+        PY_CODE_LOCATION_INFO_NO_COLUMNS = 13
+        f.__code__ = f.__code__.replace(
+            co_firstlineno=42,
+            co_code=bytes(
+                [
+                    dis.opmap["RESUME"], 0,
+                    dis.opmap["LOAD_ASSERTION_ERROR"], 0,
+                    dis.opmap["RAISE_VARARGS"], 1,
+                ]
+            ),
+            co_linetable=bytes(
+                [
+                    (1 << 7)
+                    | (PY_CODE_LOCATION_INFO_NO_COLUMNS << 3)
+                    | (3 - 1),
+                    0,
+                ]
+            ),
+        )
+        self.assertRaises(AssertionError, f)
+        self.assertEqual(
+            list(f.__code__.co_positions()),
+            3 * [(42, 42, None, None)],
+        )
+
 
 if check_impl_detail(cpython=True) and ctypes is not None:
     py = ctypes.pythonapi
diff --git a/Lib/test/test_codecs.py b/Lib/test/test_codecs.py
index 42c600dcb0..7cabe6a83a 100644
--- a/Lib/test/test_codecs.py
+++ b/Lib/test/test_codecs.py
@@ -709,7 +709,8 @@ def test_decoder_state(self):
                                          "spamspam", self.spambe)
 
     def test_bug691291(self):
-        # Files are always opened in binary mode, even if no binary mode was
+        # If encoding is not None, then
+        # files are always opened in binary mode, even if no binary mode was
         # specified.  This means that no automatic conversion of '\n' is done
         # on reading and writing.
         s1 = 'Hello\r\nworld\r\n'
diff --git a/Lib/test/test_codeop.py b/Lib/test/test_codeop.py
index 17376c7ed7..133096d25a 100644
--- a/Lib/test/test_codeop.py
+++ b/Lib/test/test_codeop.py
@@ -321,6 +321,26 @@ def test_warning(self):
             warnings.simplefilter('error', SyntaxWarning)
             compile_command('1 is 1', symbol='exec')
 
+        # Check DeprecationWarning treated as an SyntaxError
+        with warnings.catch_warnings(), self.assertRaises(SyntaxError):
+            warnings.simplefilter('error', DeprecationWarning)
+            compile_command(r"'\e'", symbol='exec')
+
+    def test_incomplete_warning(self):
+        with warnings.catch_warnings(record=True) as w:
+            warnings.simplefilter('always')
+            self.assertIncomplete("'\\e' + (")
+        self.assertEqual(w, [])
+
+    def test_invalid_warning(self):
+        with warnings.catch_warnings(record=True) as w:
+            warnings.simplefilter('always')
+            self.assertInvalid("'\\e' 1")
+        self.assertEqual(len(w), 1)
+        self.assertEqual(w[0].category, DeprecationWarning)
+        self.assertRegex(str(w[0].message), 'invalid escape sequence')
+        self.assertEqual(w[0].filename, '<input>')
+
 
 if __name__ == "__main__":
     unittest.main()
diff --git a/Lib/test/test_collections.py b/Lib/test/test_collections.py
index fa1d0e014d..db7f9e7beb 100644
--- a/Lib/test/test_collections.py
+++ b/Lib/test/test_collections.py
@@ -1594,6 +1594,7 @@ def __len__(self):
         containers = [
             seq,
             ItemsView({1: nan, 2: obj}),
+            KeysView({1: nan, 2: obj}),
             ValuesView({1: nan, 2: obj})
         ]
         for container in containers:
@@ -1857,6 +1858,8 @@ def test_MutableMapping_subclass(self):
         mymap['red'] = 5
         self.assertIsInstance(mymap.keys(), Set)
         self.assertIsInstance(mymap.keys(), KeysView)
+        self.assertIsInstance(mymap.values(), Collection)
+        self.assertIsInstance(mymap.values(), ValuesView)
         self.assertIsInstance(mymap.items(), Set)
         self.assertIsInstance(mymap.items(), ItemsView)
 
diff --git a/Lib/test/test_compile.py b/Lib/test/test_compile.py
index cd4d58acd4..23f84b48fa 100644
--- a/Lib/test/test_compile.py
+++ b/Lib/test/test_compile.py
@@ -1039,6 +1039,32 @@ def while_not_chained(a, b, c):
         for instr in dis.Bytecode(while_not_chained):
             self.assertNotEqual(instr.opname, "EXTENDED_ARG")
 
+    def test_compare_positions(self):
+        for opname, op in [
+            ("COMPARE_OP", "<"),
+            ("COMPARE_OP", "<="),
+            ("COMPARE_OP", ">"),
+            ("COMPARE_OP", ">="),
+            ("CONTAINS_OP", "in"),
+            ("CONTAINS_OP", "not in"),
+            ("IS_OP", "is"),
+            ("IS_OP", "is not"),
+        ]:
+            expr = f'a {op} b {op} c'
+            expected_positions = 2 * [(2, 2, 0, len(expr))]
+            for source in [
+                f"\\\n{expr}", f'if \\\n{expr}: x', f"x if \\\n{expr} else y"
+            ]:
+                code = compile(source, "<test>", "exec")
+                actual_positions = [
+                    instruction.positions
+                    for instruction in dis.get_instructions(code)
+                    if instruction.opname == opname
+                ]
+                with self.subTest(source):
+                    self.assertEqual(actual_positions, expected_positions)
+
+
 @requires_debug_ranges()
 class TestSourcePositions(unittest.TestCase):
     # Ensure that compiled code snippets have correct line and column numbers
diff --git a/Lib/test/test_coroutines.py b/Lib/test/test_coroutines.py
index 8fff2d47c1..a15736e9f9 100644
--- a/Lib/test/test_coroutines.py
+++ b/Lib/test/test_coroutines.py
@@ -1280,7 +1280,7 @@ async def __aexit__(self, *exc):
 
         async def func():
             async with CM():
-                assert (1, ) == 1
+                self.assertEqual((1, ), 1)
 
         with self.assertRaises(AssertionError):
             run_async(func())
diff --git a/Lib/test/test_csv.py b/Lib/test/test_csv.py
index 95a19dd46c..834217bf60 100644
--- a/Lib/test/test_csv.py
+++ b/Lib/test/test_csv.py
@@ -362,6 +362,11 @@ def test_read_quoting(self):
         self._read_test(['1,@,3,@,5'], [['1', ',3,', '5']], quotechar='@')
         self._read_test(['1,\0,3,\0,5'], [['1', ',3,', '5']], quotechar='\0')
 
+    def test_read_skipinitialspace(self):
+        self._read_test(['no space, space,  spaces,\ttab'],
+                        [['no space', 'space', 'spaces', '\ttab']],
+                        skipinitialspace=True)
+
     def test_read_bigfield(self):
         # This exercises the buffer realloc functionality and field size
         # limits.
@@ -448,6 +453,34 @@ def test_register_kwargs(self):
         self.assertEqual(csv.get_dialect(name).delimiter, ';')
         self.assertEqual([['X', 'Y', 'Z']], list(csv.reader(['X;Y;Z'], name)))
 
+    def test_register_kwargs_override(self):
+        class mydialect(csv.Dialect):
+            delimiter = "\t"
+            quotechar = '"'
+            doublequote = True
+            skipinitialspace = False
+            lineterminator = '\r\n'
+            quoting = csv.QUOTE_MINIMAL
+
+        name = 'test_dialect'
+        csv.register_dialect(name, mydialect,
+                             delimiter=';',
+                             quotechar="'",
+                             doublequote=False,
+                             skipinitialspace=True,
+                             lineterminator='\n',
+                             quoting=csv.QUOTE_ALL)
+        self.addCleanup(csv.unregister_dialect, name)
+
+        # Ensure that kwargs do override attributes of a dialect class:
+        dialect = csv.get_dialect(name)
+        self.assertEqual(dialect.delimiter, ';')
+        self.assertEqual(dialect.quotechar, "'")
+        self.assertEqual(dialect.doublequote, False)
+        self.assertEqual(dialect.skipinitialspace, True)
+        self.assertEqual(dialect.lineterminator, '\n')
+        self.assertEqual(dialect.quoting, csv.QUOTE_ALL)
+
     def test_incomplete_dialect(self):
         class myexceltsv(csv.Dialect):
             delimiter = "\t"
diff --git a/Lib/test/test_dataclasses.py b/Lib/test/test_dataclasses.py
index 63380ea0b6..0d809bd2eb 100644
--- a/Lib/test/test_dataclasses.py
+++ b/Lib/test/test_dataclasses.py
@@ -231,6 +231,14 @@ class C:
         c = C('foo')
         self.assertEqual(c.object, 'foo')
 
+    def test_field_named_BUILTINS_frozen(self):
+        # gh-96151
+        @dataclass(frozen=True)
+        class C:
+            BUILTINS: int
+        c = C(5)
+        self.assertEqual(c.BUILTINS, 5)
+
     def test_field_named_like_builtin(self):
         # Attribute names can shadow built-in names
         # since code generation is used.
diff --git a/Lib/test/test_decimal.py b/Lib/test/test_decimal.py
index 33d9c6def9..67ccaab40c 100644
--- a/Lib/test/test_decimal.py
+++ b/Lib/test/test_decimal.py
@@ -37,7 +37,7 @@
                           requires_legacy_unicode_capi, check_sanitizer)
 from test.support import (TestFailed,
                           run_with_locale, cpython_only,
-                          darwin_malloc_err_warning)
+                          darwin_malloc_err_warning, is_emscripten)
 from test.support.import_helper import import_fresh_module
 from test.support import threading_helper
 from test.support import warnings_helper
@@ -5623,6 +5623,7 @@ def __abs__(self):
     # Issue 41540:
     @unittest.skipIf(sys.platform.startswith("aix"),
                      "AIX: default ulimit: test is flaky because of extreme over-allocation")
+    @unittest.skipIf(is_emscripten, "Test is unstable on Emscripten")
     @unittest.skipIf(check_sanitizer(address=True, memory=True),
                      "ASAN/MSAN sanitizer defaults to crashing "
                      "instead of returning NULL for malloc failure.")
diff --git a/Lib/test/test_descr.py b/Lib/test/test_descr.py
index afe0f7e9c7..3145dff81b 100644
--- a/Lib/test/test_descr.py
+++ b/Lib/test/test_descr.py
@@ -1310,6 +1310,15 @@ class X(object):
         with self.assertRaisesRegex(AttributeError, "'X' object has no attribute 'a'"):
             X().a
 
+        # Test string subclass in `__slots__`, see gh-98783
+        class SubStr(str):
+            pass
+        class X(object):
+            __slots__ = (SubStr('x'),)
+        X().x = 1
+        with self.assertRaisesRegex(AttributeError, "'X' object has no attribute 'a'"):
+            X().a
+
     def test_slots_special(self):
         # Testing __dict__ and __weakref__ in __slots__...
         class D(object):
@@ -3581,6 +3590,16 @@ def __repr__(self):
         self.assertEqual(o.__str__(), '41')
         self.assertEqual(o.__repr__(), 'A repr')
 
+    def test_repr_with_module_str_subclass(self):
+        # gh-98783
+        class StrSub(str):
+            pass
+        class Some:
+            pass
+        Some.__module__ = StrSub('example')
+        self.assertIsInstance(repr(Some), str)  # should not crash
+        self.assertIsInstance(repr(Some()), str)  # should not crash
+
     def test_keyword_arguments(self):
         # Testing keyword arguments to __init__, __call__...
         def f(a): return a
diff --git a/Lib/test/test_dictviews.py b/Lib/test/test_dictviews.py
index be271bebaa..dae93740d4 100644
--- a/Lib/test/test_dictviews.py
+++ b/Lib/test/test_dictviews.py
@@ -320,6 +320,9 @@ def test_abc_registry(self):
         self.assertIsInstance(d.values(), collections.abc.ValuesView)
         self.assertIsInstance(d.values(), collections.abc.MappingView)
         self.assertIsInstance(d.values(), collections.abc.Sized)
+        self.assertIsInstance(d.values(), collections.abc.Collection)
+        self.assertIsInstance(d.values(), collections.abc.Iterable)
+        self.assertIsInstance(d.values(), collections.abc.Container)
 
         self.assertIsInstance(d.items(), collections.abc.ItemsView)
         self.assertIsInstance(d.items(), collections.abc.MappingView)
diff --git a/Lib/test/test_dis.py b/Lib/test/test_dis.py
index 6d16021a61..6a0a2d9279 100644
--- a/Lib/test/test_dis.py
+++ b/Lib/test/test_dis.py
@@ -1076,7 +1076,7 @@ def get_disassembly(self, func, lasti=-1, wrapper=True, **kwargs):
         return output.getvalue()
 
 
-if sys.flags.optimize:
+if dis.code_info.__doc__ is None:
     code_info_consts = "0: None"
 else:
     code_info_consts = "0: 'Formatted details of methods, functions, or code.'"
diff --git a/Lib/test/test_embed.py b/Lib/test/test_embed.py
index b8e3c37bbd..be7980eebe 100644
--- a/Lib/test/test_embed.py
+++ b/Lib/test/test_embed.py
@@ -341,6 +341,12 @@ def test_finalize_structseq(self):
         out, err = self.run_embedded_interpreter("test_repeated_init_exec", code)
         self.assertEqual(out, 'Tests passed\n' * INIT_LOOPS)
 
+    def test_simple_initialization_api(self):
+        # _testembed now uses Py_InitializeFromConfig by default
+        # This case specifically checks Py_Initialize(Ex) still works
+        out, err = self.run_embedded_interpreter("test_repeated_simple_init")
+        self.assertEqual(out, 'Finalized\n' * INIT_LOOPS)
+
     def test_quickened_static_code_gets_unquickened_at_Py_FINALIZE(self):
         # https://github.com/python/cpython/issues/92031
 
@@ -1473,17 +1479,11 @@ def test_init_pyvenv_cfg(self):
             if not MS_WINDOWS:
                 paths[-1] = lib_dynload
             else:
-                # Include DLLs directory as well
-                paths.insert(1, '.\\DLLs')
-                for index, path in enumerate(paths):
-                    if index == 0:
-                        # Because we copy the DLLs into tmpdir as well, the zip file
-                        # entry in sys.path will be there. For a regular venv, it will
-                        # usually be in the home directory.
-                        paths[index] = os.path.join(tmpdir, os.path.basename(path))
-                    else:
-                        paths[index] = os.path.join(pyvenv_home, os.path.basename(path))
-                paths[-1] = pyvenv_home
+                paths = [
+                    os.path.join(tmpdir, os.path.basename(paths[0])),
+                    pyvenv_home,
+                    os.path.join(pyvenv_home, "Lib"),
+                ]
 
             executable = self.test_exe
             base_executable = os.path.join(pyvenv_home, os.path.basename(executable))
@@ -1500,12 +1500,12 @@ def test_init_pyvenv_cfg(self):
                 config['base_prefix'] = pyvenv_home
                 config['prefix'] = pyvenv_home
                 config['stdlib_dir'] = os.path.join(pyvenv_home, 'Lib')
-                config['use_frozen_modules'] = not Py_DEBUG
+                config['use_frozen_modules'] = int(not Py_DEBUG)
             else:
                 # cannot reliably assume stdlib_dir here because it
                 # depends too much on our build. But it ought to be found
                 config['stdlib_dir'] = self.IGNORE_CONFIG
-                config['use_frozen_modules'] = not Py_DEBUG
+                config['use_frozen_modules'] = int(not Py_DEBUG)
 
             env = self.copy_paths_by_env(config)
             self.check_all_configs("test_init_compat_config", config,
diff --git a/Lib/test/test_enum.py b/Lib/test/test_enum.py
index 8cd1fe1c10..d2cfc7f7cd 100644
--- a/Lib/test/test_enum.py
+++ b/Lib/test/test_enum.py
@@ -764,7 +764,7 @@ class _FlagTests:
     def test_default_missing_with_wrong_type_value(self):
         with self.assertRaisesRegex(
             ValueError,
-            "'RED' is not a valid TestFlag.Color",
+            "'RED' is not a valid ",
             ) as ctx:
             self.MainEnum('RED')
         self.assertIs(ctx.exception.__context__, None)
@@ -773,7 +773,7 @@ class TestPlainEnum(_EnumTests, _PlainOutputTests, unittest.TestCase):
     enum_type = Enum
 
 
-class TestPlainFlag(_EnumTests, _PlainOutputTests, unittest.TestCase):
+class TestPlainFlag(_EnumTests, _PlainOutputTests, _FlagTests, unittest.TestCase):
     enum_type = Flag
 
 
@@ -785,7 +785,7 @@ class TestStrEnum(_EnumTests, _MinimalOutputTests, unittest.TestCase):
     enum_type = StrEnum
 
 
-class TestIntFlag(_EnumTests, _MinimalOutputTests, unittest.TestCase):
+class TestIntFlag(_EnumTests, _MinimalOutputTests, _FlagTests, unittest.TestCase):
     enum_type = IntFlag
 
 
@@ -797,7 +797,7 @@ class TestMixedStr(_EnumTests, _MixedOutputTests, unittest.TestCase):
     class enum_type(str, Enum): pass
 
 
-class TestMixedIntFlag(_EnumTests, _MixedOutputTests, unittest.TestCase):
+class TestMixedIntFlag(_EnumTests, _MixedOutputTests, _FlagTests, unittest.TestCase):
     class enum_type(int, Flag): pass
 
 
diff --git a/Lib/test/test_exception_hierarchy.py b/Lib/test/test_exception_hierarchy.py
index 89fe9ddcef..3318fa8e77 100644
--- a/Lib/test/test_exception_hierarchy.py
+++ b/Lib/test/test_exception_hierarchy.py
@@ -63,7 +63,7 @@ def test_select_error(self):
         +-- InterruptedError                                            EINTR
         +-- IsADirectoryError                                          EISDIR
         +-- NotADirectoryError                                        ENOTDIR
-        +-- PermissionError                                     EACCES, EPERM
+        +-- PermissionError                        EACCES, EPERM, ENOTCAPABLE
         +-- ProcessLookupError                                          ESRCH
         +-- TimeoutError                                            ETIMEDOUT
     """
@@ -75,6 +75,8 @@ def _make_map(s):
                 continue
             excname, _, errnames = line.partition(' ')
             for errname in filter(None, errnames.strip().split(', ')):
+                if errname == "ENOTCAPABLE" and not hasattr(errno, errname):
+                    continue
                 _map[getattr(errno, errname)] = getattr(builtins, excname)
         return _map
     _map = _make_map(_pep_map)
@@ -91,7 +93,7 @@ def test_errno_mapping(self):
         othercodes = set(errno.errorcode) - set(self._map)
         for errcode in othercodes:
             e = OSError(errcode, "Some message")
-            self.assertIs(type(e), OSError)
+            self.assertIs(type(e), OSError, repr(e))
 
     def test_try_except(self):
         filename = "some_hopefully_non_existing_file"
diff --git a/Lib/test/test_frame.py b/Lib/test/test_frame.py
index e153bc5c7c..4b86a60d2f 100644
--- a/Lib/test/test_frame.py
+++ b/Lib/test/test_frame.py
@@ -1,11 +1,13 @@
 import gc
 import re
 import sys
+import textwrap
 import types
 import unittest
 import weakref
 
 from test import support
+from test.support.script_helper import assert_python_ok
 
 
 class ClearTest(unittest.TestCase):
@@ -239,25 +241,26 @@ def inner():
 class TestIncompleteFrameAreInvisible(unittest.TestCase):
 
     def test_issue95818(self):
-        #See GH-95818 for details
-        import gc
-        self.addCleanup(gc.set_threshold, *gc.get_threshold())
+        # See GH-95818 for details
+        code = textwrap.dedent(f"""
+            import gc
 
-        gc.set_threshold(1,1,1)
-        class GCHello:
-            def __del__(self):
-                print("Destroyed from gc")
+            gc.set_threshold(1,1,1)
+            class GCHello:
+                def __del__(self):
+                    print("Destroyed from gc")
 
-        def gen():
-            yield
-
-        fd = open(__file__)
-        l = [fd, GCHello()]
-        l.append(l)
-        del fd
-        del l
-        gen()
+            def gen():
+                yield
 
+            fd = open({__file__!r})
+            l = [fd, GCHello()]
+            l.append(l)
+            del fd
+            del l
+            gen()
+        """)
+        assert_python_ok("-c", code)
 
     @support.cpython_only
     def test_sneaky_frame_object(self):
diff --git a/Lib/test/test_genericalias.py b/Lib/test/test_genericalias.py
index 6959c2ae3c..e44193a0f7 100644
--- a/Lib/test/test_genericalias.py
+++ b/Lib/test/test_genericalias.py
@@ -203,23 +203,11 @@ class MyList(list):
         self.assertEqual(repr(list[str]), 'list[str]')
         self.assertEqual(repr(list[()]), 'list[()]')
         self.assertEqual(repr(tuple[int, ...]), 'tuple[int, ...]')
-        x1 = tuple[
-            tuple(  # Effectively the same as starring; TODO
-                tuple[int]
-            )
-        ]
+        x1 = tuple[*tuple[int]]
         self.assertEqual(repr(x1), 'tuple[*tuple[int]]')
-        x2 = tuple[
-            tuple(  # Ditto TODO
-                tuple[int, str]
-            )
-        ]
+        x2 = tuple[*tuple[int, str]]
         self.assertEqual(repr(x2), 'tuple[*tuple[int, str]]')
-        x3 = tuple[
-            tuple(  # Ditto TODO
-                tuple[int, ...]
-            )
-        ]
+        x3 = tuple[*tuple[int, ...]]
         self.assertEqual(repr(x3), 'tuple[*tuple[int, ...]]')
         self.assertTrue(repr(MyList[int]).endswith('.BaseTest.test_repr.<locals>.MyList[int]'))
         self.assertEqual(repr(list[str]()), '[]')  # instances should keep their normal repr
@@ -273,42 +261,24 @@ def test_parameters(self):
         self.assertEqual(L5.__args__, (Callable[[K, V], K],))
         self.assertEqual(L5.__parameters__, (K, V))
 
-        T1 = tuple[
-            tuple(  # Ditto TODO
-                tuple[int]
-            )
-        ]
+        T1 = tuple[*tuple[int]]
         self.assertEqual(
             T1.__args__,
-            tuple(  # Ditto TODO
-                tuple[int]
-            )
+            (*tuple[int],),
         )
         self.assertEqual(T1.__parameters__, ())
 
-        T2 = tuple[
-            tuple(  # Ditto TODO
-                tuple[T]
-            )
-        ]
+        T2 = tuple[*tuple[T]]
         self.assertEqual(
             T2.__args__,
-            tuple(  # Ditto TODO
-                tuple[T]
-            )
+            (*tuple[T],),
         )
         self.assertEqual(T2.__parameters__, (T,))
 
-        T4 = tuple[
-            tuple(  # Ditto TODO
-                tuple[int, str]
-            )
-        ]
+        T4 = tuple[*tuple[int, str]]
         self.assertEqual(
             T4.__args__,
-            tuple(  # Ditto TODO
-                tuple[int, str]
-            )
+            (*tuple[int, str],),
         )
         self.assertEqual(T4.__parameters__, ())
 
@@ -343,18 +313,7 @@ def test_equality(self):
         self.assertEqual(list[int], list[int])
         self.assertEqual(dict[str, int], dict[str, int])
         self.assertEqual((*tuple[int],)[0], (*tuple[int],)[0])
-        self.assertEqual(
-            tuple[
-                tuple(  # Effectively the same as starring; TODO
-                    tuple[int]
-                )
-            ],
-            tuple[
-                tuple(  # Ditto TODO
-                    tuple[int]
-                )
-            ]
-        )
+        self.assertEqual(tuple[*tuple[int]], tuple[*tuple[int]])
         self.assertNotEqual(dict[str, int], dict[str, str])
         self.assertNotEqual(list, list[int])
         self.assertNotEqual(list[int], list)
diff --git a/Lib/test/test_getpath.py b/Lib/test/test_getpath.py
index 5208374e20..d668e4f546 100644
--- a/Lib/test/test_getpath.py
+++ b/Lib/test/test_getpath.py
@@ -239,6 +239,29 @@ def test_buildtree_pythonhome_win32(self):
         actual = getpath(ns, expected)
         self.assertEqual(expected, actual)
 
+    def test_no_dlls_win32(self):
+        "Test a layout on Windows with no DLLs directory."
+        ns = MockNTNamespace(
+            argv0=r"C:\Python\python.exe",
+            real_executable=r"C:\Python\python.exe",
+        )
+        ns.add_known_xfile(r"C:\Python\python.exe")
+        ns.add_known_file(r"C:\Python\Lib\os.py")
+        expected = dict(
+            executable=r"C:\Python\python.exe",
+            base_executable=r"C:\Python\python.exe",
+            prefix=r"C:\Python",
+            exec_prefix=r"C:\Python",
+            module_search_paths_set=1,
+            module_search_paths=[
+                r"C:\Python\python98.zip",
+                r"C:\Python\Lib",
+                r"C:\Python",
+            ],
+        )
+        actual = getpath(ns, expected)
+        self.assertEqual(expected, actual)
+
     def test_normal_posix(self):
         "Test a 'standard' install layout on *nix"
         ns = MockPosixNamespace(
diff --git a/Lib/test/test_importlib/util.py b/Lib/test/test_importlib/util.py
index c07ac2a64c..0b6dcc5eaf 100644
--- a/Lib/test/test_importlib/util.py
+++ b/Lib/test/test_importlib/util.py
@@ -298,7 +298,7 @@ def writes_bytecode_files(fxn):
     """Decorator to protect sys.dont_write_bytecode from mutation and to skip
     tests that require it to be set to False."""
     if sys.dont_write_bytecode:
-        return lambda *args, **kwargs: None
+        return unittest.skip("relies on writing bytecode")(fxn)
     @functools.wraps(fxn)
     def wrapper(*args, **kwargs):
         original = sys.dont_write_bytecode
diff --git a/Lib/test/test_inspect.py b/Lib/test/test_inspect.py
index be9f29e04a..c030be77e8 100644
--- a/Lib/test/test_inspect.py
+++ b/Lib/test/test_inspect.py
@@ -1421,6 +1421,13 @@ def wrapper(a, b):
         self.assertEqual(inspect.get_annotations(isa.MyClassWithLocalAnnotations, eval_str=True), {'x': int})
 
 
+class TestFormatAnnotation(unittest.TestCase):
+    def test_typing_replacement(self):
+        from test.typinganndata.ann_module9 import ann, ann1
+        self.assertEqual(inspect.formatannotation(ann), 'Union[List[str], int]')
+        self.assertEqual(inspect.formatannotation(ann1), 'Union[List[testModule.typing.A], int]')
+
+
 class TestIsDataDescriptor(unittest.TestCase):
 
     def test_custom_descriptors(self):
diff --git a/Lib/test/test_ipaddress.py b/Lib/test/test_ipaddress.py
index c9ae7dab38..5c656c49e2 100644
--- a/Lib/test/test_ipaddress.py
+++ b/Lib/test/test_ipaddress.py
@@ -1652,7 +1652,7 @@ def testNth(self):
         self.assertRaises(IndexError, self.ipv6_scoped_network.__getitem__, 1 << 64)
 
     def testGetitem(self):
-        # http://code.google.com/p/ipaddr-py/issues/detail?id=15
+        # https://code.google.com/p/ipaddr-py/issues/detail?id=15
         addr = ipaddress.IPv4Network('172.31.255.128/255.255.255.240')
         self.assertEqual(28, addr.prefixlen)
         addr_list = list(addr)
diff --git a/Lib/test/test_iter.py b/Lib/test/test_iter.py
index 554f602f62..acbdcb5f30 100644
--- a/Lib/test/test_iter.py
+++ b/Lib/test/test_iter.py
@@ -81,6 +81,16 @@ class BadIterableClass:
     def __iter__(self):
         raise ZeroDivisionError
 
+class CallableIterClass:
+    def __init__(self):
+        self.i = 0
+    def __call__(self):
+        i = self.i
+        self.i = i + 1
+        if i > 100:
+            raise IndexError # Emergency stop
+        return i
+
 # Main test suite
 
 class TestCase(unittest.TestCase):
@@ -237,16 +247,7 @@ def __iter__(self):
 
     # Test two-argument iter() with callable instance
     def test_iter_callable(self):
-        class C:
-            def __init__(self):
-                self.i = 0
-            def __call__(self):
-                i = self.i
-                self.i = i + 1
-                if i > 100:
-                    raise IndexError # Emergency stop
-                return i
-        self.check_iterator(iter(C(), 10), list(range(10)), pickle=False)
+        self.check_iterator(iter(CallableIterClass(), 10), list(range(10)), pickle=True)
 
     # Test two-argument iter() with function
     def test_iter_function(self):
diff --git a/Lib/test/test_json/test_fail.py b/Lib/test/test_json/test_fail.py
index eb9064edea..efc982e8b0 100644
--- a/Lib/test/test_json/test_fail.py
+++ b/Lib/test/test_json/test_fail.py
@@ -2,73 +2,73 @@
 
 # 2007-10-05
 JSONDOCS = [
-    # http://json.org/JSON_checker/test/fail1.json
+    # https://json.org/JSON_checker/test/fail1.json
     '"A JSON payload should be an object or array, not a string."',
-    # http://json.org/JSON_checker/test/fail2.json
+    # https://json.org/JSON_checker/test/fail2.json
     '["Unclosed array"',
-    # http://json.org/JSON_checker/test/fail3.json
+    # https://json.org/JSON_checker/test/fail3.json
     '{unquoted_key: "keys must be quoted"}',
-    # http://json.org/JSON_checker/test/fail4.json
+    # https://json.org/JSON_checker/test/fail4.json
     '["extra comma",]',
-    # http://json.org/JSON_checker/test/fail5.json
+    # https://json.org/JSON_checker/test/fail5.json
     '["double extra comma",,]',
-    # http://json.org/JSON_checker/test/fail6.json
+    # https://json.org/JSON_checker/test/fail6.json
     '[   , "<-- missing value"]',
-    # http://json.org/JSON_checker/test/fail7.json
+    # https://json.org/JSON_checker/test/fail7.json
     '["Comma after the close"],',
-    # http://json.org/JSON_checker/test/fail8.json
+    # https://json.org/JSON_checker/test/fail8.json
     '["Extra close"]]',
-    # http://json.org/JSON_checker/test/fail9.json
+    # https://json.org/JSON_checker/test/fail9.json
     '{"Extra comma": true,}',
-    # http://json.org/JSON_checker/test/fail10.json
+    # https://json.org/JSON_checker/test/fail10.json
     '{"Extra value after close": true} "misplaced quoted value"',
-    # http://json.org/JSON_checker/test/fail11.json
+    # https://json.org/JSON_checker/test/fail11.json
     '{"Illegal expression": 1 + 2}',
-    # http://json.org/JSON_checker/test/fail12.json
+    # https://json.org/JSON_checker/test/fail12.json
     '{"Illegal invocation": alert()}',
-    # http://json.org/JSON_checker/test/fail13.json
+    # https://json.org/JSON_checker/test/fail13.json
     '{"Numbers cannot have leading zeroes": 013}',
-    # http://json.org/JSON_checker/test/fail14.json
+    # https://json.org/JSON_checker/test/fail14.json
     '{"Numbers cannot be hex": 0x14}',
-    # http://json.org/JSON_checker/test/fail15.json
+    # https://json.org/JSON_checker/test/fail15.json
     '["Illegal backslash escape: \\x15"]',
-    # http://json.org/JSON_checker/test/fail16.json
+    # https://json.org/JSON_checker/test/fail16.json
     '[\\naked]',
-    # http://json.org/JSON_checker/test/fail17.json
+    # https://json.org/JSON_checker/test/fail17.json
     '["Illegal backslash escape: \\017"]',
-    # http://json.org/JSON_checker/test/fail18.json
+    # https://json.org/JSON_checker/test/fail18.json
     '[[[[[[[[[[[[[[[[[[[["Too deep"]]]]]]]]]]]]]]]]]]]]',
-    # http://json.org/JSON_checker/test/fail19.json
+    # https://json.org/JSON_checker/test/fail19.json
     '{"Missing colon" null}',
-    # http://json.org/JSON_checker/test/fail20.json
+    # https://json.org/JSON_checker/test/fail20.json
     '{"Double colon":: null}',
-    # http://json.org/JSON_checker/test/fail21.json
+    # https://json.org/JSON_checker/test/fail21.json
     '{"Comma instead of colon", null}',
-    # http://json.org/JSON_checker/test/fail22.json
+    # https://json.org/JSON_checker/test/fail22.json
     '["Colon instead of comma": false]',
-    # http://json.org/JSON_checker/test/fail23.json
+    # https://json.org/JSON_checker/test/fail23.json
     '["Bad value", truth]',
-    # http://json.org/JSON_checker/test/fail24.json
+    # https://json.org/JSON_checker/test/fail24.json
     "['single quote']",
-    # http://json.org/JSON_checker/test/fail25.json
+    # https://json.org/JSON_checker/test/fail25.json
     '["\ttab\tcharacter\tin\tstring\t"]',
-    # http://json.org/JSON_checker/test/fail26.json
+    # https://json.org/JSON_checker/test/fail26.json
     '["tab\\   character\\   in\\  string\\  "]',
-    # http://json.org/JSON_checker/test/fail27.json
+    # https://json.org/JSON_checker/test/fail27.json
     '["line\nbreak"]',
-    # http://json.org/JSON_checker/test/fail28.json
+    # https://json.org/JSON_checker/test/fail28.json
     '["line\\\nbreak"]',
-    # http://json.org/JSON_checker/test/fail29.json
+    # https://json.org/JSON_checker/test/fail29.json
     '[0e]',
-    # http://json.org/JSON_checker/test/fail30.json
+    # https://json.org/JSON_checker/test/fail30.json
     '[0e+]',
-    # http://json.org/JSON_checker/test/fail31.json
+    # https://json.org/JSON_checker/test/fail31.json
     '[0e+-1]',
-    # http://json.org/JSON_checker/test/fail32.json
+    # https://json.org/JSON_checker/test/fail32.json
     '{"Comma instead if closing brace": true,',
-    # http://json.org/JSON_checker/test/fail33.json
+    # https://json.org/JSON_checker/test/fail33.json
     '["mismatch"}',
-    # http://code.google.com/p/simplejson/issues/detail?id=3
+    # https://code.google.com/archive/p/simplejson/issues/3
     '["A\u001FZ control characters in string"]',
 ]
 
diff --git a/Lib/test/test_json/test_pass1.py b/Lib/test/test_json/test_pass1.py
index 15e64b0aea..26bf3cdbd7 100644
--- a/Lib/test/test_json/test_pass1.py
+++ b/Lib/test/test_json/test_pass1.py
@@ -1,7 +1,7 @@
 from test.test_json import PyTest, CTest
 
 
-# from http://json.org/JSON_checker/test/pass1.json
+# from https://json.org/JSON_checker/test/pass1.json
 JSON = r'''
 [
     "JSON Test Pattern pass1",
diff --git a/Lib/test/test_json/test_pass2.py b/Lib/test/test_json/test_pass2.py
index 35075249e3..9340de665a 100644
--- a/Lib/test/test_json/test_pass2.py
+++ b/Lib/test/test_json/test_pass2.py
@@ -1,7 +1,7 @@
 from test.test_json import PyTest, CTest
 
 
-# from http://json.org/JSON_checker/test/pass2.json
+# from https://json.org/JSON_checker/test/pass2.json
 JSON = r'''
 [[[[[[[[[[[[[[[[[[["Not too deep"]]]]]]]]]]]]]]]]]]]
 '''
diff --git a/Lib/test/test_json/test_pass3.py b/Lib/test/test_json/test_pass3.py
index cd0cf170d2..0adccc1c2a 100644
--- a/Lib/test/test_json/test_pass3.py
+++ b/Lib/test/test_json/test_pass3.py
@@ -1,7 +1,7 @@
 from test.test_json import PyTest, CTest
 
 
-# from http://json.org/JSON_checker/test/pass3.json
+# from https://json.org/JSON_checker/test/pass3.json
 JSON = r'''
 {
     "JSON Test Pattern pass3": {
diff --git a/Lib/test/test_launcher.py b/Lib/test/test_launcher.py
index ba6856b3e2..be6d002269 100644
--- a/Lib/test/test_launcher.py
+++ b/Lib/test/test_launcher.py
@@ -517,6 +517,14 @@ def test_py_shebang(self):
         self.assertEqual("3.100", data["SearchInfo.tag"])
         self.assertEqual(f"X.Y.exe -prearg {script} -postarg", data["stdout"].strip())
 
+    def test_python_shebang(self):
+        with self.py_ini(TEST_PY_COMMANDS):
+            with self.script("#! python -prearg") as script:
+                data = self.run_py([script, "-postarg"])
+        self.assertEqual("PythonTestSuite", data["SearchInfo.company"])
+        self.assertEqual("3.100", data["SearchInfo.tag"])
+        self.assertEqual(f"X.Y.exe -prearg {script} -postarg", data["stdout"].strip())
+
     def test_py2_shebang(self):
         with self.py_ini(TEST_PY_COMMANDS):
             with self.script("#! /usr/bin/python2 -prearg") as script:
@@ -618,3 +626,42 @@ def test_install(self):
             self.assertIn("winget.exe", cmd)
         # Both command lines include the store ID
         self.assertIn("9PJPW5LDXLZ5", cmd)
+
+    def test_literal_shebang_absolute(self):
+        with self.script(f"#! C:/some_random_app -witharg") as script:
+            data = self.run_py([script])
+        self.assertEqual(
+            f"C:\\some_random_app -witharg {script}",
+            data["stdout"].strip(),
+        )
+
+    def test_literal_shebang_relative(self):
+        with self.script(f"#! ..\\some_random_app -witharg") as script:
+            data = self.run_py([script])
+        self.assertEqual(
+            f"{script.parent.parent}\\some_random_app -witharg {script}",
+            data["stdout"].strip(),
+        )
+
+    def test_literal_shebang_quoted(self):
+        with self.script(f'#! "some random app" -witharg') as script:
+            data = self.run_py([script])
+        self.assertEqual(
+            f'"{script.parent}\\some random app" -witharg {script}',
+            data["stdout"].strip(),
+        )
+
+        with self.script(f'#! some" random "app -witharg') as script:
+            data = self.run_py([script])
+        self.assertEqual(
+            f'"{script.parent}\\some random app" -witharg {script}',
+            data["stdout"].strip(),
+        )
+
+    def test_literal_shebang_quoted_escape(self):
+        with self.script(f'#! some\\" random "app -witharg') as script:
+            data = self.run_py([script])
+        self.assertEqual(
+            f'"{script.parent}\\some\\ random app" -witharg {script}',
+            data["stdout"].strip(),
+        )
diff --git a/Lib/test/test_long.py b/Lib/test/test_long.py
index d092e0176c..77b37ca1fa 100644
--- a/Lib/test/test_long.py
+++ b/Lib/test/test_long.py
@@ -1334,6 +1334,12 @@ def equivalent_python(n, length, byteorder, signed=False):
                          b'\xff\xff\xff\xff\xff')
         self.assertRaises(OverflowError, (1).to_bytes, 0, 'big')
 
+        # gh-98783
+        class SubStr(str):
+            pass
+        self.assertEqual((0).to_bytes(1, SubStr('big')), b'\x00')
+        self.assertEqual((0).to_bytes(0, SubStr('little')), b'')
+
     def test_from_bytes(self):
         def check(tests, byteorder, signed=False):
             def equivalent_python(byte_array, byteorder, signed=False):
@@ -1518,6 +1524,28 @@ def __init__(self, value):
         self.assertEqual(i, 1)
         self.assertEqual(getattr(i, 'foo', 'none'), 'bar')
 
+        class ValidBytes:
+            def __bytes__(self):
+                return b'\x01'
+        class InvalidBytes:
+            def __bytes__(self):
+                return 'abc'
+        class MissingBytes: ...
+        class RaisingBytes:
+            def __bytes__(self):
+                1 / 0
+
+        self.assertEqual(int.from_bytes(ValidBytes()), 1)
+        self.assertRaises(TypeError, int.from_bytes, InvalidBytes())
+        self.assertRaises(TypeError, int.from_bytes, MissingBytes())
+        self.assertRaises(ZeroDivisionError, int.from_bytes, RaisingBytes())
+
+        # gh-98783
+        class SubStr(str):
+            pass
+        self.assertEqual(int.from_bytes(b'', SubStr('big')), 0)
+        self.assertEqual(int.from_bytes(b'\x00', SubStr('little')), 0)
+
     @support.cpython_only
     def test_from_bytes_small(self):
         # bpo-46361
diff --git a/Lib/test/test_marshal.py b/Lib/test/test_marshal.py
index aae86cc257..f5956fc3a1 100644
--- a/Lib/test/test_marshal.py
+++ b/Lib/test/test_marshal.py
@@ -259,6 +259,8 @@ def test_recursion_limit(self):
         #if os.name == 'nt' and hasattr(sys, 'gettotalrefcount'):
         if os.name == 'nt':
             MAX_MARSHAL_STACK_DEPTH = 1000
+        elif sys.platform == 'wasi':
+            MAX_MARSHAL_STACK_DEPTH = 1500
         else:
             MAX_MARSHAL_STACK_DEPTH = 2000
         for i in range(MAX_MARSHAL_STACK_DEPTH - 2):
diff --git a/Lib/test/test_math.py b/Lib/test/test_math.py
index cfaf3b3ea2..bf0d0a56e6 100644
--- a/Lib/test/test_math.py
+++ b/Lib/test/test_math.py
@@ -1006,6 +1006,11 @@ class T(tuple):
             self.assertEqual(math.dist(p, q), 5*scale)
             self.assertEqual(math.dist(q, p), 5*scale)
 
+    def test_math_dist_leak(self):
+        # gh-98897: Check for error handling does not leak memory
+        with self.assertRaises(ValueError):
+            math.dist([1, 2], [3, 4, 5])
+
     def testIsqrt(self):
         # Test a variety of inputs, large and small.
         test_values = (
diff --git a/Lib/test/test_pdb.py b/Lib/test/test_pdb.py
index 55c3283e26..48f419e62f 100644
--- a/Lib/test/test_pdb.py
+++ b/Lib/test/test_pdb.py
@@ -2104,6 +2104,52 @@ def inner(v): pass
         stdout, stderr = self.run_pdb_script(script, commands)
         self.assertFalse(stderr)
 
+    def test_gh_93696_frozen_list(self):
+        frozen_src = """
+        def func():
+            x = "Sentinel string for gh-93696"
+            print(x)
+        """
+        host_program = """
+        import os
+        import sys
+
+        def _create_fake_frozen_module():
+            with open('gh93696.py') as f:
+                src = f.read()
+
+            # this function has a co_filename as if it were in a frozen module
+            dummy_mod = compile(src, "<frozen gh93696>", "exec")
+            func_code = dummy_mod.co_consts[0]
+
+            mod = type(sys)("gh93696")
+            mod.func = type(lambda: None)(func_code, mod.__dict__)
+            mod.__file__ = 'gh93696.py'
+
+            return mod
+
+        mod = _create_fake_frozen_module()
+        mod.func()
+        """
+        commands = """
+            break 20
+            continue
+            step
+            list
+            quit
+        """
+        with open('gh93696.py', 'w') as f:
+            f.write(textwrap.dedent(frozen_src))
+
+        with open('gh93696_host.py', 'w') as f:
+            f.write(textwrap.dedent(host_program))
+
+        self.addCleanup(os_helper.unlink, 'gh93696.py')
+        self.addCleanup(os_helper.unlink, 'gh93696_host.py')
+        stdout, stderr = self._run_pdb(["gh93696_host.py"], commands)
+        # verify that pdb found the source of the "frozen" function
+        self.assertIn('x = "Sentinel string for gh-93696"', stdout, "Sentinel statement not found")
+
 class ChecklineTests(unittest.TestCase):
     def setUp(self):
         linecache.clearcache()  # Pdb.checkline() uses linecache.getline()
diff --git a/Lib/test/test_re.py b/Lib/test/test_re.py
index 5d946370ee..59d0b7b5c4 100644
--- a/Lib/test/test_re.py
+++ b/Lib/test/test_re.py
@@ -661,6 +661,11 @@ def test_re_groupref_exists_errors(self):
         self.checkPatternError(r'()(?(2)a)',
                                "invalid group reference 2", 5)
 
+    def test_re_groupref_exists_validation_bug(self):
+        for i in range(256):
+            with self.subTest(code=i):
+                re.compile(r'()(?(1)\x%02x?)' % i)
+
     def test_re_groupref_overflow(self):
         from re._constants import MAXGROUPS
         self.checkTemplateError('()', r'\g<%s>' % MAXGROUPS, 'xx',
diff --git a/Lib/test/test_sched.py b/Lib/test/test_sched.py
index 32cc8105bc..eb52ac7983 100644
--- a/Lib/test/test_sched.py
+++ b/Lib/test/test_sched.py
@@ -92,10 +92,23 @@ def test_priority(self):
         l = []
         fun = lambda x: l.append(x)
         scheduler = sched.scheduler(time.time, time.sleep)
-        for priority in [1, 2, 3, 4, 5]:
-            z = scheduler.enterabs(0.01, priority, fun, (priority,))
-        scheduler.run()
-        self.assertEqual(l, [1, 2, 3, 4, 5])
+
+        cases = [
+            ([1, 2, 3, 4, 5], [1, 2, 3, 4, 5]),
+            ([5, 4, 3, 2, 1], [1, 2, 3, 4, 5]),
+            ([2, 5, 3, 1, 4], [1, 2, 3, 4, 5]),
+            ([1, 2, 3, 2, 1], [1, 1, 2, 2, 3]),
+        ]
+        for priorities, expected in cases:
+            with self.subTest(priorities=priorities, expected=expected):
+                for priority in priorities:
+                    scheduler.enterabs(0.01, priority, fun, (priority,))
+                scheduler.run()
+                self.assertEqual(l, expected)
+
+                # Cleanup:
+                self.assertTrue(scheduler.empty())
+                l.clear()
 
     def test_cancel(self):
         l = []
diff --git a/Lib/test/test_string_literals.py b/Lib/test/test_string_literals.py
index 3a3830bcb6..7247b7e48b 100644
--- a/Lib/test/test_string_literals.py
+++ b/Lib/test/test_string_literals.py
@@ -266,6 +266,13 @@ def test_eval_str_u(self):
         self.assertRaises(SyntaxError, eval, """ bu'' """)
         self.assertRaises(SyntaxError, eval, """ ub'' """)
 
+    def test_uppercase_prefixes(self):
+        self.assertEqual(eval(""" B'x' """), b'x')
+        self.assertEqual(eval(r""" R'\x01' """), r'\x01')
+        self.assertEqual(eval(r""" BR'\x01' """), br'\x01')
+        self.assertEqual(eval(""" F'{1+1}' """), f'{1+1}')
+        self.assertEqual(eval(r""" U'\U0001d120' """), u'\U0001d120')
+
     def check_encoding(self, encoding, extra=""):
         modname = "xx_" + encoding.replace("-", "_")
         fn = os.path.join(self.tmpdir, modname + ".py")
diff --git a/Lib/test/test_subprocess.py b/Lib/test/test_subprocess.py
index f6854922a5..424a4a93b6 100644
--- a/Lib/test/test_subprocess.py
+++ b/Lib/test/test_subprocess.py
@@ -238,6 +238,12 @@ def test_check_output_input_none_universal_newlines(self):
                 input=None, universal_newlines=True)
         self.assertNotIn('XX', output)
 
+    def test_check_output_input_none_encoding_errors(self):
+        output = subprocess.check_output(
+                [sys.executable, "-c", "print('foo')"],
+                input=None, encoding='utf-8', errors='ignore')
+        self.assertIn('foo', output)
+
     def test_check_output_stdout_arg(self):
         # check_output() refuses to accept 'stdout' argument
         with self.assertRaises(ValueError) as c:
diff --git a/Lib/test/test_sys_settrace.py b/Lib/test/test_sys_settrace.py
index 9f1aa81dbc..aa61f8b185 100644
--- a/Lib/test/test_sys_settrace.py
+++ b/Lib/test/test_sys_settrace.py
@@ -1721,6 +1721,20 @@ def g(frame, event, arg):
         finally:
             sys.settrace(existing)
 
+    def test_line_event_raises_before_opcode_event(self):
+        exception = ValueError("BOOM!")
+        def trace(frame, event, arg):
+            if event == "line":
+                raise exception
+            frame.f_trace_opcodes = True
+            return trace
+        def f():
+            pass
+        with self.assertRaises(ValueError) as caught:
+            sys.settrace(trace)
+            f()
+        self.assertIs(caught.exception, exception)
+
 
 # 'Jump' tests: assigning to frame.f_lineno within a trace function
 # moves the execution position - it's how debuggers implement a Jump
diff --git a/Lib/test/test_sysconfig.py b/Lib/test/test_sysconfig.py
index 578ac1db50..d96371d242 100644
--- a/Lib/test/test_sysconfig.py
+++ b/Lib/test/test_sysconfig.py
@@ -439,6 +439,7 @@ def test_platform_in_subprocess(self):
         self.assertEqual(status, 0)
         self.assertEqual(my_platform, test_platform)
 
+    @unittest.skipIf(is_wasi, "Incompatible with WASI mapdir and OOT builds")
     def test_srcdir(self):
         # See Issues #15322, #15364.
         srcdir = sysconfig.get_config_var('srcdir')
diff --git a/Lib/test/test_syslog.py b/Lib/test/test_syslog.py
index fe09bd39f8..2125ec58d8 100644
--- a/Lib/test/test_syslog.py
+++ b/Lib/test/test_syslog.py
@@ -1,5 +1,9 @@
-from test.support import import_helper
+from test.support import import_helper, threading_helper
 syslog = import_helper.import_module("syslog") #skip if not supported
+from test import support
+import sys
+import threading
+import time
 import unittest
 
 # XXX(nnorwitz): This test sucks.  I don't know of a platform independent way
@@ -8,6 +12,9 @@
 
 class Test(unittest.TestCase):
 
+    def tearDown(self):
+        syslog.closelog()
+
     def test_openlog(self):
         syslog.openlog('python')
         # Issue #6697.
@@ -18,22 +25,59 @@ def test_syslog(self):
         syslog.syslog('test message from python test_syslog')
         syslog.syslog(syslog.LOG_ERR, 'test error from python test_syslog')
 
+    def test_syslog_implicit_open(self):
+        syslog.closelog() # Make sure log is closed
+        syslog.syslog('test message from python test_syslog')
+        syslog.syslog(syslog.LOG_ERR, 'test error from python test_syslog')
+
     def test_closelog(self):
         syslog.openlog('python')
         syslog.closelog()
+        syslog.closelog()  # idempotent operation
 
     def test_setlogmask(self):
-        syslog.setlogmask(syslog.LOG_DEBUG)
+        mask = syslog.LOG_UPTO(syslog.LOG_WARNING)
+        oldmask = syslog.setlogmask(mask)
+        self.assertEqual(syslog.setlogmask(0), mask)
+        self.assertEqual(syslog.setlogmask(oldmask), mask)
 
     def test_log_mask(self):
-        syslog.LOG_MASK(syslog.LOG_INFO)
-
-    def test_log_upto(self):
-        syslog.LOG_UPTO(syslog.LOG_INFO)
+        mask = syslog.LOG_UPTO(syslog.LOG_WARNING)
+        self.assertTrue(mask & syslog.LOG_MASK(syslog.LOG_WARNING))
+        self.assertTrue(mask & syslog.LOG_MASK(syslog.LOG_ERR))
+        self.assertFalse(mask & syslog.LOG_MASK(syslog.LOG_INFO))
 
     def test_openlog_noargs(self):
         syslog.openlog()
         syslog.syslog('test message from python test_syslog')
 
+    @threading_helper.requires_working_threading()
+    def test_syslog_threaded(self):
+        start = threading.Event()
+        stop = False
+        def opener():
+            start.wait(10)
+            i = 1
+            while not stop:
+                syslog.openlog(f'python-test-{i}')  # new string object
+                i += 1
+        def logger():
+            start.wait(10)
+            while not stop:
+                syslog.syslog('test message from python test_syslog')
+
+        orig_si = sys.getswitchinterval()
+        support.setswitchinterval(1e-9)
+        try:
+            threads = [threading.Thread(target=opener)]
+            threads += [threading.Thread(target=logger) for k in range(10)]
+            with threading_helper.start_threads(threads):
+                start.set()
+                time.sleep(0.1)
+                stop = True
+        finally:
+            sys.setswitchinterval(orig_si)
+
+
 if __name__ == "__main__":
     unittest.main()
diff --git a/Lib/test/test_tokenize.py b/Lib/test/test_tokenize.py
index 1272e1e9be..47f2c06685 100644
--- a/Lib/test/test_tokenize.py
+++ b/Lib/test/test_tokenize.py
@@ -3,7 +3,7 @@
 from tokenize import (tokenize, _tokenize, untokenize, NUMBER, NAME, OP,
                      STRING, ENDMARKER, ENCODING, tok_name, detect_encoding,
                      open as tokenize_open, Untokenizer, generate_tokens,
-                     NEWLINE, _generate_tokens_from_c_tokenizer)
+                     NEWLINE, _generate_tokens_from_c_tokenizer, DEDENT)
 from io import BytesIO, StringIO
 import unittest
 from textwrap import dedent
@@ -2512,6 +2512,26 @@ def get_tokens(string):
         self.assertRaises(SyntaxError, get_tokens, "("*1000+"a"+")"*1000)
         self.assertRaises(SyntaxError, get_tokens, "]")
 
+    def test_max_indent(self):
+        MAXINDENT = 100
+
+        def generate_source(indents):
+            source = ''.join(('  ' * x) + 'if True:\n' for x in range(indents))
+            source += '  ' * indents + 'pass\n'
+            return source
+
+        valid = generate_source(MAXINDENT - 1)
+        tokens = list(_generate_tokens_from_c_tokenizer(valid))
+        self.assertEqual(tokens[-1].type, DEDENT)
+        compile(valid, "<string>", "exec")
+
+        invalid = generate_source(MAXINDENT)
+        tokens = list(_generate_tokens_from_c_tokenizer(invalid))
+        self.assertEqual(tokens[-1].type, NEWLINE)
+        self.assertRaises(
+            IndentationError, compile, invalid, "<string>", "exec"
+        )
+
     def test_continuation_lines_indentation(self):
         def get_tokens(string):
             return [(kind, string) for (kind, string, *_) in _generate_tokens_from_c_tokenizer(string)]
diff --git a/Lib/test/test_tools/test_i18n.py b/Lib/test/test_tools/test_i18n.py
index 7f18edaaa8..c083a04475 100644
--- a/Lib/test/test_tools/test_i18n.py
+++ b/Lib/test/test_tools/test_i18n.py
@@ -155,6 +155,26 @@ class C:
         '''))
         self.assertFalse([msgid for msgid in msgids if 'doc' in msgid])
 
+    def test_moduledocstring(self):
+        for doc in ('"""doc"""', "r'''doc'''", "R'doc'", 'u"doc"'):
+            with self.subTest(doc):
+                msgids = self.extract_docstrings_from_str(dedent('''\
+                %s
+                ''' % doc))
+                self.assertIn('doc', msgids)
+
+    def test_moduledocstring_bytes(self):
+        msgids = self.extract_docstrings_from_str(dedent('''\
+        b"""doc"""
+        '''))
+        self.assertFalse([msgid for msgid in msgids if 'doc' in msgid])
+
+    def test_moduledocstring_fstring(self):
+        msgids = self.extract_docstrings_from_str(dedent('''\
+        f"""doc"""
+        '''))
+        self.assertFalse([msgid for msgid in msgids if 'doc' in msgid])
+
     def test_msgid(self):
         msgids = self.extract_docstrings_from_str(
                 '''_("""doc""" r'str' u"ing")''')
diff --git a/Lib/test/test_traceback.py b/Lib/test/test_traceback.py
index 94ccc3f48d..6d15500656 100644
--- a/Lib/test/test_traceback.py
+++ b/Lib/test/test_traceback.py
@@ -778,6 +778,56 @@ def f():
         ]
         self.assertEqual(actual, expected)
 
+    def test_wide_characters_unicode_with_problematic_byte_offset(self):
+        def f():
+            
+
+        actual = self.get_exception(f)
+        expected = [
+            f"Traceback (most recent call last):",
+            f"  File \"{__file__}\", line {self.callable_line}, in get_exception",
+            f"    callable()",
+            f"  File \"{__file__}\", line {f.__code__.co_firstlineno + 1}, in f",
+            f"    ",
+        ]
+        self.assertEqual(actual, expected)
+
+
+    def test_byte_offset_with_wide_characters_middle(self):
+        def f():
+             = 1
+            raise ValueError()
+
+        actual = self.get_exception(f)
+        expected = [
+            f"Traceback (most recent call last):",
+            f"  File \"{__file__}\", line {self.callable_line}, in get_exception",
+            f"    callable()",
+            f"  File \"{__file__}\", line {f.__code__.co_firstlineno + 2}, in f",
+            f"    raise ValueError()",
+        ]
+        self.assertEqual(actual, expected)
+
+    def test_byte_offset_multiline(self):
+        def f():
+             = 1
+             = 0
+
+            print(1, (
+                    ))
+
+        actual = self.get_exception(f)
+        expected = [
+            f"Traceback (most recent call last):",
+            f"  File \"{__file__}\", line {self.callable_line}, in get_exception",
+            f"    callable()",
+            f"  File \"{__file__}\", line {f.__code__.co_firstlineno + 4}, in f",
+            f"    print(1, (",
+            f"             ^^^^",
+        ]
+        self.assertEqual(actual, expected)
+
+
 @cpython_only
 @requires_debug_ranges()
 class CPythonTracebackErrorCaretTests(TracebackErrorLocationCaretTests):
diff --git a/Lib/test/test_typing.py b/Lib/test/test_typing.py
index 776a6f003c..3b0d767546 100644
--- a/Lib/test/test_typing.py
+++ b/Lib/test/test_typing.py
@@ -42,7 +42,7 @@
 import weakref
 import types
 
-from test.support import import_helper, captured_stderr
+from test.support import import_helper, captured_stderr, cpython_only
 from test import mod_generics_cache
 from test import _typed_dict_helper
 
@@ -50,6 +50,8 @@
 py_typing = import_helper.import_fresh_module('typing', blocked=['_typing'])
 c_typing = import_helper.import_fresh_module('typing', fresh=['_typing'])
 
+CANNOT_SUBCLASS_TYPE = 'Cannot subclass special typing classes'
+
 
 class BaseTestCase(TestCase):
 
@@ -109,6 +111,12 @@ def test_any_instance_type_error(self):
     def test_repr(self):
         self.assertEqual(repr(Any), 'typing.Any')
 
+        class Sub(Any): pass
+        self.assertEqual(
+            repr(Sub),
+            "<class 'test.test_typing.AnyTests.test_repr.<locals>.Sub'>",
+        )
+
     def test_errors(self):
         with self.assertRaises(TypeError):
             issubclass(42, Any)
@@ -581,10 +589,9 @@ def test_no_duplicates_if_replacement_not_in_templates(self):
 class GenericAliasSubstitutionTests(BaseTestCase):
     """Tests for type variable substitution in generic aliases.
 
-    Note that the expected results here are tentative, based on a
-    still-being-worked-out spec for what we allow at runtime (given that
-    implementation of *full* substitution logic at runtime would add too much
-    complexity to typing.py). This spec is currently being discussed at
+    For variadic cases, these tests should be regarded as the source of truth,
+    since we hadn't realised the full complexity of variadic substitution
+    at the time of finalizing PEP 646. For full discussion, see
     https://github.com/python/cpython/issues/91162.
     """
 
@@ -671,9 +678,6 @@ class C(Generic[T1, T2]): pass
 
             ('generic[T1, T2]',                        '[tuple_type[int, ...]]',                            'TypeError'),
             ('generic[T1, T2]',                        '[tuple_type[int, ...], tuple_type[str, ...]]',      'generic[tuple_type[int, ...], tuple_type[str, ...]]'),
-            # Should raise TypeError according to the tentative spec: unpacked
-            # types cannot be used as arguments to aliases that expect a fixed
-            # number of arguments.
             ('generic[T1, T2]',                        '[*tuple_type[int, ...]]',                           'TypeError'),
             ('generic[T1, T2]',                        '[int, *tuple_type[str, ...]]',                      'TypeError'),
             ('generic[T1, T2]',                        '[*tuple_type[int, ...], str]',                      'TypeError'),
@@ -681,10 +685,12 @@ class C(Generic[T1, T2]): pass
             ('generic[T1, T2]',                        '[*Ts]',                                             'TypeError'),
             ('generic[T1, T2]',                        '[T, *Ts]',                                          'TypeError'),
             ('generic[T1, T2]',                        '[*Ts, T]',                                          'TypeError'),
-            # Should raise TypeError according to the tentative spec: unpacked
-            # types cannot be used as arguments to generics that expect a fixed
-            # number of arguments.
-            # (None of the things in `generics` were defined using *Ts.)
+            # This one isn't technically valid - none of the things that
+            # `generic` can be (defined in `generics` above) are variadic, so we
+            # shouldn't really be able to do `generic[T1, *tuple_type[int, ...]]`.
+            # So even if type checkers shouldn't allow it, we allow it at
+            # runtime, in accordance with a general philosophy of "Keep the
+            # runtime lenient so people can experiment with typing constructs".
             ('generic[T1, *tuple_type[int, ...]]',     '[str]',                                             'generic[str, *tuple_type[int, ...]]'),
         ]
 
@@ -746,8 +752,6 @@ class C(Generic[*Ts]): pass
         generics = ['C', 'tuple', 'Tuple']
         tuple_types = ['tuple', 'Tuple']
 
-        # The majority of these have three separate cases for C, tuple and
-        # Tuple because tuple currently behaves differently.
         tests = [
             # Alias                                    # Args                                            # Expected result
             ('generic[*Ts]',                           '[()]',                                           'generic[()]'),
@@ -780,7 +784,11 @@ class C(Generic[*Ts]): pass
             ('generic[*Ts, list[T]]',                  '[int, str, bool]',                               'generic[int, str, list[bool]]'),
 
             ('generic[T, *Ts]',                        '[*tuple_type[int, ...]]',                        'generic[int, *tuple_type[int, ...]]'),
+            ('generic[T, *Ts]',                        '[str, *tuple_type[int, ...]]',                   'generic[str, *tuple_type[int, ...]]'),
+            ('generic[T, *Ts]',                        '[*tuple_type[int, ...], str]',                   'generic[int, *tuple_type[int, ...], str]'),
             ('generic[*Ts, T]',                        '[*tuple_type[int, ...]]',                        'generic[*tuple_type[int, ...], int]'),
+            ('generic[*Ts, T]',                        '[str, *tuple_type[int, ...]]',                   'generic[str, *tuple_type[int, ...], int]'),
+            ('generic[*Ts, T]',                        '[*tuple_type[int, ...], str]',                   'generic[*tuple_type[int, ...], str]'),
             ('generic[T1, *Ts, T2]',                   '[*tuple_type[int, ...]]',                        'generic[int, *tuple_type[int, ...], int]'),
             ('generic[T, str, *Ts]',                   '[*tuple_type[int, ...]]',                        'generic[int, str, *tuple_type[int, ...]]'),
             ('generic[*Ts, str, T]',                   '[*tuple_type[int, ...]]',                        'generic[*tuple_type[int, ...], str, int]'),
@@ -819,13 +827,19 @@ class C(Generic[*Ts]): pass
 class UnpackTests(BaseTestCase):
 
     def test_accepts_single_type(self):
+        (*tuple[int],)
         Unpack[Tuple[int]]
 
     def test_rejects_multiple_types(self):
         with self.assertRaises(TypeError):
             Unpack[Tuple[int], Tuple[str]]
+        # We can't do the equivalent for `*` here -
+        # *(Tuple[int], Tuple[str]) is just plain tuple unpacking,
+        # which is valid.
 
     def test_rejects_multiple_parameterization(self):
+        with self.assertRaises(TypeError):
+            (*tuple[int],)[0][tuple[int]]
         with self.assertRaises(TypeError):
             Unpack[Tuple[int]][Tuple[int]]
 
@@ -864,19 +878,20 @@ def test_cannot_call_instance(self):
 
     def test_unpacked_typevartuple_is_equal_to_itself(self):
         Ts = TypeVarTuple('Ts')
+        self.assertEqual((*Ts,)[0], (*Ts,)[0])
         self.assertEqual(Unpack[Ts], Unpack[Ts])
 
     def test_parameterised_tuple_is_equal_to_itself(self):
         Ts = TypeVarTuple('Ts')
-        self.assertEqual(tuple[Unpack[Ts]], tuple[Unpack[Ts]])
+        self.assertEqual(tuple[*Ts], tuple[*Ts])
         self.assertEqual(Tuple[Unpack[Ts]], Tuple[Unpack[Ts]])
 
     def tests_tuple_arg_ordering_matters(self):
         Ts1 = TypeVarTuple('Ts1')
         Ts2 = TypeVarTuple('Ts2')
         self.assertNotEqual(
-            tuple[Unpack[Ts1], Unpack[Ts2]],
-            tuple[Unpack[Ts2], Unpack[Ts1]],
+            tuple[*Ts1, *Ts2],
+            tuple[*Ts2, *Ts1],
         )
         self.assertNotEqual(
             Tuple[Unpack[Ts1], Unpack[Ts2]],
@@ -885,8 +900,8 @@ def tests_tuple_arg_ordering_matters(self):
 
     def test_tuple_args_and_parameters_are_correct(self):
         Ts = TypeVarTuple('Ts')
-        t1 = tuple[Unpack[Ts]]
-        self.assertEqual(t1.__args__, (Unpack[Ts],))
+        t1 = tuple[*Ts]
+        self.assertEqual(t1.__args__, (*Ts,))
         self.assertEqual(t1.__parameters__, (Ts,))
         t2 = Tuple[Unpack[Ts]]
         self.assertEqual(t2.__args__, (Unpack[Ts],))
@@ -896,128 +911,218 @@ def test_var_substitution(self):
         Ts = TypeVarTuple('Ts')
         T = TypeVar('T')
         T2 = TypeVar('T2')
-        class G(Generic[Unpack[Ts]]): pass
+        class G1(Generic[*Ts]): pass
+        class G2(Generic[Unpack[Ts]]): pass
 
-        for A in G, Tuple, tuple:
-            B = A[Unpack[Ts]]
+        for A in G1, G2, Tuple, tuple:
+            B = A[*Ts]
             self.assertEqual(B[()], A[()])
             self.assertEqual(B[float], A[float])
             self.assertEqual(B[float, str], A[float, str])
 
-            C = List[A[Unpack[Ts]]]
-            self.assertEqual(C[()], List[A[()]])
-            self.assertEqual(C[float], List[A[float]])
-            self.assertEqual(C[float, str], List[A[float, str]])
+            C = A[Unpack[Ts]]
+            self.assertEqual(C[()], A[()])
+            self.assertEqual(C[float], A[float])
+            self.assertEqual(C[float, str], A[float, str])
 
-            D = A[T, Unpack[Ts], T2]
+            D = list[A[*Ts]]
+            self.assertEqual(D[()], list[A[()]])
+            self.assertEqual(D[float], list[A[float]])
+            self.assertEqual(D[float, str], list[A[float, str]])
+
+            E = List[A[Unpack[Ts]]]
+            self.assertEqual(E[()], List[A[()]])
+            self.assertEqual(E[float], List[A[float]])
+            self.assertEqual(E[float, str], List[A[float, str]])
+
+            F = A[T, *Ts, T2]
             with self.assertRaises(TypeError):
-                D[()]
+                F[()]
             with self.assertRaises(TypeError):
-                D[float]
-            self.assertEqual(D[float, str], A[float, str])
-            self.assertEqual(D[float, str, int], A[float, str, int])
-            self.assertEqual(D[float, str, int, bytes], A[float, str, int, bytes])
+                F[float]
+            self.assertEqual(F[float, str], A[float, str])
+            self.assertEqual(F[float, str, int], A[float, str, int])
+            self.assertEqual(F[float, str, int, bytes], A[float, str, int, bytes])
 
-            E = Tuple[List[T], A[Unpack[Ts]], List[T2]]
+            G = A[T, Unpack[Ts], T2]
             with self.assertRaises(TypeError):
-                E[()]
+                G[()]
+            with self.assertRaises(TypeError):
+                G[float]
+            self.assertEqual(G[float, str], A[float, str])
+            self.assertEqual(G[float, str, int], A[float, str, int])
+            self.assertEqual(G[float, str, int, bytes], A[float, str, int, bytes])
+
+            H = tuple[list[T], A[*Ts], list[T2]]
             with self.assertRaises(TypeError):
-                E[float]
+                H[()]
+            with self.assertRaises(TypeError):
+                H[float]
+            if A != Tuple:
+                self.assertEqual(H[float, str],
+                                 tuple[list[float], A[()], list[str]])
+            self.assertEqual(H[float, str, int],
+                             tuple[list[float], A[str], list[int]])
+            self.assertEqual(H[float, str, int, bytes],
+                             tuple[list[float], A[str, int], list[bytes]])
+
+            I = Tuple[List[T], A[Unpack[Ts]], List[T2]]
+            with self.assertRaises(TypeError):
+                I[()]
+            with self.assertRaises(TypeError):
+                I[float]
             if A != Tuple:
-                self.assertEqual(E[float, str],
+                self.assertEqual(I[float, str],
                                  Tuple[List[float], A[()], List[str]])
-            self.assertEqual(E[float, str, int],
+            self.assertEqual(I[float, str, int],
                              Tuple[List[float], A[str], List[int]])
-            self.assertEqual(E[float, str, int, bytes],
+            self.assertEqual(I[float, str, int, bytes],
                              Tuple[List[float], A[str, int], List[bytes]])
 
     def test_bad_var_substitution(self):
         Ts = TypeVarTuple('Ts')
         T = TypeVar('T')
         T2 = TypeVar('T2')
-        class G(Generic[Unpack[Ts]]): pass
+        class G1(Generic[*Ts]): pass
+        class G2(Generic[Unpack[Ts]]): pass
 
-        for A in G, Tuple, tuple:
+        for A in G1, G2, Tuple, tuple:
             B = A[Ts]
             with self.assertRaises(TypeError):
                 B[int, str]
 
             C = A[T, T2]
+            with self.assertRaises(TypeError):
+                C[*Ts]
             with self.assertRaises(TypeError):
                 C[Unpack[Ts]]
 
-    def test_repr_is_correct(self):
-        Ts = TypeVarTuple('Ts')
-        T = TypeVar('T')
-        T2 = TypeVar('T2')
-        class G(Generic[Unpack[Ts]]): pass
-
-        for A in G, Tuple:
-            B = A[T, Unpack[Ts], str, T2]
+            B = A[T, *Ts, str, T2]
+            with self.assertRaises(TypeError):
+                B[int, *Ts]
             with self.assertRaises(TypeError):
-                B[int, Unpack[Ts]]
+                B[int, *Ts, *Ts]
+
             C = A[T, Unpack[Ts], str, T2]
+            with self.assertRaises(TypeError):
+                C[int, Unpack[Ts]]
             with self.assertRaises(TypeError):
                 C[int, Unpack[Ts], Unpack[Ts]]
 
     def test_repr_is_correct(self):
         Ts = TypeVarTuple('Ts')
+        T = TypeVar('T')
+        T2 = TypeVar('T2')
+
+        class G1(Generic[*Ts]): pass
+        class G2(Generic[Unpack[Ts]]): pass
+
         self.assertEqual(repr(Ts), 'Ts')
+
+        self.assertEqual(repr((*Ts,)[0]), '*Ts')
         self.assertEqual(repr(Unpack[Ts]), '*Ts')
-        self.assertEqual(repr(tuple[Unpack[Ts]]), 'tuple[*Ts]')
+
+        self.assertEqual(repr(tuple[*Ts]), 'tuple[*Ts]')
         self.assertEqual(repr(Tuple[Unpack[Ts]]), 'typing.Tuple[*Ts]')
-        self.assertEqual(repr(Unpack[tuple[Unpack[Ts]]]), '*tuple[*Ts]')
+
+        self.assertEqual(repr(*tuple[*Ts]), '*tuple[*Ts]')
         self.assertEqual(repr(Unpack[Tuple[Unpack[Ts]]]), '*typing.Tuple[*Ts]')
 
     def test_variadic_class_repr_is_correct(self):
         Ts = TypeVarTuple('Ts')
-        class A(Generic[Unpack[Ts]]): pass
+        class A(Generic[*Ts]): pass
+        class B(Generic[Unpack[Ts]]): pass
 
         self.assertEndsWith(repr(A[()]), 'A[()]')
+        self.assertEndsWith(repr(B[()]), 'B[()]')
         self.assertEndsWith(repr(A[float]), 'A[float]')
+        self.assertEndsWith(repr(B[float]), 'B[float]')
         self.assertEndsWith(repr(A[float, str]), 'A[float, str]')
-        self.assertEndsWith(repr(A[Unpack[tuple[int, ...]]]),
+        self.assertEndsWith(repr(B[float, str]), 'B[float, str]')
+
+        self.assertEndsWith(repr(A[*tuple[int, ...]]),
                             'A[*tuple[int, ...]]')
-        self.assertEndsWith(repr(A[float, Unpack[tuple[int, ...]]]),
+        self.assertEndsWith(repr(B[Unpack[Tuple[int, ...]]]),
+                            'B[*typing.Tuple[int, ...]]')
+
+        self.assertEndsWith(repr(A[float, *tuple[int, ...]]),
                             'A[float, *tuple[int, ...]]')
-        self.assertEndsWith(repr(A[Unpack[tuple[int, ...]], str]),
+        self.assertEndsWith(repr(A[float, Unpack[Tuple[int, ...]]]),
+                            'A[float, *typing.Tuple[int, ...]]')
+
+        self.assertEndsWith(repr(A[*tuple[int, ...], str]),
                             'A[*tuple[int, ...], str]')
-        self.assertEndsWith(repr(A[float, Unpack[tuple[int, ...]], str]),
+        self.assertEndsWith(repr(B[Unpack[Tuple[int, ...]], str]),
+                            'B[*typing.Tuple[int, ...], str]')
+
+        self.assertEndsWith(repr(A[float, *tuple[int, ...], str]),
                             'A[float, *tuple[int, ...], str]')
+        self.assertEndsWith(repr(B[float, Unpack[Tuple[int, ...]], str]),
+                            'B[float, *typing.Tuple[int, ...], str]')
 
     def test_variadic_class_alias_repr_is_correct(self):
         Ts = TypeVarTuple('Ts')
         class A(Generic[Unpack[Ts]]): pass
 
-        B = A[Unpack[Ts]]
+        B = A[*Ts]
         self.assertEndsWith(repr(B), 'A[*Ts]')
         self.assertEndsWith(repr(B[()]), 'A[()]')
         self.assertEndsWith(repr(B[float]), 'A[float]')
         self.assertEndsWith(repr(B[float, str]), 'A[float, str]')
 
-        C = A[Unpack[Ts], int]
-        self.assertEndsWith(repr(C), 'A[*Ts, int]')
-        self.assertEndsWith(repr(C[()]), 'A[int]')
-        self.assertEndsWith(repr(C[float]), 'A[float, int]')
-        self.assertEndsWith(repr(C[float, str]), 'A[float, str, int]')
+        C = A[Unpack[Ts]]
+        self.assertEndsWith(repr(C), 'A[*Ts]')
+        self.assertEndsWith(repr(C[()]), 'A[()]')
+        self.assertEndsWith(repr(C[float]), 'A[float]')
+        self.assertEndsWith(repr(C[float, str]), 'A[float, str]')
 
-        D = A[int, Unpack[Ts]]
-        self.assertEndsWith(repr(D), 'A[int, *Ts]')
+        D = A[*Ts, int]
+        self.assertEndsWith(repr(D), 'A[*Ts, int]')
         self.assertEndsWith(repr(D[()]), 'A[int]')
-        self.assertEndsWith(repr(D[float]), 'A[int, float]')
-        self.assertEndsWith(repr(D[float, str]), 'A[int, float, str]')
-
-        E = A[int, Unpack[Ts], str]
-        self.assertEndsWith(repr(E), 'A[int, *Ts, str]')
-        self.assertEndsWith(repr(E[()]), 'A[int, str]')
-        self.assertEndsWith(repr(E[float]), 'A[int, float, str]')
-        self.assertEndsWith(repr(E[float, str]), 'A[int, float, str, str]')
-
-        F = A[Unpack[Ts], Unpack[tuple[str, ...]]]
-        self.assertEndsWith(repr(F), 'A[*Ts, *tuple[str, ...]]')
-        self.assertEndsWith(repr(F[()]), 'A[*tuple[str, ...]]')
-        self.assertEndsWith(repr(F[float]), 'A[float, *tuple[str, ...]]')
-        self.assertEndsWith(repr(F[float, str]), 'A[float, str, *tuple[str, ...]]')
+        self.assertEndsWith(repr(D[float]), 'A[float, int]')
+        self.assertEndsWith(repr(D[float, str]), 'A[float, str, int]')
+
+        E = A[Unpack[Ts], int]
+        self.assertEndsWith(repr(E), 'A[*Ts, int]')
+        self.assertEndsWith(repr(E[()]), 'A[int]')
+        self.assertEndsWith(repr(E[float]), 'A[float, int]')
+        self.assertEndsWith(repr(E[float, str]), 'A[float, str, int]')
+
+        F = A[int, *Ts]
+        self.assertEndsWith(repr(F), 'A[int, *Ts]')
+        self.assertEndsWith(repr(F[()]), 'A[int]')
+        self.assertEndsWith(repr(F[float]), 'A[int, float]')
+        self.assertEndsWith(repr(F[float, str]), 'A[int, float, str]')
+
+        G = A[int, Unpack[Ts]]
+        self.assertEndsWith(repr(G), 'A[int, *Ts]')
+        self.assertEndsWith(repr(G[()]), 'A[int]')
+        self.assertEndsWith(repr(G[float]), 'A[int, float]')
+        self.assertEndsWith(repr(G[float, str]), 'A[int, float, str]')
+
+        H = A[int, *Ts, str]
+        self.assertEndsWith(repr(H), 'A[int, *Ts, str]')
+        self.assertEndsWith(repr(H[()]), 'A[int, str]')
+        self.assertEndsWith(repr(H[float]), 'A[int, float, str]')
+        self.assertEndsWith(repr(H[float, str]), 'A[int, float, str, str]')
+
+        I = A[int, Unpack[Ts], str]
+        self.assertEndsWith(repr(I), 'A[int, *Ts, str]')
+        self.assertEndsWith(repr(I[()]), 'A[int, str]')
+        self.assertEndsWith(repr(I[float]), 'A[int, float, str]')
+        self.assertEndsWith(repr(I[float, str]), 'A[int, float, str, str]')
+
+        J = A[*Ts, *tuple[str, ...]]
+        self.assertEndsWith(repr(J), 'A[*Ts, *tuple[str, ...]]')
+        self.assertEndsWith(repr(J[()]), 'A[*tuple[str, ...]]')
+        self.assertEndsWith(repr(J[float]), 'A[float, *tuple[str, ...]]')
+        self.assertEndsWith(repr(J[float, str]), 'A[float, str, *tuple[str, ...]]')
+
+        K = A[Unpack[Ts], Unpack[Tuple[str, ...]]]
+        self.assertEndsWith(repr(K), 'A[*Ts, *typing.Tuple[str, ...]]')
+        self.assertEndsWith(repr(K[()]), 'A[*typing.Tuple[str, ...]]')
+        self.assertEndsWith(repr(K[float]), 'A[float, *typing.Tuple[str, ...]]')
+        self.assertEndsWith(repr(K[float, str]), 'A[float, str, *typing.Tuple[str, ...]]')
 
     def test_cannot_subclass_class(self):
         with self.assertRaises(TypeError):
@@ -1027,30 +1132,69 @@ def test_cannot_subclass_instance(self):
         Ts = TypeVarTuple('Ts')
         with self.assertRaises(TypeError):
             class C(Ts): pass
-        with self.assertRaises(TypeError):
+        with self.assertRaisesRegex(TypeError, CANNOT_SUBCLASS_TYPE):
+            class C(type(Unpack)): pass
+        with self.assertRaisesRegex(TypeError, CANNOT_SUBCLASS_TYPE):
+            class C(type(*Ts)): pass
+        with self.assertRaisesRegex(TypeError, CANNOT_SUBCLASS_TYPE):
+            class C(type(Unpack[Ts])): pass
+        with self.assertRaisesRegex(TypeError,
+                                    r'Cannot subclass typing\.Unpack'):
+            class C(Unpack): pass
+        with self.assertRaisesRegex(TypeError, r'Cannot subclass \*Ts'):
+            class C(*Ts): pass
+        with self.assertRaisesRegex(TypeError, r'Cannot subclass \*Ts'):
             class C(Unpack[Ts]): pass
 
     def test_variadic_class_args_are_correct(self):
         T = TypeVar('T')
         Ts = TypeVarTuple('Ts')
-        class A(Generic[Unpack[Ts]]): pass
-        B = A[()]
-        self.assertEqual(B.__args__, ())
-        C = A[int]
-        self.assertEqual(C.__args__, (int,))
-        D = A[int, str]
-        self.assertEqual(D.__args__, (int, str))
-        E = A[T]
-        self.assertEqual(E.__args__, (T,))
-        F = A[Unpack[Ts]]
-        self.assertEqual(F.__args__, (Unpack[Ts],))
-        G = A[T, Unpack[Ts]]
-        self.assertEqual(G.__args__, (T, Unpack[Ts]))
-        H = A[Unpack[Ts], T]
-        self.assertEqual(H.__args__, (Unpack[Ts], T))
+        class A(Generic[*Ts]): pass
+        class B(Generic[Unpack[Ts]]): pass
+
+        C = A[()]
+        D = B[()]
+        self.assertEqual(C.__args__, ())
+        self.assertEqual(D.__args__, ())
+
+        E = A[int]
+        F = B[int]
+        self.assertEqual(E.__args__, (int,))
+        self.assertEqual(F.__args__, (int,))
+
+        G = A[int, str]
+        H = B[int, str]
+        self.assertEqual(G.__args__, (int, str))
+        self.assertEqual(H.__args__, (int, str))
+
+        I = A[T]
+        J = B[T]
+        self.assertEqual(I.__args__, (T,))
+        self.assertEqual(J.__args__, (T,))
+
+        K = A[*Ts]
+        L = B[Unpack[Ts]]
+        self.assertEqual(K.__args__, (*Ts,))
+        self.assertEqual(L.__args__, (Unpack[Ts],))
+
+        M = A[T, *Ts]
+        N = B[T, Unpack[Ts]]
+        self.assertEqual(M.__args__, (T, *Ts))
+        self.assertEqual(N.__args__, (T, Unpack[Ts]))
+
+        O = A[*Ts, T]
+        P = B[Unpack[Ts], T]
+        self.assertEqual(O.__args__, (*Ts, T))
+        self.assertEqual(P.__args__, (Unpack[Ts], T))
 
     def test_variadic_class_origin_is_correct(self):
         Ts = TypeVarTuple('Ts')
+
+        class C(Generic[*Ts]): pass
+        self.assertIs(C[int].__origin__, C)
+        self.assertIs(C[T].__origin__, C)
+        self.assertIs(C[Unpack[Ts]].__origin__, C)
+
         class D(Generic[Unpack[Ts]]): pass
         self.assertIs(D[int].__origin__, D)
         self.assertIs(D[T].__origin__, D)
@@ -1059,21 +1203,21 @@ class D(Generic[Unpack[Ts]]): pass
     def test_tuple_args_are_correct(self):
         Ts = TypeVarTuple('Ts')
 
-        self.assertEqual(tuple[Unpack[Ts]].__args__, (Unpack[Ts],))
+        self.assertEqual(tuple[*Ts].__args__, (*Ts,))
         self.assertEqual(Tuple[Unpack[Ts]].__args__, (Unpack[Ts],))
 
-        self.assertEqual(tuple[Unpack[Ts], int].__args__, (Unpack[Ts], int))
+        self.assertEqual(tuple[*Ts, int].__args__, (*Ts, int))
         self.assertEqual(Tuple[Unpack[Ts], int].__args__, (Unpack[Ts], int))
 
-        self.assertEqual(tuple[int, Unpack[Ts]].__args__, (int, Unpack[Ts]))
+        self.assertEqual(tuple[int, *Ts].__args__, (int, *Ts))
         self.assertEqual(Tuple[int, Unpack[Ts]].__args__, (int, Unpack[Ts]))
 
-        self.assertEqual(tuple[int, Unpack[Ts], str].__args__,
-                         (int, Unpack[Ts], str))
+        self.assertEqual(tuple[int, *Ts, str].__args__,
+                         (int, *Ts, str))
         self.assertEqual(Tuple[int, Unpack[Ts], str].__args__,
                          (int, Unpack[Ts], str))
 
-        self.assertEqual(tuple[Unpack[Ts], int].__args__, (Unpack[Ts], int))
+        self.assertEqual(tuple[*Ts, int].__args__, (*Ts, int))
         self.assertEqual(Tuple[Unpack[Ts]].__args__, (Unpack[Ts],))
 
     def test_callable_args_are_correct(self):
@@ -1083,63 +1227,97 @@ def test_callable_args_are_correct(self):
 
         # TypeVarTuple in the arguments
 
-        a = Callable[[Unpack[Ts]], None]
-        self.assertEqual(a.__args__, (Unpack[Ts], type(None)))
+        a = Callable[[*Ts], None]
+        b = Callable[[Unpack[Ts]], None]
+        self.assertEqual(a.__args__, (*Ts, type(None)))
+        self.assertEqual(b.__args__, (Unpack[Ts], type(None)))
 
-        b = Callable[[int, Unpack[Ts]], None]
-        self.assertEqual(b.__args__, (int, Unpack[Ts], type(None)))
+        c = Callable[[int, *Ts], None]
+        d = Callable[[int, Unpack[Ts]], None]
+        self.assertEqual(c.__args__, (int, *Ts, type(None)))
+        self.assertEqual(d.__args__, (int, Unpack[Ts], type(None)))
 
-        c = Callable[[Unpack[Ts], int], None]
-        self.assertEqual(c.__args__, (Unpack[Ts], int, type(None)))
+        e = Callable[[*Ts, int], None]
+        f = Callable[[Unpack[Ts], int], None]
+        self.assertEqual(e.__args__, (*Ts, int, type(None)))
+        self.assertEqual(f.__args__, (Unpack[Ts], int, type(None)))
 
-        d = Callable[[str, Unpack[Ts], int], None]
-        self.assertEqual(d.__args__, (str, Unpack[Ts], int, type(None)))
+        g = Callable[[str, *Ts, int], None]
+        h = Callable[[str, Unpack[Ts], int], None]
+        self.assertEqual(g.__args__, (str, *Ts, int, type(None)))
+        self.assertEqual(h.__args__, (str, Unpack[Ts], int, type(None)))
 
         # TypeVarTuple as the return
 
-        e = Callable[[None], Unpack[Ts]]
-        self.assertEqual(e.__args__, (type(None), Unpack[Ts]))
+        i = Callable[[None], *Ts]
+        j = Callable[[None], Unpack[Ts]]
+        self.assertEqual(i.__args__, (type(None), *Ts))
+        self.assertEqual(i.__args__, (type(None), Unpack[Ts]))
 
-        f = Callable[[None], tuple[int, Unpack[Ts]]]
-        self.assertEqual(f.__args__, (type(None), tuple[int, Unpack[Ts]]))
+        k = Callable[[None], tuple[int, *Ts]]
+        l = Callable[[None], Tuple[int, Unpack[Ts]]]
+        self.assertEqual(k.__args__, (type(None), tuple[int, *Ts]))
+        self.assertEqual(l.__args__, (type(None), Tuple[int, Unpack[Ts]]))
 
-        g = Callable[[None], tuple[Unpack[Ts], int]]
-        self.assertEqual(g.__args__, (type(None), tuple[Unpack[Ts], int]))
+        m = Callable[[None], tuple[*Ts, int]]
+        n = Callable[[None], Tuple[Unpack[Ts], int]]
+        self.assertEqual(m.__args__, (type(None), tuple[*Ts, int]))
+        self.assertEqual(n.__args__, (type(None), Tuple[Unpack[Ts], int]))
 
-        h = Callable[[None], tuple[str, Unpack[Ts], int]]
-        self.assertEqual(h.__args__, (type(None), tuple[str, Unpack[Ts], int]))
+        o = Callable[[None], tuple[str, *Ts, int]]
+        p = Callable[[None], Tuple[str, Unpack[Ts], int]]
+        self.assertEqual(o.__args__, (type(None), tuple[str, *Ts, int]))
+        self.assertEqual(p.__args__, (type(None), Tuple[str, Unpack[Ts], int]))
 
         # TypeVarTuple in both
 
-        i = Callable[[Unpack[Ts]], Unpack[Ts]]
-        self.assertEqual(i.__args__, (Unpack[Ts], Unpack[Ts]))
+        q = Callable[[*Ts], *Ts]
+        r = Callable[[Unpack[Ts]], Unpack[Ts]]
+        self.assertEqual(q.__args__, (*Ts, *Ts))
+        self.assertEqual(r.__args__, (Unpack[Ts], Unpack[Ts]))
 
-        j = Callable[[Unpack[Ts1]], Unpack[Ts2]]
-        self.assertEqual(j.__args__, (Unpack[Ts1], Unpack[Ts2]))
+        s = Callable[[*Ts1], *Ts2]
+        u = Callable[[Unpack[Ts1]], Unpack[Ts2]]
+        self.assertEqual(s.__args__, (*Ts1, *Ts2))
+        self.assertEqual(u.__args__, (Unpack[Ts1], Unpack[Ts2]))
 
     def test_variadic_class_with_duplicate_typevartuples_fails(self):
         Ts1 = TypeVarTuple('Ts1')
         Ts2 = TypeVarTuple('Ts2')
+
+        with self.assertRaises(TypeError):
+            class C(Generic[*Ts1, *Ts1]): pass
         with self.assertRaises(TypeError):
             class C(Generic[Unpack[Ts1], Unpack[Ts1]]): pass
+
+        with self.assertRaises(TypeError):
+            class C(Generic[*Ts1, *Ts2, *Ts1]): pass
         with self.assertRaises(TypeError):
             class C(Generic[Unpack[Ts1], Unpack[Ts2], Unpack[Ts1]]): pass
 
     def test_type_concatenation_in_variadic_class_argument_list_succeeds(self):
         Ts = TypeVarTuple('Ts')
         class C(Generic[Unpack[Ts]]): pass
+
+        C[int, *Ts]
         C[int, Unpack[Ts]]
+
+        C[*Ts, int]
         C[Unpack[Ts], int]
+
+        C[int, *Ts, str]
         C[int, Unpack[Ts], str]
+
+        C[int, bool, *Ts, float, str]
         C[int, bool, Unpack[Ts], float, str]
 
     def test_type_concatenation_in_tuple_argument_list_succeeds(self):
         Ts = TypeVarTuple('Ts')
 
-        tuple[int, Unpack[Ts]]
-        tuple[Unpack[Ts], int]
-        tuple[int, Unpack[Ts], str]
-        tuple[int, bool, Unpack[Ts], float, str]
+        tuple[int, *Ts]
+        tuple[*Ts, int]
+        tuple[int, *Ts, str]
+        tuple[int, bool, *Ts, float, str]
 
         Tuple[int, Unpack[Ts]]
         Tuple[Unpack[Ts], int]
@@ -1153,6 +1331,8 @@ class C(Generic[Ts]): pass
 
     def test_variadic_class_definition_using_concrete_types_fails(self):
         Ts = TypeVarTuple('Ts')
+        with self.assertRaises(TypeError):
+            class F(Generic[*Ts, int]): pass
         with self.assertRaises(TypeError):
             class E(Generic[Unpack[Ts], int]): pass
 
@@ -1161,32 +1341,50 @@ def test_variadic_class_with_2_typevars_accepts_2_or_more_args(self):
         T1 = TypeVar('T1')
         T2 = TypeVar('T2')
 
-        class A(Generic[T1, T2, Unpack[Ts]]): pass
+        class A(Generic[T1, T2, *Ts]): pass
         A[int, str]
         A[int, str, float]
         A[int, str, float, bool]
 
-        class B(Generic[T1, Unpack[Ts], T2]): pass
+        class B(Generic[T1, T2, Unpack[Ts]]): pass
         B[int, str]
         B[int, str, float]
         B[int, str, float, bool]
 
-        class C(Generic[Unpack[Ts], T1, T2]): pass
+        class C(Generic[T1, *Ts, T2]): pass
         C[int, str]
         C[int, str, float]
         C[int, str, float, bool]
 
+        class D(Generic[T1, Unpack[Ts], T2]): pass
+        D[int, str]
+        D[int, str, float]
+        D[int, str, float, bool]
+
+        class E(Generic[*Ts, T1, T2]): pass
+        E[int, str]
+        E[int, str, float]
+        E[int, str, float, bool]
+
+        class F(Generic[Unpack[Ts], T1, T2]): pass
+        F[int, str]
+        F[int, str, float]
+        F[int, str, float, bool]
+
     def test_variadic_args_annotations_are_correct(self):
         Ts = TypeVarTuple('Ts')
+
         def f(*args: Unpack[Ts]): pass
+        def g(*args: *Ts): pass
         self.assertEqual(f.__annotations__, {'args': Unpack[Ts]})
+        self.assertEqual(g.__annotations__, {'args': (*Ts,)[0]})
 
     def test_variadic_args_with_ellipsis_annotations_are_correct(self):
         Ts = TypeVarTuple('Ts')
 
-        def a(*args: Unpack[tuple[int, ...]]): pass
+        def a(*args: *tuple[int, ...]): pass
         self.assertEqual(a.__annotations__,
-                         {'args': Unpack[tuple[int, ...]]})
+                         {'args': (*tuple[int, ...],)[0]})
 
         def b(*args: Unpack[Tuple[int, ...]]): pass
         self.assertEqual(b.__annotations__,
@@ -1195,30 +1393,30 @@ def b(*args: Unpack[Tuple[int, ...]]): pass
     def test_concatenation_in_variadic_args_annotations_are_correct(self):
         Ts = TypeVarTuple('Ts')
 
-        # Unpacking using `Unpack`, native `tuple` type
+        # Unpacking using `*`, native `tuple` type
 
-        def a(*args: Unpack[tuple[int, Unpack[Ts]]]): pass
+        def a(*args: *tuple[int, *Ts]): pass
         self.assertEqual(
             a.__annotations__,
-            {'args': Unpack[tuple[int, Unpack[Ts]]]},
+            {'args': (*tuple[int, *Ts],)[0]},
         )
 
-        def b(*args: Unpack[tuple[Unpack[Ts], int]]): pass
+        def b(*args: *tuple[*Ts, int]): pass
         self.assertEqual(
             b.__annotations__,
-            {'args': Unpack[tuple[Unpack[Ts], int]]},
+            {'args': (*tuple[*Ts, int],)[0]},
         )
 
-        def c(*args: Unpack[tuple[str, Unpack[Ts], int]]): pass
+        def c(*args: *tuple[str, *Ts, int]): pass
         self.assertEqual(
             c.__annotations__,
-            {'args': Unpack[tuple[str, Unpack[Ts], int]]},
+            {'args': (*tuple[str, *Ts, int],)[0]},
         )
 
-        def d(*args: Unpack[tuple[int, bool, Unpack[Ts], float, str]]): pass
+        def d(*args: *tuple[int, bool, *Ts, float, str]): pass
         self.assertEqual(
             d.__annotations__,
-            {'args': Unpack[tuple[int, bool, Unpack[Ts], float, str]]},
+            {'args': (*tuple[int, bool, *Ts, float, str],)[0]},
         )
 
         # Unpacking using `Unpack`, `Tuple` type from typing.py
@@ -1249,47 +1447,78 @@ def h(*args: Unpack[Tuple[int, bool, Unpack[Ts], float, str]]): pass
 
     def test_variadic_class_same_args_results_in_equalty(self):
         Ts = TypeVarTuple('Ts')
-        class C(Generic[Unpack[Ts]]): pass
+        class C(Generic[*Ts]): pass
+        class D(Generic[Unpack[Ts]]): pass
 
         self.assertEqual(C[int], C[int])
+        self.assertEqual(D[int], D[int])
 
         Ts1 = TypeVarTuple('Ts1')
         Ts2 = TypeVarTuple('Ts2')
+
         self.assertEqual(
-            C[Unpack[Ts1]],
-            C[Unpack[Ts1]],
+            C[*Ts1],
+            C[*Ts1],
         )
         self.assertEqual(
-            C[Unpack[Ts1], Unpack[Ts2]],
-            C[Unpack[Ts1], Unpack[Ts2]],
+            D[Unpack[Ts1]],
+            D[Unpack[Ts1]],
         )
+
         self.assertEqual(
-            C[int, Unpack[Ts1], Unpack[Ts2]],
-            C[int, Unpack[Ts1], Unpack[Ts2]],
+            C[*Ts1, *Ts2],
+            C[*Ts1, *Ts2],
+        )
+        self.assertEqual(
+            D[Unpack[Ts1], Unpack[Ts2]],
+            D[Unpack[Ts1], Unpack[Ts2]],
+        )
+
+        self.assertEqual(
+            C[int, *Ts1, *Ts2],
+            C[int, *Ts1, *Ts2],
+        )
+        self.assertEqual(
+            D[int, Unpack[Ts1], Unpack[Ts2]],
+            D[int, Unpack[Ts1], Unpack[Ts2]],
         )
 
     def test_variadic_class_arg_ordering_matters(self):
         Ts = TypeVarTuple('Ts')
-        class C(Generic[Unpack[Ts]]): pass
+        class C(Generic[*Ts]): pass
+        class D(Generic[Unpack[Ts]]): pass
 
         self.assertNotEqual(
             C[int, str],
             C[str, int],
         )
+        self.assertNotEqual(
+            D[int, str],
+            D[str, int],
+        )
 
         Ts1 = TypeVarTuple('Ts1')
         Ts2 = TypeVarTuple('Ts2')
+
         self.assertNotEqual(
-            C[Unpack[Ts1], Unpack[Ts2]],
-            C[Unpack[Ts2], Unpack[Ts1]],
+            C[*Ts1, *Ts2],
+            C[*Ts2, *Ts1],
+        )
+        self.assertNotEqual(
+            D[Unpack[Ts1], Unpack[Ts2]],
+            D[Unpack[Ts2], Unpack[Ts1]],
         )
 
     def test_variadic_class_arg_typevartuple_identity_matters(self):
         Ts = TypeVarTuple('Ts')
-        class C(Generic[Unpack[Ts]]): pass
         Ts1 = TypeVarTuple('Ts1')
         Ts2 = TypeVarTuple('Ts2')
-        self.assertNotEqual(C[Unpack[Ts1]], C[Unpack[Ts2]])
+
+        class C(Generic[*Ts]): pass
+        class D(Generic[Unpack[Ts]]): pass
+
+        self.assertNotEqual(C[*Ts1], C[*Ts2])
+        self.assertNotEqual(D[Unpack[Ts1]], D[Unpack[Ts2]])
 
 
 class TypeVarTuplePicklingTests(BaseTestCase):
@@ -1309,10 +1538,15 @@ def test_pickling_then_unpickling_results_in_same_identity(self, proto):
     def test_pickling_then_unpickling_unpacked_results_in_same_identity(self, proto):
         global global_Ts  # See explanation at start of class.
         global_Ts = TypeVarTuple('global_Ts')
-        unpacked1 = Unpack[global_Ts]
+
+        unpacked1 = (*global_Ts,)[0]
         unpacked2 = pickle.loads(pickle.dumps(unpacked1, proto))
         self.assertIs(unpacked1, unpacked2)
 
+        unpacked3 = Unpack[global_Ts]
+        unpacked4 = pickle.loads(pickle.dumps(unpacked3, proto))
+        self.assertIs(unpacked3, unpacked4)
+
     @all_pickle_protocols
     def test_pickling_then_unpickling_tuple_with_typevartuple_equality(
             self, proto
@@ -1321,17 +1555,19 @@ def test_pickling_then_unpickling_tuple_with_typevartuple_equality(
         global_T = TypeVar('global_T')
         global_Ts = TypeVarTuple('global_Ts')
 
-        a1 = Tuple[Unpack[global_Ts]]
-        a2 = pickle.loads(pickle.dumps(a1, proto))
-        self.assertEqual(a1, a2)
+        tuples = [
+            tuple[*global_Ts],
+            Tuple[Unpack[global_Ts]],
 
-        a1 = Tuple[T, Unpack[global_Ts]]
-        a2 = pickle.loads(pickle.dumps(a1, proto))
-        self.assertEqual(a1, a2)
+            tuple[T, *global_Ts],
+            Tuple[T, Unpack[global_Ts]],
 
-        a1 = Tuple[int, Unpack[global_Ts]]
-        a2 = pickle.loads(pickle.dumps(a1, proto))
-        self.assertEqual(a1, a2)
+            tuple[int, *global_Ts],
+            Tuple[int, Unpack[global_Ts]],
+        ]
+        for t in tuples:
+            t2 = pickle.loads(pickle.dumps(t, proto))
+            self.assertEqual(t, t2)
 
 
 class UnionTests(BaseTestCase):
@@ -3554,11 +3790,11 @@ class D(C):
 
         self.assertEqual(D.__parameters__, ())
 
-        with self.assertRaises(Exception):
+        with self.assertRaises(TypeError):
             D[int]
-        with self.assertRaises(Exception):
+        with self.assertRaises(TypeError):
             D[Any]
-        with self.assertRaises(Exception):
+        with self.assertRaises(TypeError):
             D[T]
 
     def test_new_with_args(self):
@@ -3676,6 +3912,34 @@ class A:
         # C version of GenericAlias
         self.assertEqual(list[A()].__parameters__, (T,))
 
+    def test_non_generic_subscript(self):
+        T = TypeVar('T')
+        class G(Generic[T]):
+            pass
+        class A:
+            __parameters__ = (T,)
+
+        for s in (int, G, A, List, list,
+                  TypeVar, TypeVarTuple, ParamSpec,
+                  types.GenericAlias, types.UnionType):
+
+            for t in Tuple, tuple:
+                with self.subTest(tuple=t, sub=s):
+                    self.assertEqual(t[s, T][int], t[s, int])
+                    self.assertEqual(t[T, s][int], t[int, s])
+                    a = t[s]
+                    with self.assertRaises(TypeError):
+                        a[int]
+
+            for c in Callable, collections.abc.Callable:
+                with self.subTest(callable=c, sub=s):
+                    self.assertEqual(c[[s], T][int], c[[s], int])
+                    self.assertEqual(c[[T], s][int], c[[int], s])
+                    a = c[[s], s]
+                    with self.assertRaises(TypeError):
+                        a[int]
+
+
 class ClassVarTests(BaseTestCase):
 
     def test_basics(self):
@@ -4361,7 +4625,7 @@ def method(self): ...
 class OverloadTests(BaseTestCase):
 
     def test_overload_fails(self):
-        with self.assertRaises(RuntimeError):
+        with self.assertRaises(NotImplementedError):
 
             @overload
             def blah():
@@ -4379,6 +4643,21 @@ def blah():
 
         blah()
 
+    @cpython_only  # gh-98713
+    def test_overload_on_compiled_functions(self):
+        with patch("typing._overload_registry",
+                   defaultdict(lambda: defaultdict(dict))):
+            # The registry starts out empty:
+            self.assertEqual(typing._overload_registry, {})
+
+            # This should just not fail:
+            overload(sum)
+            overload(print)
+
+            # No overloads are recorded (but, it still has a side-effect):
+            self.assertEqual(typing.get_overloads(sum), [])
+            self.assertEqual(typing.get_overloads(print), [])
+
     def set_up_overloads(self):
         def blah():
             pass
@@ -4413,6 +4692,9 @@ def some_other_func(): pass
         other_overload = some_other_func
         def some_other_func(): pass
         self.assertEqual(list(get_overloads(some_other_func)), [other_overload])
+        # Unrelated function still has no overloads:
+        def not_overloaded(): pass
+        self.assertEqual(list(get_overloads(not_overloaded)), [])
 
         # Make sure that after we clear all overloads, the registry is
         # completely empty.
@@ -4882,6 +5164,7 @@ def h(x: collections.abc.Callable[P, int]): ...
 class GetUtilitiesTestCase(TestCase):
     def test_get_origin(self):
         T = TypeVar('T')
+        Ts = TypeVarTuple('Ts')
         P = ParamSpec('P')
         class C(Generic[T]): pass
         self.assertIs(get_origin(C[int]), C)
@@ -4905,6 +5188,10 @@ class C(Generic[T]): pass
         self.assertIs(get_origin(P.kwargs), P)
         self.assertIs(get_origin(Required[int]), Required)
         self.assertIs(get_origin(NotRequired[int]), NotRequired)
+        self.assertIs(get_origin((*Ts,)[0]), Unpack)
+        self.assertIs(get_origin(Unpack[Ts]), Unpack)
+        self.assertIs(get_origin((*tuple[*Ts],)[0]), tuple)
+        self.assertIs(get_origin(Unpack[Tuple[Unpack[Ts]]]), Unpack)
 
     def test_get_args(self):
         T = TypeVar('T')
@@ -4944,6 +5231,16 @@ class C(Generic[T]): pass
         self.assertEqual(get_args(list | str), (list, str))
         self.assertEqual(get_args(Required[int]), (int,))
         self.assertEqual(get_args(NotRequired[int]), (int,))
+        self.assertEqual(get_args(TypeAlias), ())
+        self.assertEqual(get_args(TypeGuard[int]), (int,))
+        Ts = TypeVarTuple('Ts')
+        self.assertEqual(get_args(Ts), ())
+        self.assertEqual(get_args((*Ts,)[0]), (Ts,))
+        self.assertEqual(get_args(Unpack[Ts]), (Ts,))
+        self.assertEqual(get_args(tuple[*Ts]), (*Ts,))
+        self.assertEqual(get_args(tuple[Unpack[Ts]]), (Unpack[Ts],))
+        self.assertEqual(get_args((*tuple[*Ts],)[0]), (*Ts,))
+        self.assertEqual(get_args(Unpack[tuple[Unpack[Ts]]]), (tuple[Unpack[Ts]],))
 
 
 class CollectionsAbcTests(BaseTestCase):
@@ -6609,69 +6906,112 @@ def test_typevar_subst(self):
         T1 = TypeVar('T1')
         T2 = TypeVar('T2')
 
-        A = Annotated[Tuple[Unpack[Ts]], dec]
-        self.assertEqual(A[int], Annotated[Tuple[int], dec])
-        self.assertEqual(A[str, int], Annotated[Tuple[str, int], dec])
+        A = Annotated[tuple[*Ts], dec]
+        self.assertEqual(A[int], Annotated[tuple[int], dec])
+        self.assertEqual(A[str, int], Annotated[tuple[str, int], dec])
         with self.assertRaises(TypeError):
-            Annotated[Unpack[Ts], dec]
+            Annotated[*Ts, dec]
 
-        B = Annotated[Tuple[T, Unpack[Ts]], dec]
+        B = Annotated[Tuple[Unpack[Ts]], dec]
         self.assertEqual(B[int], Annotated[Tuple[int], dec])
-        self.assertEqual(B[int, str], Annotated[Tuple[int, str], dec])
-        self.assertEqual(
-            B[int, str, float],
-            Annotated[Tuple[int, str, float], dec]
-        )
+        self.assertEqual(B[str, int], Annotated[Tuple[str, int], dec])
         with self.assertRaises(TypeError):
-            B[()]
+            Annotated[Unpack[Ts], dec]
 
-        C = Annotated[Tuple[Unpack[Ts], T], dec]
-        self.assertEqual(C[int], Annotated[Tuple[int], dec])
-        self.assertEqual(C[int, str], Annotated[Tuple[int, str], dec])
+        C = Annotated[tuple[T, *Ts], dec]
+        self.assertEqual(C[int], Annotated[tuple[int], dec])
+        self.assertEqual(C[int, str], Annotated[tuple[int, str], dec])
         self.assertEqual(
             C[int, str, float],
-            Annotated[Tuple[int, str, float], dec]
+            Annotated[tuple[int, str, float], dec]
         )
         with self.assertRaises(TypeError):
             C[()]
 
-        D = Annotated[Tuple[T1, Unpack[Ts], T2], dec]
+        D = Annotated[Tuple[T, Unpack[Ts]], dec]
+        self.assertEqual(D[int], Annotated[Tuple[int], dec])
         self.assertEqual(D[int, str], Annotated[Tuple[int, str], dec])
         self.assertEqual(
             D[int, str, float],
             Annotated[Tuple[int, str, float], dec]
         )
+        with self.assertRaises(TypeError):
+            D[()]
+
+        E = Annotated[tuple[*Ts, T], dec]
+        self.assertEqual(E[int], Annotated[tuple[int], dec])
+        self.assertEqual(E[int, str], Annotated[tuple[int, str], dec])
         self.assertEqual(
-            D[int, str, bool, float],
-            Annotated[Tuple[int, str, bool, float], dec]
+            E[int, str, float],
+            Annotated[tuple[int, str, float], dec]
         )
         with self.assertRaises(TypeError):
-            D[int]
-
-        # Now let's try creating an alias from an alias.
+            E[()]
 
-        Ts2 = TypeVarTuple('Ts2')
-        T3 = TypeVar('T3')
-        T4 = TypeVar('T4')
+        F = Annotated[Tuple[Unpack[Ts], T], dec]
+        self.assertEqual(F[int], Annotated[Tuple[int], dec])
+        self.assertEqual(F[int, str], Annotated[Tuple[int, str], dec])
+        self.assertEqual(
+            F[int, str, float],
+            Annotated[Tuple[int, str, float], dec]
+        )
+        with self.assertRaises(TypeError):
+            F[()]
 
-        E = D[T3, Unpack[Ts2], T4]
+        G = Annotated[tuple[T1, *Ts, T2], dec]
+        self.assertEqual(G[int, str], Annotated[tuple[int, str], dec])
         self.assertEqual(
-            E,
-            Annotated[Tuple[T3, Unpack[Ts2], T4], dec]
+            G[int, str, float],
+            Annotated[tuple[int, str, float], dec]
         )
         self.assertEqual(
-            E[int, str], Annotated[Tuple[int, str], dec]
+            G[int, str, bool, float],
+            Annotated[tuple[int, str, bool, float], dec]
         )
+        with self.assertRaises(TypeError):
+            G[int]
+
+        H = Annotated[Tuple[T1, Unpack[Ts], T2], dec]
+        self.assertEqual(H[int, str], Annotated[Tuple[int, str], dec])
         self.assertEqual(
-            E[int, str, float],
+            H[int, str, float],
             Annotated[Tuple[int, str, float], dec]
         )
         self.assertEqual(
-            E[int, str, bool, float],
+            H[int, str, bool, float],
             Annotated[Tuple[int, str, bool, float], dec]
         )
         with self.assertRaises(TypeError):
-            E[int]
+            H[int]
+
+        # Now let's try creating an alias from an alias.
+
+        Ts2 = TypeVarTuple('Ts2')
+        T3 = TypeVar('T3')
+        T4 = TypeVar('T4')
+
+        # G is Annotated[tuple[T1, *Ts, T2], dec].
+        I = G[T3, *Ts2, T4]
+        J = G[T3, Unpack[Ts2], T4]
+
+        for x, y in [
+            (I,                  Annotated[tuple[T3, *Ts2, T4], dec]),
+            (J,                  Annotated[tuple[T3, Unpack[Ts2], T4], dec]),
+            (I[int, str],        Annotated[tuple[int, str], dec]),
+            (J[int, str],        Annotated[tuple[int, str], dec]),
+            (I[int, str, float], Annotated[tuple[int, str, float], dec]),
+            (J[int, str, float], Annotated[tuple[int, str, float], dec]),
+            (I[int, str, bool, float],
+                                 Annotated[tuple[int, str, bool, float], dec]),
+            (J[int, str, bool, float],
+                                 Annotated[tuple[int, str, bool, float], dec]),
+        ]:
+            self.assertEqual(x, y)
+
+        with self.assertRaises(TypeError):
+            I[int]
+        with self.assertRaises(TypeError):
+            J[int]
 
     def test_annotated_in_other_types(self):
         X = List[Annotated[T, 5]]
diff --git a/Lib/test/test_unicode.py b/Lib/test/test_unicode.py
index 90bd75f550..c8c07a463d 100644
--- a/Lib/test/test_unicode.py
+++ b/Lib/test/test_unicode.py
@@ -257,6 +257,20 @@ def test_find(self):
         self.checkequalnofix(9,  'abcdefghiabc', 'find', 'abc', 1)
         self.checkequalnofix(-1, 'abcdefghiabc', 'find', 'def', 4)
 
+        # test utf-8 non-ascii char
+        self.checkequal(0, '', 'find', '')
+        self.checkequal(3, '', 'find', '', 1)
+        self.checkequal(-1, '', 'find', '', 1, 3)
+        self.checkequal(-1, '', 'find', 'e')  # english `e`
+        # test utf-8 non-ascii slice
+        self.checkequal(1, ' ', 'find', '')
+        self.checkequal(1, ' ', 'find', '', 1)
+        self.checkequal(1, ' ', 'find', '', 1, 3)
+        self.checkequal(6, ' ', 'find', '', 2)
+        self.checkequal(-1, ' ', 'find', '', 6, 7)
+        self.checkequal(-1, ' ', 'find', '', 7)
+        self.checkequal(-1, ' ', 'find', 'ec')  # english `ec`
+
         self.assertRaises(TypeError, 'hello'.find)
         self.assertRaises(TypeError, 'hello'.find, 42)
         # test mixed kinds
@@ -287,6 +301,19 @@ def test_rfind(self):
         self.checkequalnofix(9,   'abcdefghiabc', 'rfind', 'abc')
         self.checkequalnofix(12,  'abcdefghiabc', 'rfind', '')
         self.checkequalnofix(12, 'abcdefghiabc', 'rfind',  '')
+        # test utf-8 non-ascii char
+        self.checkequal(1, '', 'rfind', '')
+        self.checkequal(1, '', 'rfind', '', 1)
+        self.checkequal(-1, '', 'rfind', '', 2)
+        self.checkequal(-1, '', 'rfind', 'e')  # english `e`
+        # test utf-8 non-ascii slice
+        self.checkequal(6, ' ', 'rfind', '')
+        self.checkequal(6, ' ', 'rfind', '', 1)
+        self.checkequal(1, ' ', 'rfind', '', 1, 3)
+        self.checkequal(6, ' ', 'rfind', '', 2)
+        self.checkequal(-1, ' ', 'rfind', '', 6, 7)
+        self.checkequal(-1, ' ', 'rfind', '', 7)
+        self.checkequal(-1, ' ', 'rfind', 'ec')  # english `ec`
         # test mixed kinds
         self.checkequal(0, 'a' + '\u0102' * 100, 'rfind', 'a')
         self.checkequal(0, 'a' + '\U00100304' * 100, 'rfind', 'a')
@@ -441,10 +468,10 @@ def test_split(self):
     def test_rsplit(self):
         string_tests.CommonTest.test_rsplit(self)
         # test mixed kinds
-        for left, right in ('ba', '\u0101\u0100', '\U00010301\U00010300'):
+        for left, right in ('ba', '', '\u0101\u0100', '\U00010301\U00010300'):
             left *= 9
             right *= 9
-            for delim in ('c', '\u0102', '\U00010302'):
+            for delim in ('c', '', '\u0102', '\U00010302'):
                 self.checkequal([left + right],
                                 left + right, 'rsplit', delim)
                 self.checkequal([left, right],
@@ -454,6 +481,10 @@ def test_rsplit(self):
                 self.checkequal([left, right],
                                 left + delim * 2 + right, 'rsplit', delim *2)
 
+            # Check `None` as well:
+            self.checkequal([left + right],
+                             left + right, 'rsplit', None)
+
     def test_partition(self):
         string_tests.MixinStrUnicodeUserStringTest.test_partition(self)
         # test mixed kinds
@@ -2809,6 +2840,25 @@ def check_format(expected, format, *args):
         check_format('repr=abc',
                      b'repr=%V', 'abc', b'xyz')
 
+        # test %p
+        # We cannot test the exact result,
+        # because it returns a hex representation of a C pointer,
+        # which is going to be different each time. But, we can test the format.
+        p_format_regex = r'^0x[a-zA-Z0-9]{3,}$'
+        p_format1 = PyUnicode_FromFormat(b'%p', 'abc')
+        self.assertIsInstance(p_format1, str)
+        self.assertRegex(p_format1, p_format_regex)
+
+        p_format2 = PyUnicode_FromFormat(b'%p %p', '123456', b'xyz')
+        self.assertIsInstance(p_format2, str)
+        self.assertRegex(p_format2,
+                         r'0x[a-zA-Z0-9]{3,} 0x[a-zA-Z0-9]{3,}')
+
+        # Extra args are ignored:
+        p_format3 = PyUnicode_FromFormat(b'%p', '123456', None, b'xyz')
+        self.assertIsInstance(p_format3, str)
+        self.assertRegex(p_format3, p_format_regex)
+
         # Test string decode from parameter of %s using utf-8.
         # b'\xe4\xba\xba\xe6\xb0\x91' is utf-8 encoded byte sequence of
         # '\u4eba\u6c11'
diff --git a/Lib/test/test_unicode_file_functions.py b/Lib/test/test_unicode_file_functions.py
index 54916dec4e..47619c8807 100644
--- a/Lib/test/test_unicode_file_functions.py
+++ b/Lib/test/test_unicode_file_functions.py
@@ -6,6 +6,7 @@
 import warnings
 from unicodedata import normalize
 from test.support import os_helper
+from test import support
 
 
 filenames = [
@@ -123,6 +124,10 @@ def test_open(self):
     # NFKD in Python is useless, because darwin will normalize it later and so
     # open(), os.stat(), etc. don't raise any exception.
     @unittest.skipIf(sys.platform == 'darwin', 'irrelevant test on Mac OS X')
+    @unittest.skipIf(
+        support.is_emscripten or support.is_wasi,
+        "test fails on Emscripten/WASI when host platform is macOS."
+    )
     def test_normalize(self):
         files = set(self.files)
         others = set()
diff --git a/Lib/test/test_unicodedata.py b/Lib/test/test_unicodedata.py
index 3514697f54..85a3c2d6d5 100644
--- a/Lib/test/test_unicodedata.py
+++ b/Lib/test/test_unicodedata.py
@@ -95,6 +95,13 @@ def test_function_checksum(self):
         result = h.hexdigest()
         self.assertEqual(result, self.expectedchecksum)
 
+    @requires_resource('cpu')
+    def test_name_inverse_lookup(self):
+        for i in range(sys.maxunicode + 1):
+            char = chr(i)
+            if looked_name := self.db.name(char, None):
+                self.assertEqual(self.db.lookup(looked_name), char)
+
     def test_digit(self):
         self.assertEqual(self.db.digit('A', None), None)
         self.assertEqual(self.db.digit('9'), 9)
diff --git a/Lib/test/test_urlparse.py b/Lib/test/test_urlparse.py
index 2f629c72ae..4d28646d5f 100644
--- a/Lib/test/test_urlparse.py
+++ b/Lib/test/test_urlparse.py
@@ -653,13 +653,16 @@ def test_attributes_bad_port(self):
         """Check handling of invalid ports."""
         for bytes in (False, True):
             for parse in (urllib.parse.urlsplit, urllib.parse.urlparse):
-                for port in ("foo", "1.5", "-1", "0x10"):
+                for port in ("foo", "1.5", "-1", "0x10", "-0", "1_1", " 1", "1 ", ""):
                     with self.subTest(bytes=bytes, parse=parse, port=port):
                         netloc = "www.example.net:" + port
                         url = "http://" + netloc
                         if bytes:
-                            netloc = netloc.encode("ascii")
-                            url = url.encode("ascii")
+                            if netloc.isascii() and port.isascii():
+                                netloc = netloc.encode("ascii")
+                                url = url.encode("ascii")
+                            else:
+                                continue
                         p = parse(url)
                         self.assertEqual(p.netloc, netloc)
                         with self.assertRaises(ValueError):
@@ -1195,6 +1198,7 @@ def test_splitnport(self):
         self.assertEqual(splitnport('127.0.0.1', 55), ('127.0.0.1', 55))
         self.assertEqual(splitnport('parrot:cheese'), ('parrot', None))
         self.assertEqual(splitnport('parrot:cheese', 55), ('parrot', None))
+        self.assertEqual(splitnport('parrot: +1_0 '), ('parrot', None))
 
     def test_splitquery(self):
         # Normal cases are exercised by other tests; ensure that we also
diff --git a/Lib/test/test_venv.py b/Lib/test/test_venv.py
index decf021c64..c88df1795f 100644
--- a/Lib/test/test_venv.py
+++ b/Lib/test/test_venv.py
@@ -216,7 +216,7 @@ def test_upgrade_dependencies(self):
             if sys.platform == 'win32':
                 expect_exe = os.path.normcase(os.path.realpath(expect_exe))
 
-            def pip_cmd_checker(cmd):
+            def pip_cmd_checker(cmd, **kwargs):
                 cmd[0] = os.path.normcase(cmd[0])
                 self.assertEqual(
                     cmd,
@@ -232,7 +232,7 @@ def pip_cmd_checker(cmd):
                 )
 
             fake_context = builder.ensure_directories(fake_env_dir)
-            with patch('venv.subprocess.check_call', pip_cmd_checker):
+            with patch('venv.subprocess.check_output', pip_cmd_checker):
                 builder.upgrade_dependencies(fake_context)
 
     @requireVenvCreate
@@ -673,8 +673,8 @@ def nicer_error(self):
         try:
             yield
         except subprocess.CalledProcessError as exc:
-            out = exc.output.decode(errors="replace")
-            err = exc.stderr.decode(errors="replace")
+            out = (exc.output or b'').decode(errors="replace")
+            err = (exc.stderr or b'').decode(errors="replace")
             self.fail(
                 f"{exc}\n\n"
                 f"**Subprocess Output**\n{out}\n\n"
diff --git a/Lib/test/test_warnings/__init__.py b/Lib/test/test_warnings/__init__.py
index 0f960b82bf..61a644406a 100644
--- a/Lib/test/test_warnings/__init__.py
+++ b/Lib/test/test_warnings/__init__.py
@@ -489,7 +489,14 @@ def test_warn_explicit_non_ascii_filename(self):
                 module=self.module) as w:
             self.module.resetwarnings()
             self.module.filterwarnings("always", category=UserWarning)
-            for filename in ("nonascii\xe9\u20ac", "surrogate\udc80"):
+            filenames = ["nonascii\xe9\u20ac"]
+            if not support.is_emscripten:
+                # JavaScript does not like surrogates.
+                # Invalid UTF-8 leading byte 0x80 encountered when
+                # deserializing a UTF-8 string in wasm memory to a JS
+                # string!
+                filenames.append("surrogate\udc80")
+            for filename in filenames:
                 try:
                     os.fsencode(filename)
                 except UnicodeEncodeError:
diff --git a/Lib/test/typinganndata/__init__.py b/Lib/test/typinganndata/__init__.py
new file mode 100644
index 0000000000..e69de29bb2
diff --git a/Lib/test/typinganndata/ann_module9.py b/Lib/test/typinganndata/ann_module9.py
new file mode 100644
index 0000000000..952217393e
--- /dev/null
+++ b/Lib/test/typinganndata/ann_module9.py
@@ -0,0 +1,14 @@
+# Test ``inspect.formatannotation``
+# https://github.com/python/cpython/issues/96073
+
+from typing import Union, List
+
+ann = Union[List[str], int]
+
+# mock typing._type_repr behaviour
+class A: ...
+
+A.__module__ = 'testModule.typing'
+A.__qualname__ = 'A'
+
+ann1 = Union[List[A], int]
diff --git a/Lib/tkinter/__init__.py b/Lib/tkinter/__init__.py
index 296320235a..a8e7bf490a 100644
--- a/Lib/tkinter/__init__.py
+++ b/Lib/tkinter/__init__.py
@@ -2619,7 +2619,7 @@ def __init__(self, master, widgetName, cnf={}, kw={}, extra=()):
         if kw:
             cnf = _cnfmerge((cnf, kw))
         self.widgetName = widgetName
-        BaseWidget._setup(self, master, cnf)
+        self._setup(master, cnf)
         if self._tclCommands is None:
             self._tclCommands = []
         classes = [(k, v) for k, v in cnf.items() if isinstance(k, type)]
@@ -3038,6 +3038,8 @@ def type(self, tagOrId):
         return self.tk.call(self._w, 'type', tagOrId) or None
 
 
+_checkbutton_count = 0
+
 class Checkbutton(Widget):
     """Checkbutton widget which is either in on- or off-state."""
 
@@ -3053,6 +3055,14 @@ def __init__(self, master=None, cnf={}, **kw):
         underline, variable, width, wraplength."""
         Widget.__init__(self, master, 'checkbutton', cnf, kw)
 
+    def _setup(self, master, cnf):
+        if not cnf.get('name'):
+            global _checkbutton_count
+            name = self.__class__.__name__.lower()
+            _checkbutton_count += 1
+            cnf['name'] = f'!{name}{_checkbutton_count}'
+        super()._setup(master, cnf)
+
     def deselect(self):
         """Put the button in off-state."""
         self.tk.call(self._w, 'deselect')
@@ -3638,7 +3648,7 @@ def count(self, index1, index2, *args): # new in Tk 8.5
         "lines", "xpixels" and "ypixels". There is an additional possible
         option "update", which if given then all subsequent options ensure
         that any possible out of date information is recalculated."""
-        args = ['-%s' % arg for arg in args if not arg.startswith('-')]
+        args = ['-%s' % arg for arg in args]
         args += [index1, index2]
         res = self.tk.call(self._w, 'count', *args) or None
         if res is not None and len(args) <= 3:
diff --git a/Lib/tkinter/dialog.py b/Lib/tkinter/dialog.py
index 8ae2140117..36ae6c277c 100644
--- a/Lib/tkinter/dialog.py
+++ b/Lib/tkinter/dialog.py
@@ -11,7 +11,7 @@ class Dialog(Widget):
     def __init__(self, master=None, cnf={}, **kw):
         cnf = _cnfmerge((cnf, kw))
         self.widgetName = '__dialog__'
-        Widget._setup(self, master, cnf)
+        self._setup(master, cnf)
         self.num = self.tk.getint(
                 self.tk.call(
                       'tk_dialog', self._w,
diff --git a/Lib/tkinter/test/test_tkinter/test_text.py b/Lib/tkinter/test/test_tkinter/test_text.py
index 482f150df5..ea557586c7 100644
--- a/Lib/tkinter/test/test_tkinter/test_text.py
+++ b/Lib/tkinter/test/test_tkinter/test_text.py
@@ -40,6 +40,58 @@ def test_search(self):
         self.assertEqual(text.search('-test', '1.0', 'end'), '1.2')
         self.assertEqual(text.search('test', '1.0', 'end'), '1.3')
 
+    def test_count(self):
+        # XXX Some assertions do not check against the intended result,
+        # but instead check the current result to prevent regression.
+        text = self.text
+        text.insert('1.0',
+            'Lorem ipsum dolor sit amet,\n'
+            'consectetur adipiscing elit,\n'
+            'sed do eiusmod tempor incididunt\n'
+            'ut labore et dolore magna aliqua.')
+
+        options = ('chars', 'indices', 'lines',
+                   'displaychars', 'displayindices', 'displaylines',
+                   'xpixels', 'ypixels')
+        if self.wantobjects:
+            self.assertEqual(len(text.count('1.0', 'end', *options)), 8)
+        else:
+            text.count('1.0', 'end', *options)
+        self.assertEqual(text.count('1.0', 'end', 'chars', 'lines'), (124, 4)
+                         if self.wantobjects else '124 4')
+        self.assertEqual(text.count('1.3', '4.5', 'chars', 'lines'), (92, 3)
+                         if self.wantobjects else '92 3')
+        self.assertEqual(text.count('4.5', '1.3', 'chars', 'lines'), (-92, -3)
+                         if self.wantobjects else '-92 -3')
+        self.assertEqual(text.count('1.3', '1.3', 'chars', 'lines'), (0, 0)
+                         if self.wantobjects else '0 0')
+        self.assertEqual(text.count('1.0', 'end', 'lines'), (4,)
+                         if self.wantobjects else ('4',))
+        self.assertEqual(text.count('end', '1.0', 'lines'), (-4,)
+                         if self.wantobjects else ('-4',))
+        self.assertEqual(text.count('1.3', '1.5', 'lines'), None
+                         if self.wantobjects else ('0',))
+        self.assertEqual(text.count('1.3', '1.3', 'lines'), None
+                         if self.wantobjects else ('0',))
+        self.assertEqual(text.count('1.0', 'end'), (124,)  # 'indices' by default
+                         if self.wantobjects else ('124',))
+        self.assertRaises(tkinter.TclError, text.count, '1.0', 'end', 'spam')
+        self.assertRaises(tkinter.TclError, text.count, '1.0', 'end', '-lines')
+
+        self.assertIsInstance(text.count('1.3', '1.5', 'ypixels'), tuple)
+        self.assertIsInstance(text.count('1.3', '1.5', 'update', 'ypixels'), int
+                              if self.wantobjects else str)
+        self.assertEqual(text.count('1.3', '1.3', 'update', 'ypixels'), None
+                         if self.wantobjects else '0')
+        self.assertEqual(text.count('1.3', '1.5', 'update', 'indices'), 2
+                         if self.wantobjects else '2')
+        self.assertEqual(text.count('1.3', '1.3', 'update', 'indices'), None
+                         if self.wantobjects else '0')
+        self.assertEqual(text.count('1.3', '1.5', 'update'), (2,)
+                         if self.wantobjects else ('2',))
+        self.assertEqual(text.count('1.3', '1.3', 'update'), None
+                         if self.wantobjects else ('0',))
+
 
 if __name__ == "__main__":
     unittest.main()
diff --git a/Lib/tkinter/test/test_tkinter/test_widgets.py b/Lib/tkinter/test/test_tkinter/test_widgets.py
index fe8ecfeb32..da321a1dae 100644
--- a/Lib/tkinter/test/test_tkinter/test_widgets.py
+++ b/Lib/tkinter/test/test_tkinter/test_widgets.py
@@ -212,6 +212,32 @@ def test_configure_onvalue(self):
         widget = self.create()
         self.checkParams(widget, 'onvalue', 1, 2.3, '', 'any string')
 
+    def test_unique_variables(self):
+        frames = []
+        buttons = []
+        for i in range(2):
+            f = tkinter.Frame(self.root)
+            f.pack()
+            frames.append(f)
+            for j in 'AB':
+                b = tkinter.Checkbutton(f, text=j)
+                b.pack()
+                buttons.append(b)
+        variables = [str(b['variable']) for b in buttons]
+        self.assertEqual(len(set(variables)), 4, variables)
+
+    def test_same_name(self):
+        f1 = tkinter.Frame(self.root)
+        f2 = tkinter.Frame(self.root)
+        b1 = tkinter.Checkbutton(f1, name='test', text='Test1')
+        b2 = tkinter.Checkbutton(f2, name='test', text='Test2')
+
+        v = tkinter.IntVar(self.root, name='test')
+        b1.select()
+        self.assertEqual(v.get(), 1)
+        b2.deselect()
+        self.assertEqual(v.get(), 0)
+
 
 @add_standard_options(StandardOptionsTests)
 class RadiobuttonTest(AbstractLabelTest, unittest.TestCase):
@@ -733,6 +759,164 @@ def test_configure_yscrollincrement(self):
         self.checkPixelsParam(widget, 'yscrollincrement',
                               10, 0, 11.2, 13.6, -10, '0.1i')
 
+    def _test_option_joinstyle(self, c, factory):
+        for joinstyle in 'bevel', 'miter', 'round':
+            i = factory(joinstyle=joinstyle)
+            self.assertEqual(c.itemcget(i, 'joinstyle'), joinstyle)
+        self.assertRaises(TclError, factory, joinstyle='spam')
+
+    def _test_option_smooth(self, c, factory):
+        for smooth in 1, True, '1', 'true', 'yes', 'on':
+            i = factory(smooth=smooth)
+            self.assertEqual(c.itemcget(i, 'smooth'), 'true')
+        for smooth in 0, False, '0', 'false', 'no', 'off':
+            i = factory(smooth=smooth)
+            self.assertEqual(c.itemcget(i, 'smooth'), '0')
+        i = factory(smooth=True, splinestep=30)
+        self.assertEqual(c.itemcget(i, 'smooth'), 'true')
+        self.assertEqual(c.itemcget(i, 'splinestep'), '30')
+        i = factory(smooth='raw', splinestep=30)
+        self.assertEqual(c.itemcget(i, 'smooth'), 'raw')
+        self.assertEqual(c.itemcget(i, 'splinestep'), '30')
+        self.assertRaises(TclError, factory, smooth='spam')
+
+    def test_create_rectangle(self):
+        c = self.create()
+        i1 = c.create_rectangle(20, 30, 60, 10)
+        self.assertEqual(c.coords(i1), [20.0, 10.0, 60.0, 30.0])
+        self.assertEqual(c.bbox(i1), (19, 9, 61, 31))
+
+        i2 = c.create_rectangle([21, 31, 61, 11])
+        self.assertEqual(c.coords(i2), [21.0, 11.0, 61.0, 31.0])
+        self.assertEqual(c.bbox(i2), (20, 10, 62, 32))
+
+        i3 = c.create_rectangle((22, 32), (62, 12))
+        self.assertEqual(c.coords(i3), [22.0, 12.0, 62.0, 32.0])
+        self.assertEqual(c.bbox(i3), (21, 11, 63, 33))
+
+        i4 = c.create_rectangle([(23, 33), (63, 13)])
+        self.assertEqual(c.coords(i4), [23.0, 13.0, 63.0, 33.0])
+        self.assertEqual(c.bbox(i4), (22, 12, 64, 34))
+
+        self.assertRaises(TclError, c.create_rectangle, 20, 30, 60)
+        self.assertRaises(TclError, c.create_rectangle, [20, 30, 60])
+        self.assertRaises(TclError, c.create_rectangle, 20, 30, 40, 50, 60, 10)
+        self.assertRaises(TclError, c.create_rectangle, [20, 30, 40, 50, 60, 10])
+        self.assertRaises(TclError, c.create_rectangle, 20, 30)
+        self.assertRaises(TclError, c.create_rectangle, [20, 30])
+        self.assertRaises(IndexError, c.create_rectangle)
+        self.assertRaises(IndexError, c.create_rectangle, [])
+
+    def test_create_line(self):
+        c = self.create()
+        i1 = c.create_line(20, 30, 40, 50, 60, 10)
+        self.assertEqual(c.coords(i1), [20.0, 30.0, 40.0, 50.0, 60.0, 10.0])
+        self.assertEqual(c.bbox(i1), (18, 8, 62, 52))
+        self.assertEqual(c.itemcget(i1, 'arrow'), 'none')
+        self.assertEqual(c.itemcget(i1, 'arrowshape'), '8 10 3')
+        self.assertEqual(c.itemcget(i1, 'capstyle'), 'butt')
+        self.assertEqual(c.itemcget(i1, 'joinstyle'), 'round')
+        self.assertEqual(c.itemcget(i1, 'smooth'), '0')
+        self.assertEqual(c.itemcget(i1, 'splinestep'), '12')
+
+        i2 = c.create_line([21, 31, 41, 51, 61, 11])
+        self.assertEqual(c.coords(i2), [21.0, 31.0, 41.0, 51.0, 61.0, 11.0])
+        self.assertEqual(c.bbox(i2), (19, 9, 63, 53))
+
+        i3 = c.create_line((22, 32), (42, 52), (62, 12))
+        self.assertEqual(c.coords(i3), [22.0, 32.0, 42.0, 52.0, 62.0, 12.0])
+        self.assertEqual(c.bbox(i3), (20, 10, 64, 54))
+
+        i4 = c.create_line([(23, 33), (43, 53), (63, 13)])
+        self.assertEqual(c.coords(i4), [23.0, 33.0, 43.0, 53.0, 63.0, 13.0])
+        self.assertEqual(c.bbox(i4), (21, 11, 65, 55))
+
+        self.assertRaises(TclError, c.create_line, 20, 30, 60)
+        self.assertRaises(TclError, c.create_line, [20, 30, 60])
+        self.assertRaises(TclError, c.create_line, 20, 30)
+        self.assertRaises(TclError, c.create_line, [20, 30])
+        self.assertRaises(IndexError, c.create_line)
+        self.assertRaises(IndexError, c.create_line, [])
+
+        for arrow in 'none', 'first', 'last', 'both':
+            i = c.create_line(20, 30, 60, 10, arrow=arrow)
+            self.assertEqual(c.itemcget(i, 'arrow'), arrow)
+        i = c.create_line(20, 30, 60, 10, arrow='first', arrowshape=[10, 15, 5])
+        self.assertEqual(c.itemcget(i, 'arrowshape'), '10 15 5')
+        self.assertRaises(TclError, c.create_line, 20, 30, 60, 10, arrow='spam')
+
+        for capstyle in 'butt', 'projecting', 'round':
+            i = c.create_line(20, 30, 60, 10, capstyle=capstyle)
+            self.assertEqual(c.itemcget(i, 'capstyle'), capstyle)
+        self.assertRaises(TclError, c.create_line, 20, 30, 60, 10, capstyle='spam')
+
+        self._test_option_joinstyle(c,
+                lambda **kwargs: c.create_line(20, 30, 40, 50, 60, 10, **kwargs))
+        self._test_option_smooth(c,
+                lambda **kwargs: c.create_line(20, 30, 60, 10, **kwargs))
+
+    def test_create_polygon(self):
+        c = self.create()
+        i1 = c.create_polygon(20, 30, 40, 50, 60, 10)
+        self.assertEqual(c.coords(i1), [20.0, 30.0, 40.0, 50.0, 60.0, 10.0])
+        self.assertEqual(c.bbox(i1), (19, 9, 61, 51))
+        self.assertEqual(c.itemcget(i1, 'joinstyle'), 'round')
+        self.assertEqual(c.itemcget(i1, 'smooth'), '0')
+        self.assertEqual(c.itemcget(i1, 'splinestep'), '12')
+
+        i2 = c.create_polygon([21, 31, 41, 51, 61, 11])
+        self.assertEqual(c.coords(i2), [21.0, 31.0, 41.0, 51.0, 61.0, 11.0])
+        self.assertEqual(c.bbox(i2), (20, 10, 62, 52))
+
+        i3 = c.create_polygon((22, 32), (42, 52), (62, 12))
+        self.assertEqual(c.coords(i3), [22.0, 32.0, 42.0, 52.0, 62.0, 12.0])
+        self.assertEqual(c.bbox(i3), (21, 11, 63, 53))
+
+        i4 = c.create_polygon([(23, 33), (43, 53), (63, 13)])
+        self.assertEqual(c.coords(i4), [23.0, 33.0, 43.0, 53.0, 63.0, 13.0])
+        self.assertEqual(c.bbox(i4), (22, 12, 64, 54))
+
+        self.assertRaises(TclError, c.create_polygon, 20, 30, 60)
+        self.assertRaises(TclError, c.create_polygon, [20, 30, 60])
+        self.assertRaises(IndexError, c.create_polygon)
+        self.assertRaises(IndexError, c.create_polygon, [])
+
+        self._test_option_joinstyle(c,
+                lambda **kwargs: c.create_polygon(20, 30, 40, 50, 60, 10, **kwargs))
+        self._test_option_smooth(c,
+                lambda **kwargs: c.create_polygon(20, 30, 40, 50, 60, 10, **kwargs))
+
+    def test_coords(self):
+        c = self.create()
+        i = c.create_line(20, 30, 40, 50, 60, 10, tags='x')
+        self.assertEqual(c.coords(i), [20.0, 30.0, 40.0, 50.0, 60.0, 10.0])
+        self.assertEqual(c.coords('x'), [20.0, 30.0, 40.0, 50.0, 60.0, 10.0])
+        self.assertEqual(c.bbox(i), (18, 8, 62, 52))
+
+        c.coords(i, 50, 60, 70, 80, 90, 40)
+        self.assertEqual(c.coords(i), [50.0, 60.0, 70.0, 80.0, 90.0, 40.0])
+        self.assertEqual(c.bbox(i), (48, 38, 92, 82))
+
+        c.coords(i, [21, 31, 41, 51, 61, 11])
+        self.assertEqual(c.coords(i), [21.0, 31.0, 41.0, 51.0, 61.0, 11.0])
+
+        c.coords(i, 20, 30, 60, 10)
+        self.assertEqual(c.coords(i), [20.0, 30.0, 60.0, 10.0])
+        self.assertEqual(c.bbox(i), (18, 8, 62, 32))
+
+        self.assertRaises(TclError, c.coords, i, 20, 30, 60)
+        self.assertRaises(TclError, c.coords, i, [20, 30, 60])
+        self.assertRaises(TclError, c.coords, i, 20, 30)
+        self.assertRaises(TclError, c.coords, i, [20, 30])
+
+        c.coords(i, '20', '30c', '60i', '10p')
+        coords = c.coords(i)
+        self.assertIsInstance(coords, list)
+        self.assertEqual(len(coords), 4)
+        self.assertEqual(coords[0], 20)
+        for i in range(4):
+            self.assertIsInstance(coords[i], float)
+
     @requires_tcl(8, 6)
     def test_moveto(self):
         widget = self.create()
diff --git a/Lib/tkinter/test/test_ttk/test_widgets.py b/Lib/tkinter/test/test_ttk/test_widgets.py
index c14c321ca2..96d2afcf90 100644
--- a/Lib/tkinter/test/test_ttk/test_widgets.py
+++ b/Lib/tkinter/test/test_ttk/test_widgets.py
@@ -275,6 +275,21 @@ def cb_test():
         self.assertEqual(cbtn['offvalue'],
             cbtn.tk.globalgetvar(cbtn['variable']))
 
+    def test_unique_variables(self):
+        frames = []
+        buttons = []
+        for i in range(2):
+            f = ttk.Frame(self.root)
+            f.pack()
+            frames.append(f)
+            for j in 'AB':
+                b = ttk.Checkbutton(f, text=j)
+                b.pack()
+                buttons.append(b)
+        variables = [str(b['variable']) for b in buttons]
+        print(variables)
+        self.assertEqual(len(set(variables)), 4, variables)
+
 
 @add_standard_options(IntegerSizeTests, StandardTtkOptionsTests)
 class EntryTest(AbstractWidgetTest, unittest.TestCase):
diff --git a/Lib/tkinter/tix.py b/Lib/tkinter/tix.py
index 44ecae1a32..ce218265d4 100644
--- a/Lib/tkinter/tix.py
+++ b/Lib/tkinter/tix.py
@@ -310,7 +310,7 @@ def __init__ (self, master=None, widgetName=None,
                 del cnf[k]
 
         self.widgetName = widgetName
-        Widget._setup(self, master, cnf)
+        self._setup(master, cnf)
 
         # If widgetName is None, this is a dummy creation call where the
         # corresponding Tk widget has already been created by Tix
diff --git a/Lib/traceback.py b/Lib/traceback.py
index 55f8080044..fa2cc341af 100644
--- a/Lib/traceback.py
+++ b/Lib/traceback.py
@@ -475,32 +475,32 @@ def format_frame_summary(self, frame_summary):
                 frame_summary.colno is not None
                 and frame_summary.end_colno is not None
             ):
-                colno = _byte_offset_to_character_offset(
-                    frame_summary._original_line, frame_summary.colno)
-                end_colno = _byte_offset_to_character_offset(
-                    frame_summary._original_line, frame_summary.end_colno)
+                start_offset = _byte_offset_to_character_offset(
+                    frame_summary._original_line, frame_summary.colno) + 1
+                end_offset = _byte_offset_to_character_offset(
+                    frame_summary._original_line, frame_summary.end_colno) + 1
 
                 anchors = None
                 if frame_summary.lineno == frame_summary.end_lineno:
                     with suppress(Exception):
                         anchors = _extract_caret_anchors_from_line_segment(
-                            frame_summary._original_line[colno - 1:end_colno - 1]
+                            frame_summary._original_line[start_offset - 1:end_offset - 1]
                         )
                 else:
-                    end_colno = stripped_characters + len(stripped_line)
+                    end_offset = stripped_characters + len(stripped_line)
 
                 # show indicators if primary char doesn't span the frame line
-                if end_colno - colno < len(stripped_line) or (
+                if end_offset - start_offset < len(stripped_line) or (
                         anchors and anchors.right_start_offset - anchors.left_end_offset > 0):
                     row.append('    ')
-                    row.append(' ' * (colno - stripped_characters))
+                    row.append(' ' * (start_offset - stripped_characters))
 
                     if anchors:
                         row.append(anchors.primary_char * (anchors.left_end_offset))
                         row.append(anchors.secondary_char * (anchors.right_start_offset - anchors.left_end_offset))
-                        row.append(anchors.primary_char * (end_colno - colno - anchors.right_start_offset))
+                        row.append(anchors.primary_char * (end_offset - start_offset - anchors.right_start_offset))
                     else:
-                        row.append('^' * (end_colno - colno))
+                        row.append('^' * (end_offset - start_offset))
 
                     row.append('\n')
 
@@ -560,10 +560,7 @@ def format(self):
 
 def _byte_offset_to_character_offset(str, offset):
     as_utf8 = str.encode('utf-8')
-    if offset > len(as_utf8):
-        offset = len(as_utf8)
-
-    return len(as_utf8[:offset + 1].decode("utf-8"))
+    return len(as_utf8[:offset].decode("utf-8", errors="replace"))
 
 
 _Anchors = collections.namedtuple(
diff --git a/Lib/turtle.py b/Lib/turtle.py
index a8876e76bc..6abf9f7f65 100644
--- a/Lib/turtle.py
+++ b/Lib/turtle.py
@@ -596,7 +596,6 @@ def _write(self, pos, txt, align, font, pencolor):
         item = self.cv.create_text(x-1, -y, text = txt, anchor = anchor[align],
                                         fill = pencolor, font = font)
         x0, y0, x1, y1 = self.cv.bbox(item)
-        self.cv.update()
         return item, x1-1
 
 ##    def _dot(self, pos, size, color):
@@ -3419,6 +3418,7 @@ def _write(self, txt, align, font):
         """
         item, end = self.screen._write(self._position, txt, align, font,
                                                           self._pencolor)
+        self._update()
         self.items.append(item)
         if self.undobuffer:
             self.undobuffer.push(("wri", item))
diff --git a/Lib/turtledemo/clock.py b/Lib/turtledemo/clock.py
index 62c8851606..9f8585bd11 100755
--- a/Lib/turtledemo/clock.py
+++ b/Lib/turtledemo/clock.py
@@ -109,7 +109,6 @@ def tick():
         writer.write(datum(t),
                      align="center", font=("Courier", 14, "bold"))
         writer.forward(85)
-        tracer(True)
         second_hand.setheading(6*sekunde)  # or here
         minute_hand.setheading(6*minute)
         hour_hand.setheading(30*stunde)
diff --git a/Lib/typing.py b/Lib/typing.py
index 354976caaa..9c4d653372 100644
--- a/Lib/typing.py
+++ b/Lib/typing.py
@@ -493,7 +493,9 @@ def __instancecheck__(self, obj):
         return super().__instancecheck__(obj)
 
     def __repr__(self):
-        return "typing.Any"
+        if self is Any:
+            return "typing.Any"
+        return super().__repr__()  # respect to subclasses
 
 
 class Any(metaclass=_AnyMeta):
@@ -1423,6 +1425,10 @@ def _determine_new_args(self, args):
         new_args = []
         for old_arg in self.__args__:
 
+            if isinstance(old_arg, type):
+                new_args.append(old_arg)
+                continue
+
             substfunc = getattr(old_arg, '__typing_subst__', None)
             if substfunc:
                 new_arg = substfunc(new_arg_by_param[old_arg])
diff --git a/Lib/unittest/async_case.py b/Lib/unittest/async_case.py
index 3457e92e5d..bd2a471156 100644
--- a/Lib/unittest/async_case.py
+++ b/Lib/unittest/async_case.py
@@ -88,7 +88,7 @@ def _callSetUp(self):
 
     def _callTestMethod(self, method):
         if self._callMaybeAsync(method) is not None:
-            warnings.warn(f'It is deprecated to return a value!=None from a '
+            warnings.warn(f'It is deprecated to return a value that is not None from a '
                           f'test case ({method})', DeprecationWarning, stacklevel=4)
 
     def _callTearDown(self):
diff --git a/Lib/unittest/case.py b/Lib/unittest/case.py
index ffc8f19ddd..8633f38376 100644
--- a/Lib/unittest/case.py
+++ b/Lib/unittest/case.py
@@ -577,7 +577,7 @@ def _callSetUp(self):
 
     def _callTestMethod(self, method):
         if method() is not None:
-            warnings.warn(f'It is deprecated to return a value!=None from a '
+            warnings.warn(f'It is deprecated to return a value that is not None from a '
                           f'test case ({method})', DeprecationWarning, stacklevel=3)
 
     def _callTearDown(self):
diff --git a/Lib/unittest/mock.py b/Lib/unittest/mock.py
index cd46fea516..b8f4e57f0b 100644
--- a/Lib/unittest/mock.py
+++ b/Lib/unittest/mock.py
@@ -35,6 +35,7 @@
 from types import CodeType, ModuleType, MethodType
 from unittest.util import safe_repr
 from functools import wraps, partial
+from threading import RLock
 
 
 class InvalidSpecError(Exception):
@@ -402,6 +403,14 @@ def __init__(self, /, *args, **kwargs):
 class NonCallableMock(Base):
     """A non-callable version of `Mock`"""
 
+    # Store a mutex as a class attribute in order to protect concurrent access
+    # to mock attributes. Using a class attribute allows all NonCallableMock
+    # instances to share the mutex for simplicity.
+    #
+    # See https://github.com/python/cpython/issues/98624 for why this is
+    # necessary.
+    _lock = RLock()
+
     def __new__(cls, /, *args, **kw):
         # every instance has its own class
         # so we can create magic methods on the
@@ -644,35 +653,36 @@ def __getattr__(self, name):
                     f"{name!r} is not a valid assertion. Use a spec "
                     f"for the mock if {name!r} is meant to be an attribute.")
 
-        result = self._mock_children.get(name)
-        if result is _deleted:
-            raise AttributeError(name)
-        elif result is None:
-            wraps = None
-            if self._mock_wraps is not None:
-                # XXXX should we get the attribute without triggering code
-                # execution?
-                wraps = getattr(self._mock_wraps, name)
-
-            result = self._get_child_mock(
-                parent=self, name=name, wraps=wraps, _new_name=name,
-                _new_parent=self
-            )
-            self._mock_children[name]  = result
-
-        elif isinstance(result, _SpecState):
-            try:
-                result = create_autospec(
-                    result.spec, result.spec_set, result.instance,
-                    result.parent, result.name
+        with NonCallableMock._lock:
+            result = self._mock_children.get(name)
+            if result is _deleted:
+                raise AttributeError(name)
+            elif result is None:
+                wraps = None
+                if self._mock_wraps is not None:
+                    # XXXX should we get the attribute without triggering code
+                    # execution?
+                    wraps = getattr(self._mock_wraps, name)
+
+                result = self._get_child_mock(
+                    parent=self, name=name, wraps=wraps, _new_name=name,
+                    _new_parent=self
                 )
-            except InvalidSpecError:
-                target_name = self.__dict__['_mock_name'] or self
-                raise InvalidSpecError(
-                    f'Cannot autospec attr {name!r} from target '
-                    f'{target_name!r} as it has already been mocked out. '
-                    f'[target={self!r}, attr={result.spec!r}]')
-            self._mock_children[name]  = result
+                self._mock_children[name]  = result
+
+            elif isinstance(result, _SpecState):
+                try:
+                    result = create_autospec(
+                        result.spec, result.spec_set, result.instance,
+                        result.parent, result.name
+                    )
+                except InvalidSpecError:
+                    target_name = self.__dict__['_mock_name'] or self
+                    raise InvalidSpecError(
+                        f'Cannot autospec attr {name!r} from target '
+                        f'{target_name!r} as it has already been mocked out. '
+                        f'[target={self!r}, attr={result.spec!r}]')
+                self._mock_children[name]  = result
 
         return result
 
diff --git a/Lib/unittest/test/test_async_case.py b/Lib/unittest/test/test_async_case.py
index d7d4dc9131..fab8270ea3 100644
--- a/Lib/unittest/test/test_async_case.py
+++ b/Lib/unittest/test/test_async_case.py
@@ -277,25 +277,36 @@ async def on_cleanup2(self):
         self.assertEqual(events, ['asyncSetUp', 'test', 'asyncTearDown', 'cleanup2', 'cleanup1'])
 
     def test_deprecation_of_return_val_from_test(self):
-        # Issue 41322 - deprecate return of value!=None from a test
+        # Issue 41322 - deprecate return of value that is not None from a test
+        class Nothing:
+            def __eq__(self, o):
+                return o is None
         class Test(unittest.IsolatedAsyncioTestCase):
             async def test1(self):
                 return 1
             async def test2(self):
                 yield 1
+            async def test3(self):
+                return Nothing()
 
         with self.assertWarns(DeprecationWarning) as w:
             Test('test1').run()
-        self.assertIn('It is deprecated to return a value!=None', str(w.warning))
+        self.assertIn('It is deprecated to return a value that is not None', str(w.warning))
         self.assertIn('test1', str(w.warning))
         self.assertEqual(w.filename, __file__)
 
         with self.assertWarns(DeprecationWarning) as w:
             Test('test2').run()
-        self.assertIn('It is deprecated to return a value!=None', str(w.warning))
+        self.assertIn('It is deprecated to return a value that is not None', str(w.warning))
         self.assertIn('test2', str(w.warning))
         self.assertEqual(w.filename, __file__)
 
+        with self.assertWarns(DeprecationWarning) as w:
+            Test('test3').run()
+        self.assertIn('It is deprecated to return a value that is not None', str(w.warning))
+        self.assertIn('test3', str(w.warning))
+        self.assertEqual(w.filename, __file__)
+
     def test_cleanups_interleave_order(self):
         events = []
 
diff --git a/Lib/unittest/test/test_case.py b/Lib/unittest/test/test_case.py
index 374a255255..78303b359f 100644
--- a/Lib/unittest/test/test_case.py
+++ b/Lib/unittest/test/test_case.py
@@ -307,25 +307,36 @@ def test(self):
         Foo('test').run()
 
     def test_deprecation_of_return_val_from_test(self):
-        # Issue 41322 - deprecate return of value!=None from a test
+        # Issue 41322 - deprecate return of value that is not None from a test
+        class Nothing:
+            def __eq__(self, o):
+                return o is None
         class Foo(unittest.TestCase):
             def test1(self):
                 return 1
             def test2(self):
                 yield 1
+            def test3(self):
+                return Nothing()
 
         with self.assertWarns(DeprecationWarning) as w:
             Foo('test1').run()
-        self.assertIn('It is deprecated to return a value!=None', str(w.warning))
+        self.assertIn('It is deprecated to return a value that is not None', str(w.warning))
         self.assertIn('test1', str(w.warning))
         self.assertEqual(w.filename, __file__)
 
         with self.assertWarns(DeprecationWarning) as w:
             Foo('test2').run()
-        self.assertIn('It is deprecated to return a value!=None', str(w.warning))
+        self.assertIn('It is deprecated to return a value that is not None', str(w.warning))
         self.assertIn('test2', str(w.warning))
         self.assertEqual(w.filename, __file__)
 
+        with self.assertWarns(DeprecationWarning) as w:
+            Foo('test3').run()
+        self.assertIn('It is deprecated to return a value that is not None', str(w.warning))
+        self.assertIn('test3', str(w.warning))
+        self.assertEqual(w.filename, __file__)
+
     def _check_call_order__subtests(self, result, events, expected_events):
         class Foo(Test.LoggingTestCase):
             def test(self):
diff --git a/Lib/urllib/parse.py b/Lib/urllib/parse.py
index d70a6943f0..12fe0112e4 100644
--- a/Lib/urllib/parse.py
+++ b/Lib/urllib/parse.py
@@ -167,12 +167,11 @@ def hostname(self):
     def port(self):
         port = self._hostinfo[1]
         if port is not None:
-            try:
-                port = int(port, 10)
-            except ValueError:
-                message = f'Port could not be cast to integer value as {port!r}'
-                raise ValueError(message) from None
-            if not ( 0 <= port <= 65535):
+            if port.isdigit() and port.isascii():
+                port = int(port)
+            else:
+                raise ValueError(f"Port could not be cast to integer value as {port!r}")
+            if not (0 <= port <= 65535):
                 raise ValueError("Port out of range 0-65535")
         return port
 
@@ -1125,15 +1124,15 @@ def splitnport(host, defport=-1):
 def _splitnport(host, defport=-1):
     """Split host and port, returning numeric port.
     Return given default port if no ':' found; defaults to -1.
-    Return numerical port if a valid number are found after ':'.
+    Return numerical port if a valid number is found after ':'.
     Return None if ':' but not a valid number."""
     host, delim, port = host.rpartition(':')
     if not delim:
         host = port
     elif port:
-        try:
+        if port.isdigit() and port.isascii():
             nport = int(port)
-        except ValueError:
+        else:
             nport = None
         return host, nport
     return host, defport
diff --git a/Lib/urllib/request.py b/Lib/urllib/request.py
index 6d580a434a..73ad0127ec 100644
--- a/Lib/urllib/request.py
+++ b/Lib/urllib/request.py
@@ -1579,7 +1579,7 @@ def ftp_open(self, req):
             headers = email.message_from_string(headers)
             return addinfourl(fp, headers, req.full_url)
         except ftplib.all_errors as exp:
-            raise URLError(f'ftp error: {exp}') from exp
+            raise URLError(exp) from exp
 
     def connect_ftp(self, user, passwd, host, port, dirs, timeout):
         return ftpwrapper(user, passwd, host, port, dirs, timeout,
diff --git a/Lib/uuid.py b/Lib/uuid.py
index 8fe2479f3f..e863b63187 100644
--- a/Lib/uuid.py
+++ b/Lib/uuid.py
@@ -371,7 +371,12 @@ def _get_command_stdout(command, *args):
         # for are actually localized, but in theory some system could do so.)
         env = dict(os.environ)
         env['LC_ALL'] = 'C'
-        proc = subprocess.Popen((executable,) + args,
+        # Empty strings will be quoted by popen so we should just ommit it
+        if args != ('',):
+            command = (executable, *args)
+        else:
+            command = (executable,)
+        proc = subprocess.Popen(command,
                                 stdout=subprocess.PIPE,
                                 stderr=subprocess.DEVNULL,
                                 env=env)
@@ -511,7 +516,7 @@ def _ifconfig_getnode():
         mac = _find_mac_near_keyword('ifconfig', args, keywords, lambda i: i+1)
         if mac:
             return mac
-        return None
+    return None
 
 def _ip_getnode():
     """Get the hardware address on Unix by running ip."""
diff --git a/Lib/venv/__init__.py b/Lib/venv/__init__.py
index 6032f3648e..6bce308108 100644
--- a/Lib/venv/__init__.py
+++ b/Lib/venv/__init__.py
@@ -128,6 +128,11 @@ def create_if_needed(d):
         context.prompt = '(%s) ' % prompt
         create_if_needed(env_dir)
         executable = sys._base_executable
+        if not executable:  # see gh-96861
+            raise ValueError('Unable to determine path to the running '
+                             'Python interpreter. Provide an explicit path or '
+                             'check that your PATH environment variable is '
+                             'correctly set.')
         dirname, exename = os.path.split(os.path.abspath(executable))
         context.executable = executable
         context.python_dir = dirname
@@ -254,7 +259,7 @@ def symlink_or_copy(self, src, dst, relative_symlinks_ok=False):
                                  basename + ext)
             # Builds or venv's from builds need to remap source file
             # locations, as we do not put them into Lib/venv/scripts
-            if sysconfig.is_python_build(True) or not os.path.isfile(srcfn):
+            if sysconfig.is_python_build() or not os.path.isfile(srcfn):
                 if basename.endswith('_d'):
                     ext = '_d' + ext
                     basename = basename[:-2]
@@ -305,7 +310,7 @@ def setup_python(self, context):
                     f for f in os.listdir(dirname) if
                     os.path.normcase(os.path.splitext(f)[1]) in ('.exe', '.dll')
                 ]
-                if sysconfig.is_python_build(True):
+                if sysconfig.is_python_build():
                     suffixes = [
                         f for f in suffixes if
                         os.path.normcase(f).startswith(('python', 'vcruntime'))
@@ -320,7 +325,7 @@ def setup_python(self, context):
                 if os.path.lexists(src):
                     copier(src, os.path.join(binpath, suffix))
 
-            if sysconfig.is_python_build(True):
+            if sysconfig.is_python_build():
                 # copy init.tcl
                 for root, dirs, files in os.walk(context.python_dir):
                     if 'init.tcl' in files:
@@ -333,14 +338,25 @@ def setup_python(self, context):
                         shutil.copyfile(src, dst)
                         break
 
+    def _call_new_python(self, context, *py_args, **kwargs):
+        """Executes the newly created Python using safe-ish options"""
+        # gh-98251: We do not want to just use '-I' because that masks
+        # legitimate user preferences (such as not writing bytecode). All we
+        # really need is to ensure that the path variables do not overrule
+        # normal venv handling.
+        args = [context.env_exec_cmd, *py_args]
+        kwargs['env'] = env = os.environ.copy()
+        env['VIRTUAL_ENV'] = context.env_dir
+        env.pop('PYTHONHOME', None)
+        env.pop('PYTHONPATH', None)
+        kwargs['cwd'] = context.env_dir
+        kwargs['executable'] = context.env_exec_cmd
+        subprocess.check_output(args, **kwargs)
+
     def _setup_pip(self, context):
         """Installs or upgrades pip in a virtual environment"""
-        # We run ensurepip in isolated mode to avoid side effects from
-        # environment vars, the current directory and anything else
-        # intended for the global Python environment
-        cmd = [context.env_exec_cmd, '-Im', 'ensurepip', '--upgrade',
-                                                         '--default-pip']
-        subprocess.check_output(cmd, stderr=subprocess.STDOUT)
+        self._call_new_python(context, '-m', 'ensurepip', '--upgrade',
+                              '--default-pip', stderr=subprocess.STDOUT)
 
     def setup_scripts(self, context):
         """
@@ -439,9 +455,8 @@ def upgrade_dependencies(self, context):
         logger.debug(
             f'Upgrading {CORE_VENV_DEPS} packages in {context.bin_path}'
         )
-        cmd = [context.env_exec_cmd, '-m', 'pip', 'install', '--upgrade']
-        cmd.extend(CORE_VENV_DEPS)
-        subprocess.check_call(cmd)
+        self._call_new_python(context, '-m', 'pip', 'install', '--upgrade',
+                              *CORE_VENV_DEPS)
 
 
 def create(env_dir, system_site_packages=False, clear=False,
diff --git a/Lib/venv/scripts/posix/activate.fish b/Lib/venv/scripts/posix/activate.fish
index e40a1d7148..9aa4446005 100644
--- a/Lib/venv/scripts/posix/activate.fish
+++ b/Lib/venv/scripts/posix/activate.fish
@@ -13,10 +13,13 @@ function deactivate  -d "Exit virtual environment and return to normal shell env
     end
 
     if test -n "$_OLD_FISH_PROMPT_OVERRIDE"
-        functions -e fish_prompt
         set -e _OLD_FISH_PROMPT_OVERRIDE
-        functions -c _old_fish_prompt fish_prompt
-        functions -e _old_fish_prompt
+        # prevents error when using nested fish instances (Issue #93858)
+        if functions -q _old_fish_prompt
+            functions -e fish_prompt
+            functions -c _old_fish_prompt fish_prompt
+            functions -e _old_fish_prompt
+        end
     end
 
     set -e VIRTUAL_ENV
diff --git a/Lib/wsgiref/validate.py b/Lib/wsgiref/validate.py
index 6e16578dbb..6044e320a4 100644
--- a/Lib/wsgiref/validate.py
+++ b/Lib/wsgiref/validate.py
@@ -1,6 +1,6 @@
 # (c) 2005 Ian Bicking and contributors; written for Paste (http://pythonpaste.org)
-# Licensed under the MIT license: http://www.opensource.org/licenses/mit-license.php
-# Also licenced under the Apache License, 2.0: http://opensource.org/licenses/apache2.0.php
+# Licensed under the MIT license: https://opensource.org/licenses/mit-license.php
+# Also licenced under the Apache License, 2.0: https://opensource.org/licenses/apache2.0.php
 # Licensed to PSF under a Contributor Agreement
 """
 Middleware to check for obedience to the WSGI specification.
diff --git a/Mac/BuildScript/build-installer.py b/Mac/BuildScript/build-installer.py
index dd6bcf5fe7..86eed5ff95 100755
--- a/Mac/BuildScript/build-installer.py
+++ b/Mac/BuildScript/build-installer.py
@@ -359,9 +359,9 @@ def library_recipes():
                   ),
           ),
           dict(
-              name="SQLite 3.38.4",
-              url="https://sqlite.org/2022/sqlite-autoconf-3380400.tar.gz",
-              checksum="34c0b92a0609ed4ce78582e8dc1ed45a",
+              name="SQLite 3.39.4",
+              url="https://sqlite.org/2022/sqlite-autoconf-3390400.tar.gz",
+              checksum="44b7e6691b0954086f717a6c43b622a5",
               extra_cflags=('-Os '
                             '-DSQLITE_ENABLE_FTS5 '
                             '-DSQLITE_ENABLE_FTS4 '
diff --git a/Mac/BuildScript/resources/License.rtf b/Mac/BuildScript/resources/License.rtf
index 7fe7e66f4c..1255d1ce48 100644
--- a/Mac/BuildScript/resources/License.rtf
+++ b/Mac/BuildScript/resources/License.rtf
@@ -12,13 +12,13 @@
 HISTORY OF THE SOFTWARE\
 
 \f1\b0 \ulnone \
-Python was created in the early 1990s by Guido van Rossum at Stichting Mathematisch Centrum (CWI, see http://www.cwi.nl) in the Netherlands as a successor of a language called ABC. Guido remains Python's principal author, although it includes many contributions from others.\
+Python was created in the early 1990s by Guido van Rossum at Stichting Mathematisch Centrum (CWI, see https://www.cwi.nl) in the Netherlands as a successor of a language called ABC. Guido remains Python's principal author, although it includes many contributions from others.\
 \
-In 1995, Guido continued his work on Python at the Corporation for National Research Initiatives (CNRI, see http://www.cnri.reston.va.us) in Reston, Virginia where he released several versions of the software.\
+In 1995, Guido continued his work on Python at the Corporation for National Research Initiatives (CNRI, see https://www.cnri.reston.va.us) in Reston, Virginia where he released several versions of the software.\
 \
-In May 2000, Guido and the Python core development team moved to BeOpen.com to form the BeOpen PythonLabs team. In October of the same year, the PythonLabs team moved to Digital Creations (now Zope Corporation, see http://www.zope.org). In 2001, the Python Software Foundation (PSF, see https://www.python.org/psf/) was formed, a non-profit organization created specifically to own Python-related Intellectual Property. Zope Corporation is a sponsoring member of the PSF.\
+In May 2000, Guido and the Python core development team moved to BeOpen.com to form the BeOpen PythonLabs team. In October of the same year, the PythonLabs team moved to Digital Creations (now Zope Corporation, see https://www.zope.dev). In 2001, the Python Software Foundation (PSF, see https://www.python.org/psf/) was formed, a non-profit organization created specifically to own Python-related Intellectual Property. Zope Corporation is a sponsoring member of the PSF.\
 \
-All Python releases are Open Source (see http://www.opensource.org for the Open Source Definition). Historically, most, but not all, Python releases have also been GPL-compatible; the table below summarizes the various releases.\
+All Python releases are Open Source (see https://opensource.org for the Open Source Definition). Historically, most, but not all, Python releases have also been GPL-compatible; the table below summarizes the various releases.\
 \
 
 \f2\b Release         Derived     Year        Owner       GPL-\
diff --git a/Makefile.pre.in b/Makefile.pre.in
index 8fbcd7ac17..17466c91b3 100644
--- a/Makefile.pre.in
+++ b/Makefile.pre.in
@@ -817,10 +817,11 @@ $(DLLLIBRARY) libpython$(LDVERSION).dll.a: $(LIBRARY_OBJS)
 # wasm assets directory is relative to current build dir, e.g. "./usr/local".
 # --preload-file turns a relative asset path into an absolute path.
 
+.PHONY: wasm_stdlib
+wasm_stdlib: $(WASM_STDLIB)
 $(WASM_STDLIB): $(srcdir)/Lib/*.py $(srcdir)/Lib/*/*.py \
 	    $(srcdir)/Tools/wasm/wasm_assets.py \
-	    Makefile pybuilddir.txt Modules/Setup.local \
-	    python.html python.worker.js
+	    Makefile pybuilddir.txt Modules/Setup.local
 	$(PYTHON_FOR_BUILD) $(srcdir)/Tools/wasm/wasm_assets.py \
 	    --buildroot . --prefix $(prefix)
 
@@ -1713,6 +1714,10 @@ buildbottest: all
 		fi
 		$(TESTRUNNER) -j 1 -u all -W --slowest --fail-env-changed --timeout=$(TESTTIMEOUT) $(TESTOPTS)
 
+# Like testall, but run Python tests with HOSTRUNNER directly.
+hostrunnertest: all
+	$(RUNSHARED) $(HOSTRUNNER) ./$(BUILDPYTHON) -m test -u all $(TESTOPTS)
+
 pythoninfo: all
 		$(RUNSHARED) $(HOSTRUNNER) ./$(BUILDPYTHON) -m test.pythoninfo
 
@@ -1999,6 +2004,7 @@ TESTSUBDIRS=	ctypes/test \
 		test/test_warnings test/test_warnings/data \
 		test/test_zoneinfo test/test_zoneinfo/data \
 		test/tracedmodules \
+		test/typinganndata \
 		test/xmltestdata test/xmltestdata/c14n-20 \
 		test/ziptestdata \
 		tkinter/test tkinter/test/test_tkinter \
@@ -2383,8 +2389,7 @@ rmtestturds:
 	-rm -f gb-18030-2000.xml
 
 docclean:
-	-rm -rf Doc/build
-	-rm -rf Doc/tools/sphinx Doc/tools/pygments Doc/tools/docutils
+	$(MAKE) -C $(srcdir)/Doc clean
 
 # like the 'clean' target but retain the profile guided optimization (PGO)
 # data.  The PGO data is only valid if source code remains unchanged.
@@ -2435,7 +2440,7 @@ clobber: clean
 # Make things extra clean, before making a distribution:
 # remove all generated files, even Makefile[.pre]
 # Keep configure and Python-ast.[ch], it's possible they can't be generated
-distclean: clobber
+distclean: clobber docclean
 	for file in $(srcdir)/Lib/test/data/* ; do \
 	    if test "$$file" != "$(srcdir)/Lib/test/data/README"; then rm "$$file"; fi; \
 	done
diff --git a/Misc/HISTORY b/Misc/HISTORY
index 570638869f..0330c4891b 100644
--- a/Misc/HISTORY
+++ b/Misc/HISTORY
@@ -19610,7 +19610,7 @@ durable way.  For example, some people say they're confused by that
 the Open Source Initiative's entry for the Python Software Foundation
 License::
 
-      http://www.opensource.org/licenses/PythonSoftFoundation.php
+      https://opensource.org/licenses/PythonSoftFoundation.php
 
 says "Python 2.1.1" all over it, wondering whether it applies only
 to Python 2.1.1.
--- a/Modules/_asynciomodule.c
+++ b/Modules/_asynciomodule.c
@@ -1052,7 +1052,11 @@ _asyncio_Future_remove_done_callback(FutureObj *self, PyObject *fn)
         return NULL;
     }
 
-    for (i = 0; i < PyList_GET_SIZE(self->fut_callbacks); i++) {
+    // Beware: PyObject_RichCompareBool below may change fut_callbacks.
+    // See GH-97592.
+    for (i = 0;
+         self->fut_callbacks != NULL && i < PyList_GET_SIZE(self->fut_callbacks);
+         i++) {
         int ret;
         PyObject *item = PyList_GET_ITEM(self->fut_callbacks, i);
         Py_INCREF(item);
@@ -1071,7 +1075,8 @@ _asyncio_Future_remove_done_callback(FutureObj *self, PyObject *fn)
         }
     }
 
-    if (j == 0) {
+    // Note: fut_callbacks may have been cleared.
+    if (j == 0 || self->fut_callbacks == NULL) {
         Py_CLEAR(self->fut_callbacks);
         Py_DECREF(newlist);
         return PyLong_FromSsize_t(len + cleared_callback0);
diff --git a/Modules/_csv.c b/Modules/_csv.c
index cbf4c5de51..7519da6807 100644
--- a/Modules/_csv.c
+++ b/Modules/_csv.c
@@ -704,7 +704,7 @@ parse_process_char(ReaderObj *self, _csvstate *module_state, Py_UCS4 c)
             self->state = ESCAPED_CHAR;
         }
         else if (c == ' ' && dialect->skipinitialspace)
-            /* ignore space at start of field */
+            /* ignore spaces at start of field */
             ;
         else if (c == dialect->delimiter) {
             /* save empty field */
@@ -1647,9 +1647,9 @@ PyDoc_STRVAR(csv_module_doc,
 "        quoting character.  It defaults to '\"'.\n"
 "    * delimiter - specifies a one-character string to use as the\n"
 "        field separator.  It defaults to ','.\n"
-"    * skipinitialspace - specifies how to interpret whitespace which\n"
-"        immediately follows a delimiter.  It defaults to False, which\n"
-"        means that whitespace immediately following a delimiter is part\n"
+"    * skipinitialspace - specifies how to interpret spaces which\n"
+"        immediately follow a delimiter.  It defaults to False, which\n"
+"        means that spaces immediately following a delimiter is part\n"
 "        of the following field.\n"
 "    * lineterminator -  specifies the character sequence which should\n"
 "        terminate rows.\n"
diff --git a/Modules/_sre/sre.c b/Modules/_sre/sre.c
index 0a7019a085..448e761c98 100644
--- a/Modules/_sre/sre.c
+++ b/Modules/_sre/sre.c
@@ -1528,7 +1528,7 @@ _sre_compile_impl(PyObject *module, PyObject *pattern, int flags,
 #endif
 
 /* Report failure */
-#define FAIL do { VTRACE(("FAIL: %d\n", __LINE__)); return 0; } while (0)
+#define FAIL do { VTRACE(("FAIL: %d\n", __LINE__)); return -1; } while (0)
 
 /* Extract opcode, argument, or skip count from code array */
 #define GET_OP                                          \
@@ -1552,7 +1552,7 @@ _sre_compile_impl(PyObject *module, PyObject *pattern, int flags,
         skip = *code;                                   \
         VTRACE(("%lu (skip to %p)\n",                   \
                (unsigned long)skip, code+skip));        \
-        if (skip-adj > (uintptr_t)(end - code))      \
+        if (skip-adj > (uintptr_t)(end - code))         \
             FAIL;                                       \
         code++;                                         \
     } while (0)
@@ -1641,9 +1641,10 @@ _validate_charset(SRE_CODE *code, SRE_CODE *end)
         }
     }
 
-    return 1;
+    return 0;
 }
 
+/* Returns 0 on success, -1 on failure, and 1 if the last op is JUMP. */
 static int
 _validate_inner(SRE_CODE *code, SRE_CODE *end, Py_ssize_t groups)
 {
@@ -1721,7 +1722,7 @@ _validate_inner(SRE_CODE *code, SRE_CODE *end, Py_ssize_t groups)
         case SRE_OP_IN_LOC_IGNORE:
             GET_SKIP;
             /* Stop 1 before the end; we check the FAILURE below */
-            if (!_validate_charset(code, code+skip-2))
+            if (_validate_charset(code, code+skip-2))
                 FAIL;
             if (code[skip-2] != SRE_OP_FAILURE)
                 FAIL;
@@ -1775,7 +1776,7 @@ _validate_inner(SRE_CODE *code, SRE_CODE *end, Py_ssize_t groups)
                 }
                 /* Validate the charset */
                 if (flags & SRE_INFO_CHARSET) {
-                    if (!_validate_charset(code, newcode-1))
+                    if (_validate_charset(code, newcode-1))
                         FAIL;
                     if (newcode[-1] != SRE_OP_FAILURE)
                         FAIL;
@@ -1796,7 +1797,7 @@ _validate_inner(SRE_CODE *code, SRE_CODE *end, Py_ssize_t groups)
                     if (skip == 0)
                         break;
                     /* Stop 2 before the end; we check the JUMP below */
-                    if (!_validate_inner(code, code+skip-3, groups))
+                    if (_validate_inner(code, code+skip-3, groups))
                         FAIL;
                     code += skip-3;
                     /* Check that it ends with a JUMP, and that each JUMP
@@ -1810,6 +1811,8 @@ _validate_inner(SRE_CODE *code, SRE_CODE *end, Py_ssize_t groups)
                     else if (code+skip-1 != target)
                         FAIL;
                 }
+                if (code != target)
+                    FAIL;
             }
             break;
 
@@ -1825,7 +1828,7 @@ _validate_inner(SRE_CODE *code, SRE_CODE *end, Py_ssize_t groups)
                     FAIL;
                 if (max > SRE_MAXREPEAT)
                     FAIL;
-                if (!_validate_inner(code, code+skip-4, groups))
+                if (_validate_inner(code, code+skip-4, groups))
                     FAIL;
                 code += skip-4;
                 GET_OP;
@@ -1845,7 +1848,7 @@ _validate_inner(SRE_CODE *code, SRE_CODE *end, Py_ssize_t groups)
                     FAIL;
                 if (max > SRE_MAXREPEAT)
                     FAIL;
-                if (!_validate_inner(code, code+skip-3, groups))
+                if (_validate_inner(code, code+skip-3, groups))
                     FAIL;
                 code += skip-3;
                 GET_OP;
@@ -1863,7 +1866,7 @@ _validate_inner(SRE_CODE *code, SRE_CODE *end, Py_ssize_t groups)
         case SRE_OP_ATOMIC_GROUP:
             {
                 GET_SKIP;
-                if (!_validate_inner(code, code+skip-2, groups))
+                if (_validate_inner(code, code+skip-2, groups))
                     FAIL;
                 code += skip-2;
                 GET_OP;
@@ -1915,24 +1918,17 @@ _validate_inner(SRE_CODE *code, SRE_CODE *end, Py_ssize_t groups)
                to allow arbitrary jumps anywhere in the code; so we just look
                for a JUMP opcode preceding our skip target.
             */
-            if (skip >= 3 && skip-3 < (uintptr_t)(end - code) &&
-                code[skip-3] == SRE_OP_JUMP)
-            {
-                VTRACE(("both then and else parts present\n"));
-                if (!_validate_inner(code+1, code+skip-3, groups))
-                    FAIL;
+            VTRACE(("then part:\n"));
+            int rc = _validate_inner(code+1, code+skip-1, groups);
+            if (rc == 1) {
+                VTRACE(("else part:\n"));
                 code += skip-2; /* Position after JUMP, at <skipno> */
                 GET_SKIP;
-                if (!_validate_inner(code, code+skip-1, groups))
-                    FAIL;
-                code += skip-1;
-            }
-            else {
-                VTRACE(("only a then part present\n"));
-                if (!_validate_inner(code+1, code+skip-1, groups))
-                    FAIL;
-                code += skip-1;
+                rc = _validate_inner(code, code+skip-1, groups);
             }
+            if (rc)
+                FAIL;
+            code += skip-1;
             break;
 
         case SRE_OP_ASSERT:
@@ -1943,7 +1939,7 @@ _validate_inner(SRE_CODE *code, SRE_CODE *end, Py_ssize_t groups)
             if (arg & 0x80000000)
                 FAIL; /* Width too large */
             /* Stop 1 before the end; we check the SUCCESS below */
-            if (!_validate_inner(code+1, code+skip-2, groups))
+            if (_validate_inner(code+1, code+skip-2, groups))
                 FAIL;
             code += skip-2;
             GET_OP;
@@ -1951,6 +1947,12 @@ _validate_inner(SRE_CODE *code, SRE_CODE *end, Py_ssize_t groups)
                 FAIL;
             break;
 
+        case SRE_OP_JUMP:
+            if (code + 1 != end)
+                FAIL;
+            VTRACE(("JUMP: %d\n", __LINE__));
+            return 1;
+
         default:
             FAIL;
 
@@ -1958,7 +1960,7 @@ _validate_inner(SRE_CODE *code, SRE_CODE *end, Py_ssize_t groups)
     }
 
     VTRACE(("okay\n"));
-    return 1;
+    return 0;
 }
 
 static int
@@ -1973,7 +1975,7 @@ _validate_outer(SRE_CODE *code, SRE_CODE *end, Py_ssize_t groups)
 static int
 _validate(PatternObject *self)
 {
-    if (!_validate_outer(self->code, self->code+self->codesize, self->groups))
+    if (_validate_outer(self->code, self->code+self->codesize, self->groups))
     {
         PyErr_SetString(PyExc_RuntimeError, "invalid SRE code");
         return 0;
diff --git a/Modules/_testcapimodule.c b/Modules/_testcapimodule.c
index 43fec8138a..1c085a45f8 100644
--- a/Modules/_testcapimodule.c
+++ b/Modules/_testcapimodule.c
@@ -5348,6 +5348,40 @@ get_mapping_items(PyObject* self, PyObject *obj)
     return PyMapping_Items(obj);
 }
 
+static PyObject *
+test_mapping_has_key_string(PyObject *self, PyObject *Py_UNUSED(args))
+{
+    PyObject *context = PyDict_New();
+    PyObject *val = PyLong_FromLong(1);
+
+    // Since this uses `const char*` it is easier to test this in C:
+    PyDict_SetItemString(context, "a", val);
+    if (!PyMapping_HasKeyString(context, "a")) {
+        PyErr_SetString(PyExc_RuntimeError,
+                        "Existing mapping key does not exist");
+        return NULL;
+    }
+    if (PyMapping_HasKeyString(context, "b")) {
+        PyErr_SetString(PyExc_RuntimeError,
+                        "Missing mapping key exists");
+        return NULL;
+    }
+
+    Py_DECREF(val);
+    Py_DECREF(context);
+    Py_RETURN_NONE;
+}
+
+static PyObject *
+mapping_has_key(PyObject* self, PyObject *args)
+{
+    PyObject *context, *key;
+    if (!PyArg_ParseTuple(args, "OO", &context, &key)) {
+        return NULL;
+    }
+    return PyLong_FromLong(PyMapping_HasKey(context, key));
+}
+
 
 static PyObject *
 test_pythread_tss_key_state(PyObject *self, PyObject *args)
@@ -5935,6 +5969,12 @@ frame_getlasti(PyObject *self, PyObject *frame)
     return PyLong_FromLong(lasti);
 }
 
+static PyObject *
+eval_get_func_name(PyObject *self, PyObject *func)
+{
+    return PyUnicode_FromString(PyEval_GetFuncName(func));
+}
+
 static PyObject *
 get_feature_macros(PyObject *self, PyObject *Py_UNUSED(args))
 {
@@ -6075,6 +6115,43 @@ settrace_to_record(PyObject *self, PyObject *list)
 }
 
 static PyObject *negative_dictoffset(PyObject *, PyObject *);
+
+static PyObject *
+function_get_code(PyObject *self, PyObject *func)
+{
+    PyObject *code = PyFunction_GetCode(func);
+    if (code != NULL) {
+        Py_INCREF(code);
+        return code;
+    } else {
+        return NULL;
+    }
+}
+
+static PyObject *
+function_get_globals(PyObject *self, PyObject *func)
+{
+    PyObject *globals = PyFunction_GetGlobals(func);
+    if (globals != NULL) {
+        Py_INCREF(globals);
+        return globals;
+    } else {
+        return NULL;
+    }
+}
+
+static PyObject *
+function_get_module(PyObject *self, PyObject *func)
+{
+    PyObject *module = PyFunction_GetModule(func);
+    if (module != NULL) {
+        Py_INCREF(module);
+        return module;
+    } else {
+        return NULL;
+    }
+}
+
 static PyObject *test_buildvalue_issue38913(PyObject *, PyObject *);
 static PyObject *getargs_s_hash_int(PyObject *, PyObject *, PyObject*);
 static PyObject *getargs_s_hash_int2(PyObject *, PyObject *, PyObject*);
@@ -6339,6 +6416,8 @@ static PyMethodDef TestMethods[] = {
     {"get_mapping_keys", get_mapping_keys, METH_O},
     {"get_mapping_values", get_mapping_values, METH_O},
     {"get_mapping_items", get_mapping_items, METH_O},
+    {"test_mapping_has_key_string", test_mapping_has_key_string, METH_NOARGS},
+    {"mapping_has_key", mapping_has_key, METH_VARARGS},
     {"test_pythread_tss_key_state", test_pythread_tss_key_state, METH_VARARGS},
     {"hamt", new_hamt, METH_NOARGS},
     {"bad_get", _PyCFunction_CAST(bad_get), METH_FASTCALL},
@@ -6372,9 +6451,13 @@ static PyMethodDef TestMethods[] = {
     {"frame_getgenerator", frame_getgenerator, METH_O, NULL},
     {"frame_getbuiltins", frame_getbuiltins, METH_O, NULL},
     {"frame_getlasti", frame_getlasti, METH_O, NULL},
+    {"eval_get_func_name", eval_get_func_name, METH_O, NULL},
     {"get_feature_macros", get_feature_macros, METH_NOARGS, NULL},
     {"test_code_api", test_code_api, METH_NOARGS, NULL},
     {"settrace_to_record", settrace_to_record, METH_O, NULL},
+    {"function_get_code", function_get_code, METH_O, NULL},
+    {"function_get_globals", function_get_globals, METH_O, NULL},
+    {"function_get_module", function_get_module, METH_O, NULL},
     {NULL, NULL} /* sentinel */
 };
 
diff --git a/Modules/audioop.c b/Modules/audioop.c
index d74e634ac4..b764dd97d5 100644
--- a/Modules/audioop.c
+++ b/Modules/audioop.c
@@ -1,3 +1,33 @@
+/* The audioop module uses the code base in g777.c file of the Sox project.
+ * Source: https://web.archive.org/web/19970716121258/http://www.spies.com/Sox/Archive/soxgamma.tar.gz
+ *                 Programming the AdLib/Sound Blaster
+ *                              FM Music Chips
+ *                          Version 2.0 (24 Feb 1992)
+ *
+ *                 Copyright (c) 1991, 1992 by Jeffrey S. Lee
+ *
+ *                               jlee@smylex.uucp
+ *
+ *
+ *
+ *                       Warranty and Copyright Policy
+ *
+ *     This document is provided on an "as-is" basis, and its author makes
+ *     no warranty or representation, express or implied, with respect to
+ *    its quality performance or fitness for a particular purpose.  In no
+ *    event will the author of this document be liable for direct, indirect,
+ *    special, incidental, or consequential damages arising out of the use
+ *    or inability to use the information contained within.  Use of this
+ *    document is at your own risk.
+ *
+ *    This file may be used and copied freely so long as the applicable
+ *    copyright notices are retained, and no modifications are made to the
+ *    text of the document.  No money shall be charged for its distribution
+ *    beyond reasonable shipping, handling and duplication costs, nor shall
+ *    proprietary changes be made to this document so that it cannot be
+ *    distributed freely.  This document may not be included in published
+ *    material or commercial packages without the written consent of its
+ *    author. */
 
 /* audioopmodule - Module to detect peak values in arrays */
 
@@ -28,20 +58,6 @@ fbound(double val, double minval, double maxval)
 }
 
 
-/* Code shamelessly stolen from sox, 12.17.7, g711.c
-** (c) Craig Reese, Joe Campbell and Jeff Poskanzer 1989 */
-
-/* From g711.c:
- *
- * December 30, 1994:
- * Functions linear2alaw, linear2ulaw have been updated to correctly
- * convert unquantized 16 bit values.
- * Tables for direct u- to A-law and A- to u-law conversions have been
- * corrected.
- * Borge Lindberg, Center for PersonKommunikation, Aalborg University.
- * bli@cpk.auc.dk
- *
- */
 #define BIAS 0x84   /* define the add-in bias for 16 bit samples */
 #define CLIP 32635
 #define SIGN_BIT        (0x80)          /* Sign bit for an A-law byte. */
diff --git a/Modules/clinic/_winapi.c.h b/Modules/clinic/_winapi.c.h
index 87f624f981..118e7bfd29 100644
--- a/Modules/clinic/_winapi.c.h
+++ b/Modules/clinic/_winapi.c.h
@@ -192,7 +192,7 @@ _winapi_CreateFileMapping(PyObject *module, PyObject *const *args, Py_ssize_t na
     DWORD protect;
     DWORD max_size_high;
     DWORD max_size_low;
-    LPCWSTR name;
+    LPCWSTR name = NULL;
     HANDLE _return_value;
 
     if (!_PyArg_ParseStack(args, nargs, "" F_HANDLE "" F_POINTER "kkkO&:CreateFileMapping",
@@ -233,8 +233,8 @@ static PyObject *
 _winapi_CreateJunction(PyObject *module, PyObject *const *args, Py_ssize_t nargs)
 {
     PyObject *return_value = NULL;
-    LPCWSTR src_path;
-    LPCWSTR dst_path;
+    LPCWSTR src_path = NULL;
+    LPCWSTR dst_path = NULL;
 
     if (!_PyArg_CheckPositional("CreateJunction", nargs, 2, 2)) {
         goto exit;
@@ -394,14 +394,14 @@ static PyObject *
 _winapi_CreateProcess(PyObject *module, PyObject *const *args, Py_ssize_t nargs)
 {
     PyObject *return_value = NULL;
-    const Py_UNICODE *application_name;
+    const Py_UNICODE *application_name = NULL;
     PyObject *command_line;
     PyObject *proc_attrs;
     PyObject *thread_attrs;
     BOOL inherit_handles;
     DWORD creation_flags;
     PyObject *env_mapping;
-    const Py_UNICODE *current_directory;
+    const Py_UNICODE *current_directory = NULL;
     PyObject *startup_info;
 
     if (!_PyArg_ParseStack(args, nargs, "O&OOOikOO&O:CreateProcess",
@@ -749,7 +749,7 @@ _winapi_OpenFileMapping(PyObject *module, PyObject *const *args, Py_ssize_t narg
     PyObject *return_value = NULL;
     DWORD desired_access;
     BOOL inherit_handle;
-    LPCWSTR name;
+    LPCWSTR name = NULL;
     HANDLE _return_value;
 
     if (!_PyArg_ParseStack(args, nargs, "kiO&:OpenFileMapping",
@@ -1216,4 +1216,4 @@ _winapi__mimetypes_read_windows_registry(PyObject *module, PyObject *const *args
 exit:
     return return_value;
 }
-/*[clinic end generated code: output=dfbccec8f11b7433 input=a9049054013a1b77]*/
+/*[clinic end generated code: output=60b036183b92659e input=a9049054013a1b77]*/
diff --git a/Modules/clinic/overlapped.c.h b/Modules/clinic/overlapped.c.h
index 2861338317..6673cbfe46 100644
--- a/Modules/clinic/overlapped.c.h
+++ b/Modules/clinic/overlapped.c.h
@@ -220,7 +220,7 @@ _overlapped_CreateEvent(PyObject *module, PyObject *const *args, Py_ssize_t narg
     PyObject *EventAttributes;
     BOOL ManualReset;
     BOOL InitialState;
-    const Py_UNICODE *Name;
+    const Py_UNICODE *Name = NULL;
 
     if (!_PyArg_ParseStack(args, nargs, "OiiO&:CreateEvent",
         &EventAttributes, &ManualReset, &InitialState, _PyUnicode_WideCharString_Opt_Converter, &Name)) {
@@ -806,7 +806,7 @@ static PyObject *
 _overlapped_Overlapped_ConnectPipe(OverlappedObject *self, PyObject *arg)
 {
     PyObject *return_value = NULL;
-    const Py_UNICODE *Address;
+    const Py_UNICODE *Address = NULL;
 
     if (!PyUnicode_Check(arg)) {
         _PyArg_BadArgument("ConnectPipe", "argument", "str", arg);
@@ -851,8 +851,8 @@ _overlapped_WSAConnect(PyObject *module, PyObject *const *args, Py_ssize_t nargs
     HANDLE ConnectSocket;
     PyObject *AddressObj;
 
-    if (!_PyArg_ParseStack(args, nargs, ""F_HANDLE"O:WSAConnect",
-        &ConnectSocket, &AddressObj)) {
+    if (!_PyArg_ParseStack(args, nargs, ""F_HANDLE"O!:WSAConnect",
+        &ConnectSocket, &PyTuple_Type, &AddressObj)) {
         goto exit;
     }
     return_value = _overlapped_WSAConnect_impl(module, ConnectSocket, AddressObj);
@@ -884,8 +884,8 @@ _overlapped_Overlapped_WSASendTo(OverlappedObject *self, PyObject *const *args,
     DWORD flags;
     PyObject *AddressObj;
 
-    if (!_PyArg_ParseStack(args, nargs, ""F_HANDLE"y*kO:WSASendTo",
-        &handle, &bufobj, &flags, &AddressObj)) {
+    if (!_PyArg_ParseStack(args, nargs, ""F_HANDLE"y*kO!:WSASendTo",
+        &handle, &bufobj, &flags, &PyTuple_Type, &AddressObj)) {
         goto exit;
     }
     return_value = _overlapped_Overlapped_WSASendTo_impl(self, handle, &bufobj, flags, AddressObj);
@@ -968,4 +968,4 @@ exit:
 
     return return_value;
 }
-/*[clinic end generated code: output=b0f15f5c09f1147e input=a9049054013a1b77]*/
+/*[clinic end generated code: output=5023f7748f0e073e input=a9049054013a1b77]*/
diff --git a/Modules/clinic/posixmodule.c.h b/Modules/clinic/posixmodule.c.h
index ca2699b4e3..b66cd857e4 100644
--- a/Modules/clinic/posixmodule.c.h
+++ b/Modules/clinic/posixmodule.c.h
@@ -1360,7 +1360,8 @@ PyDoc_STRVAR(os_mkdir__doc__,
 "dir_fd may not be implemented on your platform.\n"
 "  If it is unavailable, using it will raise a NotImplementedError.\n"
 "\n"
-"The mode argument is ignored on Windows.");
+"The mode argument is ignored on Windows. Where it is used, the current umask\n"
+"value is first masked out.");
 
 #define OS_MKDIR_METHODDEF    \
     {"mkdir", _PyCFunction_CAST(os_mkdir), METH_FASTCALL|METH_KEYWORDS, os_mkdir__doc__},
@@ -1749,7 +1750,7 @@ os_system(PyObject *module, PyObject *const *args, Py_ssize_t nargs, PyObject *k
     static const char * const _keywords[] = {"command", NULL};
     static _PyArg_Parser _parser = {NULL, _keywords, "system", 0};
     PyObject *argsbuf[1];
-    const Py_UNICODE *command;
+    const Py_UNICODE *command = NULL;
     long _return_value;
 
     args = _PyArg_UnpackKeywords(args, nargs, NULL, kwnames, &_parser, 1, 1, 0, argsbuf);
@@ -9378,4 +9379,4 @@ exit:
 #ifndef OS_WAITSTATUS_TO_EXITCODE_METHODDEF
     #define OS_WAITSTATUS_TO_EXITCODE_METHODDEF
 #endif /* !defined(OS_WAITSTATUS_TO_EXITCODE_METHODDEF) */
-/*[clinic end generated code: output=3032d9c5c3aaa165 input=a9049054013a1b77]*/
+/*[clinic end generated code: output=8dd784bf1e41b881 input=a9049054013a1b77]*/
diff --git a/Modules/errnomodule.c b/Modules/errnomodule.c
index 0516e73670..4de4144520 100644
--- a/Modules/errnomodule.c
+++ b/Modules/errnomodule.c
@@ -927,6 +927,10 @@ errno_exec(PyObject *module)
 #ifdef EQFULL
     add_errcode("EQFULL", EQFULL, "Interface output queue is full");
 #endif
+#ifdef ENOTCAPABLE
+    // WASI extension
+    add_errcode("ENOTCAPABLE", ENOTCAPABLE, "Capabilities insufficient");
+#endif
 
     Py_DECREF(error_dict);
     return 0;
diff --git a/Modules/expat/COPYING b/Modules/expat/COPYING
index 3c0142e71c..ce9e593929 100644
--- a/Modules/expat/COPYING
+++ b/Modules/expat/COPYING
@@ -1,5 +1,5 @@
 Copyright (c) 1998-2000 Thai Open Source Software Center Ltd and Clark Cooper
-Copyright (c) 2001-2019 Expat maintainers
+Copyright (c) 2001-2022 Expat maintainers
 
 Permission is hereby granted, free of charge, to any person obtaining
 a copy of this software and associated documentation files (the
diff --git a/Modules/expat/expat.h b/Modules/expat/expat.h
index c9214f6407..1c83563cbf 100644
--- a/Modules/expat/expat.h
+++ b/Modules/expat/expat.h
@@ -1054,8 +1054,8 @@ XML_SetBillionLaughsAttackProtectionActivationThreshold(
    See http://semver.org.
 */
 #define XML_MAJOR_VERSION 2
-#define XML_MINOR_VERSION 4
-#define XML_MICRO_VERSION 7
+#define XML_MINOR_VERSION 5
+#define XML_MICRO_VERSION 0
 
 #ifdef __cplusplus
 }
diff --git a/Modules/expat/internal.h b/Modules/expat/internal.h
index 444eba0fb0..e09f533b23 100644
--- a/Modules/expat/internal.h
+++ b/Modules/expat/internal.h
@@ -28,7 +28,7 @@
    Copyright (c) 2002-2003 Fred L. Drake, Jr. <fdrake@users.sourceforge.net>
    Copyright (c) 2002-2006 Karl Waclawek <karl@waclawek.net>
    Copyright (c) 2003      Greg Stein <gstein@users.sourceforge.net>
-   Copyright (c) 2016-2021 Sebastian Pipping <sebastian@pipping.org>
+   Copyright (c) 2016-2022 Sebastian Pipping <sebastian@pipping.org>
    Copyright (c) 2018      Yury Gribov <tetra2005@gmail.com>
    Copyright (c) 2019      David Loffredo <loffredo@steptools.com>
    Licensed under the MIT license:
@@ -107,7 +107,9 @@
 
 #include <limits.h> // ULONG_MAX
 
-#if defined(_WIN32) && ! defined(__USE_MINGW_ANSI_STDIO)
+#if defined(_WIN32)                                                            \
+    && (! defined(__USE_MINGW_ANSI_STDIO)                                      \
+        || (1 - __USE_MINGW_ANSI_STDIO - 1 == 0))
 #  define EXPAT_FMT_ULL(midpart) "%" midpart "I64u"
 #  if defined(_WIN64) // Note: modifiers "td" and "zu" do not work for MinGW
 #    define EXPAT_FMT_PTRDIFF_T(midpart) "%" midpart "I64d"
diff --git a/Modules/expat/siphash.h b/Modules/expat/siphash.h
index e5406d7ee9..303283ad2d 100644
--- a/Modules/expat/siphash.h
+++ b/Modules/expat/siphash.h
@@ -106,7 +106,7 @@
  * if this code is included and compiled as C++; related GCC warning is:
  * warning: use of C++11 long long integer constant [-Wlong-long]
  */
-#define _SIP_ULL(high, low) (((uint64_t)high << 32) | low)
+#define _SIP_ULL(high, low) ((((uint64_t)high) << 32) | (low))
 
 #define SIP_ROTL(x, b) (uint64_t)(((x) << (b)) | ((x) >> (64 - (b))))
 
diff --git a/Modules/expat/xmlparse.c b/Modules/expat/xmlparse.c
index 05216d997b..b6c2eca975 100644
--- a/Modules/expat/xmlparse.c
+++ b/Modules/expat/xmlparse.c
@@ -1,4 +1,4 @@
-/* fcb1a62fefa945567301146eb98e3ad3413e823a41c4378e84e8b6b6f308d824 (2.4.7+)
+/* 5ab094ffadd6edfc94c3eee53af44a86951f9f1f0933ada3114bbce2bfb02c99 (2.5.0+)
                             __  __            _
                          ___\ \/ /_ __   __ _| |_
                         / _ \\  /| '_ \ / _` | __|
@@ -19,7 +19,7 @@
    Copyright (c) 2016      Gustavo Grieco <gustavo.grieco@imag.fr>
    Copyright (c) 2016      Pascal Cuoq <cuoq@trust-in-soft.com>
    Copyright (c) 2016      Ed Schouten <ed@nuxi.nl>
-   Copyright (c) 2017-2018 Rhodri James <rhodri@wildebeest.org.uk>
+   Copyright (c) 2017-2022 Rhodri James <rhodri@wildebeest.org.uk>
    Copyright (c) 2017      Vclav Slavk <vaclav@slavik.io>
    Copyright (c) 2017      Viktor Szakats <commit@vsz.me>
    Copyright (c) 2017      Chanho Park <chanho61.park@samsung.com>
@@ -35,6 +35,7 @@
    Copyright (c) 2021      Dong-hee Na <donghee.na@python.org>
    Copyright (c) 2022      Samanta Navarro <ferivoz@riseup.net>
    Copyright (c) 2022      Jeffrey Walton <noloader@gmail.com>
+   Copyright (c) 2022      Jann Horn <jannh@google.com>
    Licensed under the MIT license:
 
    Permission is  hereby granted,  free of charge,  to any  person obtaining
@@ -1068,6 +1069,14 @@ parserCreate(const XML_Char *encodingName,
   parserInit(parser, encodingName);
 
   if (encodingName && ! parser->m_protocolEncodingName) {
+    if (dtd) {
+      // We need to stop the upcoming call to XML_ParserFree from happily
+      // destroying parser->m_dtd because the DTD is shared with the parent
+      // parser and the only guard that keeps XML_ParserFree from destroying
+      // parser->m_dtd is parser->m_isParamEntity but it will be set to
+      // XML_TRUE only later in XML_ExternalEntityParserCreate (or not at all).
+      parser->m_dtd = NULL;
+    }
     XML_ParserFree(parser);
     return NULL;
   }
@@ -3011,9 +3020,6 @@ doContent(XML_Parser parser, int startTagLevel, const ENCODING *enc,
         int len;
         const char *rawName;
         TAG *tag = parser->m_tagStack;
-        parser->m_tagStack = tag->parent;
-        tag->parent = parser->m_freeTagList;
-        parser->m_freeTagList = tag;
         rawName = s + enc->minBytesPerChar * 2;
         len = XmlNameLength(enc, rawName);
         if (len != tag->rawNameLength
@@ -3021,6 +3027,9 @@ doContent(XML_Parser parser, int startTagLevel, const ENCODING *enc,
           *eventPP = rawName;
           return XML_ERROR_TAG_MISMATCH;
         }
+        parser->m_tagStack = tag->parent;
+        tag->parent = parser->m_freeTagList;
+        parser->m_freeTagList = tag;
         --parser->m_tagLevel;
         if (parser->m_endElementHandler) {
           const XML_Char *localPart;
@@ -4271,7 +4280,7 @@ processXmlDecl(XML_Parser parser, int isGeneralTextEntity, const char *s,
   const XML_Char *storedEncName = NULL;
   const ENCODING *newEncoding = NULL;
   const char *version = NULL;
-  const char *versionend;
+  const char *versionend = NULL;
   const XML_Char *storedversion = NULL;
   int standalone = -1;
 
@@ -4975,10 +4984,10 @@ doProlog(XML_Parser parser, const ENCODING *enc, const char *s, const char *end,
               parser->m_handlerArg, parser->m_declElementType->name,
               parser->m_declAttributeId->name, parser->m_declAttributeType, 0,
               role == XML_ROLE_REQUIRED_ATTRIBUTE_VALUE);
-          poolClear(&parser->m_tempPool);
           handleDefault = XML_FALSE;
         }
       }
+      poolClear(&parser->m_tempPool);
       break;
     case XML_ROLE_DEFAULT_ATTRIBUTE_VALUE:
     case XML_ROLE_FIXED_ATTRIBUTE_VALUE:
@@ -5386,7 +5395,7 @@ doProlog(XML_Parser parser, const ENCODING *enc, const char *s, const char *end,
              *
              * If 'standalone' is false, the DTD must have no
              * parameter entities or we wouldn't have passed the outer
-             * 'if' statement.  That measn the only entity in the hash
+             * 'if' statement.  That means the only entity in the hash
              * table is the external subset name "#" which cannot be
              * given as a parameter entity name in XML syntax, so the
              * lookup must have returned NULL and we don't even reach
@@ -5798,19 +5807,27 @@ internalEntityProcessor(XML_Parser parser, const char *s, const char *end,
 
   if (result != XML_ERROR_NONE)
     return result;
-  else if (textEnd != next
-           && parser->m_parsingStatus.parsing == XML_SUSPENDED) {
+
+  if (textEnd != next && parser->m_parsingStatus.parsing == XML_SUSPENDED) {
     entity->processed = (int)(next - (const char *)entity->textPtr);
     return result;
-  } else {
+  }
+
 #ifdef XML_DTD
-    entityTrackingOnClose(parser, entity, __LINE__);
+  entityTrackingOnClose(parser, entity, __LINE__);
 #endif
-    entity->open = XML_FALSE;
-    parser->m_openInternalEntities = openEntity->next;
-    /* put openEntity back in list of free instances */
-    openEntity->next = parser->m_freeInternalEntities;
-    parser->m_freeInternalEntities = openEntity;
+  entity->open = XML_FALSE;
+  parser->m_openInternalEntities = openEntity->next;
+  /* put openEntity back in list of free instances */
+  openEntity->next = parser->m_freeInternalEntities;
+  parser->m_freeInternalEntities = openEntity;
+
+  // If there are more open entities we want to stop right here and have the
+  // upcoming call to XML_ResumeParser continue with entity content, or it would
+  // be ignored altogether.
+  if (parser->m_openInternalEntities != NULL
+      && parser->m_parsingStatus.parsing == XML_SUSPENDED) {
+    return XML_ERROR_NONE;
   }
 
 #ifdef XML_DTD
@@ -5826,10 +5843,15 @@ internalEntityProcessor(XML_Parser parser, const char *s, const char *end,
   {
     parser->m_processor = contentProcessor;
     /* see externalEntityContentProcessor vs contentProcessor */
-    return doContent(parser, parser->m_parentParser ? 1 : 0, parser->m_encoding,
-                     s, end, nextPtr,
-                     (XML_Bool)! parser->m_parsingStatus.finalBuffer,
-                     XML_ACCOUNT_DIRECT);
+    result = doContent(parser, parser->m_parentParser ? 1 : 0,
+                       parser->m_encoding, s, end, nextPtr,
+                       (XML_Bool)! parser->m_parsingStatus.finalBuffer,
+                       XML_ACCOUNT_DIRECT);
+    if (result == XML_ERROR_NONE) {
+      if (! storeRawNames(parser))
+        return XML_ERROR_NO_MEMORY;
+    }
+    return result;
   }
 }
 
diff --git a/Modules/expat/xmltok.c b/Modules/expat/xmltok.c
index c659983b40..2b7012a58b 100644
--- a/Modules/expat/xmltok.c
+++ b/Modules/expat/xmltok.c
@@ -21,6 +21,7 @@
    Copyright (c) 2017      Jos Gutirrez de la Concha <jose@zeroc.com>
    Copyright (c) 2019      David Loffredo <loffredo@steptools.com>
    Copyright (c) 2021      Dong-hee Na <donghee.na@python.org>
+   Copyright (c) 2022      Martin Ettl <ettl.martin78@googlemail.com>
    Licensed under the MIT license:
 
    Permission is  hereby granted,  free of charge,  to any  person obtaining
@@ -296,7 +297,7 @@ sb_charMatches(const ENCODING *enc, const char *p, int c) {
 }
 #else
 /* c is an ASCII character */
-#  define CHAR_MATCHES(enc, p, c) (*(p) == c)
+#  define CHAR_MATCHES(enc, p, c) (*(p) == (c))
 #endif
 
 #define PREFIX(ident) normal_##ident
@@ -740,7 +741,7 @@ DEFINE_UTF16_TO_UTF16(big2_)
   ((p)[1] == 0 ? ((struct normal_encoding *)(enc))->type[(unsigned char)*(p)]  \
                : unicode_byte_type((p)[1], (p)[0]))
 #define LITTLE2_BYTE_TO_ASCII(p) ((p)[1] == 0 ? (p)[0] : -1)
-#define LITTLE2_CHAR_MATCHES(p, c) ((p)[1] == 0 && (p)[0] == c)
+#define LITTLE2_CHAR_MATCHES(p, c) ((p)[1] == 0 && (p)[0] == (c))
 #define LITTLE2_IS_NAME_CHAR_MINBPC(p)                                         \
   UCS2_GET_NAMING(namePages, (unsigned char)p[1], (unsigned char)p[0])
 #define LITTLE2_IS_NMSTRT_CHAR_MINBPC(p)                                       \
@@ -875,7 +876,7 @@ static const struct normal_encoding internal_little2_encoding
        ? ((struct normal_encoding *)(enc))->type[(unsigned char)(p)[1]]        \
        : unicode_byte_type((p)[0], (p)[1]))
 #define BIG2_BYTE_TO_ASCII(p) ((p)[0] == 0 ? (p)[1] : -1)
-#define BIG2_CHAR_MATCHES(p, c) ((p)[0] == 0 && (p)[1] == c)
+#define BIG2_CHAR_MATCHES(p, c) ((p)[0] == 0 && (p)[1] == (c))
 #define BIG2_IS_NAME_CHAR_MINBPC(p)                                            \
   UCS2_GET_NAMING(namePages, (unsigned char)p[0], (unsigned char)p[1])
 #define BIG2_IS_NMSTRT_CHAR_MINBPC(p)                                          \
diff --git a/Modules/expat/xmltok_impl.c b/Modules/expat/xmltok_impl.c
index 4072b06497..1971d74bf8 100644
--- a/Modules/expat/xmltok_impl.c
+++ b/Modules/expat/xmltok_impl.c
@@ -16,6 +16,7 @@
    Copyright (c) 2018      Anton Maklakov <antmak.pub@gmail.com>
    Copyright (c) 2019      David Loffredo <loffredo@steptools.com>
    Copyright (c) 2020      Boris Kolpackov <boris@codesynthesis.com>
+   Copyright (c) 2022      Martin Ettl <ettl.martin78@googlemail.com>
    Licensed under the MIT license:
 
    Permission is  hereby granted,  free of charge,  to any  person obtaining
@@ -96,7 +97,7 @@
 
 #  define CHECK_NMSTRT_CASE(n, enc, ptr, end, nextTokPtr)                      \
   case BT_LEAD##n:                                                             \
-    if (end - ptr < n)                                                         \
+    if ((end) - (ptr) < (n))                                                   \
       return XML_TOK_PARTIAL_CHAR;                                             \
     if (IS_INVALID_CHAR(enc, ptr, n) || ! IS_NMSTRT_CHAR(enc, ptr, n)) {       \
       *nextTokPtr = ptr;                                                       \
@@ -124,7 +125,8 @@
 #    define PREFIX(ident) ident
 #  endif
 
-#  define HAS_CHARS(enc, ptr, end, count) (end - ptr >= count * MINBPC(enc))
+#  define HAS_CHARS(enc, ptr, end, count)                                      \
+    ((end) - (ptr) >= ((count)*MINBPC(enc)))
 
 #  define HAS_CHAR(enc, ptr, end) HAS_CHARS(enc, ptr, end, 1)
 
diff --git a/Modules/expat/xmltok_impl.h b/Modules/expat/xmltok_impl.h
index c518aada01..3469c4ae13 100644
--- a/Modules/expat/xmltok_impl.h
+++ b/Modules/expat/xmltok_impl.h
@@ -45,7 +45,7 @@ enum {
   BT_LF,       /* line feed = "\n" */
   BT_GT,       /* greater than = ">" */
   BT_QUOT,     /* quotation character = "\"" */
-  BT_APOS,     /* aposthrophe = "'" */
+  BT_APOS,     /* apostrophe = "'" */
   BT_EQUALS,   /* equal sign = "=" */
   BT_QUEST,    /* question mark = "?" */
   BT_EXCL,     /* exclamation mark = "!" */
diff --git a/Modules/getpath.c b/Modules/getpath.c
index 94479887cf..ceacf36d89 100644
--- a/Modules/getpath.c
+++ b/Modules/getpath.c
@@ -82,27 +82,32 @@ getpath_abspath(PyObject *Py_UNUSED(self), PyObject *args)
 static PyObject *
 getpath_basename(PyObject *Py_UNUSED(self), PyObject *args)
 {
-    const char *path;
-    if (!PyArg_ParseTuple(args, "s", &path)) {
+    PyObject *path;
+    if (!PyArg_ParseTuple(args, "U", &path)) {
         return NULL;
     }
-    const char *name = strrchr(path, SEP);
-    return PyUnicode_FromString(name ? name + 1 : path);
+    Py_ssize_t end = PyUnicode_GET_LENGTH(path);
+    Py_ssize_t pos = PyUnicode_FindChar(path, SEP, 0, end, -1);
+    if (pos < 0) {
+        return Py_NewRef(path);
+    }
+    return PyUnicode_Substring(path, pos + 1, end);
 }
 
 
 static PyObject *
 getpath_dirname(PyObject *Py_UNUSED(self), PyObject *args)
 {
-    const char *path;
-    if (!PyArg_ParseTuple(args, "s", &path)) {
+    PyObject *path;
+    if (!PyArg_ParseTuple(args, "U", &path)) {
         return NULL;
     }
-    const char *name = strrchr(path, SEP);
-    if (!name) {
+    Py_ssize_t end = PyUnicode_GET_LENGTH(path);
+    Py_ssize_t pos = PyUnicode_FindChar(path, SEP, 0, end, -1);
+    if (pos < 0) {
         return PyUnicode_FromStringAndSize(NULL, 0);
     }
-    return PyUnicode_FromStringAndSize(path, (name - path));
+    return PyUnicode_Substring(path, 0, pos);
 }
 
 
@@ -256,7 +261,7 @@ getpath_joinpath(PyObject *Py_UNUSED(self), PyObject *args)
     }
     Py_ssize_t n = PyTuple_GET_SIZE(args);
     if (n == 0) {
-        return PyUnicode_FromString(NULL);
+        return PyUnicode_FromStringAndSize(NULL, 0);
     }
     /* Convert all parts to wchar and accumulate max final length */
     wchar_t **parts = (wchar_t **)PyMem_Malloc(n * sizeof(wchar_t *));
diff --git a/Modules/getpath.py b/Modules/getpath.py
index dceeed7702..91d6fc92a2 100644
--- a/Modules/getpath.py
+++ b/Modules/getpath.py
@@ -351,11 +351,11 @@ def search_up(prefix, *landmarks, test=isfile):
         try:
             # Read pyvenv.cfg from one level above executable
             pyvenvcfg = readlines(joinpath(venv_prefix, VENV_LANDMARK))
-        except FileNotFoundError:
+        except (FileNotFoundError, PermissionError):
             # Try the same directory as executable
             pyvenvcfg = readlines(joinpath(venv_prefix2, VENV_LANDMARK))
             venv_prefix = venv_prefix2
-    except FileNotFoundError:
+    except (FileNotFoundError, PermissionError):
         venv_prefix = None
         pyvenvcfg = []
 
@@ -475,7 +475,7 @@ def search_up(prefix, *landmarks, test=isfile):
         # File exists but is empty
         platstdlib_dir = real_executable_dir
         build_prefix = joinpath(real_executable_dir, VPATH)
-    except FileNotFoundError:
+    except (FileNotFoundError, PermissionError):
         if isfile(joinpath(real_executable_dir, BUILD_LANDMARK)):
             build_prefix = joinpath(real_executable_dir, VPATH)
             if os_name == 'nt':
@@ -579,15 +579,28 @@ def search_up(prefix, *landmarks, test=isfile):
     # Detect exec_prefix by searching from executable for the platstdlib_dir
     if PLATSTDLIB_LANDMARK and not exec_prefix:
         if executable_dir:
-            exec_prefix = search_up(executable_dir, PLATSTDLIB_LANDMARK, test=isdir)
-        if not exec_prefix:
-            if EXEC_PREFIX:
-                exec_prefix = EXEC_PREFIX
-                if not isdir(joinpath(exec_prefix, PLATSTDLIB_LANDMARK)):
-                    warn('Could not find platform dependent libraries <exec_prefix>')
+            if os_name == 'nt':
+                # QUIRK: For compatibility and security, do not search for DLLs
+                # directory. The fallback below will cover it
+                exec_prefix = executable_dir
+            else:
+                exec_prefix = search_up(executable_dir, PLATSTDLIB_LANDMARK, test=isdir)
+        if not exec_prefix and EXEC_PREFIX:
+            exec_prefix = EXEC_PREFIX
+        if not exec_prefix or not isdir(joinpath(exec_prefix, PLATSTDLIB_LANDMARK)):
+            if os_name == 'nt':
+                # QUIRK: If DLLs is missing on Windows, don't warn, just assume
+                # that it's all the same as prefix.
+                # gh-98790: We set platstdlib_dir here to avoid adding "DLLs" into
+                # sys.path when it doesn't exist, which would give site-packages
+                # precedence over executable_dir, which is *probably* where our PYDs
+                # live. Ideally, whoever changes our layout will tell us what the
+                # layout is, but in the past this worked, so it should keep working.
+                platstdlib_dir = exec_prefix = prefix
             else:
                 warn('Could not find platform dependent libraries <exec_prefix>')
 
+
     # Fallback: assume exec_prefix == prefix
     if not exec_prefix:
         exec_prefix = prefix
@@ -689,7 +702,8 @@ def search_up(prefix, *landmarks, test=isfile):
             pythonpath.append(platstdlib_dir)
         if stdlib_dir:
             pythonpath.append(stdlib_dir)
-        pythonpath.append(executable_dir)
+        if executable_dir not in pythonpath:
+            pythonpath.append(executable_dir)
     else:
         if stdlib_dir:
             pythonpath.append(stdlib_dir)
diff --git a/Modules/mathmodule.c b/Modules/mathmodule.c
index aa93e756c6..0a907a0c04 100644
--- a/Modules/mathmodule.c
+++ b/Modules/mathmodule.c
@@ -2703,13 +2703,13 @@ math_dist_impl(PyObject *module, PyObject *p, PyObject *q)
     if (m != n) {
         PyErr_SetString(PyExc_ValueError,
                         "both points must have the same number of dimensions");
-        return NULL;
-
+        goto error_exit;
     }
     if (n > NUM_STACK_ELEMS) {
         diffs = (double *) PyObject_Malloc(n * sizeof(double));
         if (diffs == NULL) {
-            return PyErr_NoMemory();
+            PyErr_NoMemory();
+            goto error_exit;
         }
     }
     for (i=0 ; i<n ; i++) {
diff --git a/Modules/overlapped.c b/Modules/overlapped.c
index 74fba8346c..9334dcaa2e 100644
--- a/Modules/overlapped.c
+++ b/Modules/overlapped.c
@@ -1684,7 +1684,7 @@ Overlapped_traverse(OverlappedObject *self, visitproc visit, void *arg)
 _overlapped.WSAConnect
 
     client_handle as ConnectSocket: HANDLE
-    address_as_bytes as AddressObj: object
+    address_as_bytes as AddressObj: object(subclass_of='&PyTuple_Type')
     /
 
 Bind a remote address to a connectionless (UDP) socket.
@@ -1693,7 +1693,7 @@ Bind a remote address to a connectionless (UDP) socket.
 static PyObject *
 _overlapped_WSAConnect_impl(PyObject *module, HANDLE ConnectSocket,
                             PyObject *AddressObj)
-/*[clinic end generated code: output=ea0b4391e94dad63 input=169f8075e9ae7fa4]*/
+/*[clinic end generated code: output=ea0b4391e94dad63 input=7cf65313d49c015a]*/
 {
     char AddressBuf[sizeof(struct sockaddr_in6)];
     SOCKADDR *Address = (SOCKADDR*)AddressBuf;
@@ -1727,7 +1727,7 @@ _overlapped.Overlapped.WSASendTo
     handle: HANDLE
     buf as bufobj: Py_buffer
     flags: DWORD
-    address_as_bytes as AddressObj: object
+    address_as_bytes as AddressObj: object(subclass_of='&PyTuple_Type')
     /
 
 Start overlapped sendto over a connectionless (UDP) socket.
@@ -1737,7 +1737,7 @@ static PyObject *
 _overlapped_Overlapped_WSASendTo_impl(OverlappedObject *self, HANDLE handle,
                                       Py_buffer *bufobj, DWORD flags,
                                       PyObject *AddressObj)
-/*[clinic end generated code: output=3cdedc4cfaeb70cd input=b7c1749a62e2e374]*/
+/*[clinic end generated code: output=3cdedc4cfaeb70cd input=31f44cd4ab92fc33]*/
 {
     char AddressBuf[sizeof(struct sockaddr_in6)];
     SOCKADDR *Address = (SOCKADDR*)AddressBuf;
diff --git a/Modules/posixmodule.c b/Modules/posixmodule.c
index 309982af82..a45179f6a1 100644
--- a/Modules/posixmodule.c
+++ b/Modules/posixmodule.c
@@ -4560,12 +4560,13 @@ If dir_fd is not None, it should be a file descriptor open to a directory,
 dir_fd may not be implemented on your platform.
   If it is unavailable, using it will raise a NotImplementedError.
 
-The mode argument is ignored on Windows.
+The mode argument is ignored on Windows. Where it is used, the current umask
+value is first masked out.
 [clinic start generated code]*/
 
 static PyObject *
 os_mkdir_impl(PyObject *module, path_t *path, int mode, int dir_fd)
-/*[clinic end generated code: output=a70446903abe821f input=e965f68377e9b1ce]*/
+/*[clinic end generated code: output=a70446903abe821f input=a61722e1576fab03]*/
 {
     int result;
 #ifdef HAVE_MKDIRAT
@@ -7096,8 +7097,13 @@ static PyObject *
 os_sched_yield_impl(PyObject *module)
 /*[clinic end generated code: output=902323500f222cac input=e54d6f98189391d4]*/
 {
-    if (sched_yield())
+    int result;
+    Py_BEGIN_ALLOW_THREADS
+    result = sched_yield();
+    Py_END_ALLOW_THREADS
+    if (result < 0) {
         return posix_error();
+    }
     Py_RETURN_NONE;
 }
 
diff --git a/Modules/pyexpat.c b/Modules/pyexpat.c
index 12319ee675..a971342222 100644
--- a/Modules/pyexpat.c
+++ b/Modules/pyexpat.c
@@ -775,7 +775,7 @@ readinst(char *buf, int buf_size, PyObject *meth)
     Py_ssize_t len;
     const char *ptr;
 
-    str = PyObject_CallFunction(meth, "n", buf_size);
+    str = PyObject_CallFunction(meth, "i", buf_size);
     if (str == NULL)
         goto error;
 
diff --git a/Modules/readline.c b/Modules/readline.c
index 1b616fc4f3..27b89de727 100644
--- a/Modules/readline.c
+++ b/Modules/readline.c
@@ -1258,9 +1258,9 @@ setup_readline(readlinestate *mod_state)
     rl_attempted_completion_function = flex_complete;
     /* Set Python word break characters */
     completer_word_break_characters =
-        rl_completer_word_break_characters =
         strdup(" \t\n`~!@#$%^&*()-=+[{]}\\|;:'\",<>/?");
         /* All nonalphanums except '.' */
+    rl_completer_word_break_characters = completer_word_break_characters;
 
     mod_state->begidx = PyLong_FromLong(0L);
     mod_state->endidx = PyLong_FromLong(0L);
diff --git a/Modules/signalmodule.c b/Modules/signalmodule.c
index e3b37f1793..0f30b4da03 100644
--- a/Modules/signalmodule.c
+++ b/Modules/signalmodule.c
@@ -1832,6 +1832,9 @@ _PyErr_CheckSignalsTstate(PyThreadState *tstate)
     _Py_atomic_store(&is_tripped, 0);
 
     _PyInterpreterFrame *frame = tstate->cframe->current_frame;
+    while (frame && _PyFrame_IsIncomplete(frame)) {
+        frame = frame->previous;
+    }
     signal_state_t *state = &signal_global_state;
     for (int i = 1; i < Py_NSIG; i++) {
         if (!_Py_atomic_load_relaxed(&Handlers[i].tripped)) {
diff --git a/Modules/syslogmodule.c b/Modules/syslogmodule.c
index c409fe968f..8416b6344c 100644
--- a/Modules/syslogmodule.c
+++ b/Modules/syslogmodule.c
@@ -207,9 +207,14 @@ syslog_syslog(PyObject * self, PyObject * args)
      */
     PyObject *ident = S_ident_o;
     Py_XINCREF(ident);
+#ifdef __APPLE__
+    // gh-98178: On macOS, libc syslog() is not thread-safe
+    syslog(priority, "%s", message);
+#else
     Py_BEGIN_ALLOW_THREADS;
     syslog(priority, "%s", message);
     Py_END_ALLOW_THREADS;
+#endif
     Py_XDECREF(ident);
     Py_RETURN_NONE;
 }
@@ -235,7 +240,7 @@ syslog_setlogmask(PyObject *self, PyObject *args)
 
     if (!PyArg_ParseTuple(args, "l;mask for priority", &maskpri))
         return NULL;
-    if (PySys_Audit("syslog.setlogmask", "(O)", args ? args : Py_None) < 0) {
+    if (PySys_Audit("syslog.setlogmask", "l", maskpri) < 0) {
         return NULL;
     }
     omaskpri = setlogmask(maskpri);
diff --git a/Objects/codeobject.c b/Objects/codeobject.c
index d7434ddefb..32938b52ab 100644
--- a/Objects/codeobject.c
+++ b/Objects/codeobject.c
@@ -636,12 +636,22 @@ PyCode_New(int argcount, int kwonlyargcount,
                                      exceptiontable);
 }
 
-static const char assert0[6] = {
+// NOTE: When modifying the construction of PyCode_NewEmpty, please also change
+// test.test_code.CodeLocationTest.test_code_new_empty to keep it in sync!
+
+static const uint8_t assert0[6] = {
     RESUME, 0,
     LOAD_ASSERTION_ERROR, 0,
     RAISE_VARARGS, 1
 };
 
+static const uint8_t linetable[2] = {
+    (1 << 7)  // New entry.
+    | (PY_CODE_LOCATION_INFO_NO_COLUMNS << 3)
+    | (3 - 1),  // Three code units.
+    0,  // Offset from co_firstlineno.
+};
+
 PyCodeObject *
 PyCode_NewEmpty(const char *filename, const char *funcname, int firstlineno)
 {
@@ -649,6 +659,7 @@ PyCode_NewEmpty(const char *filename, const char *funcname, int firstlineno)
     PyObject *filename_ob = NULL;
     PyObject *funcname_ob = NULL;
     PyObject *code_ob = NULL;
+    PyObject *linetable_ob = NULL;
     PyCodeObject *result = NULL;
 
     nulltuple = PyTuple_New(0);
@@ -663,10 +674,14 @@ PyCode_NewEmpty(const char *filename, const char *funcname, int firstlineno)
     if (filename_ob == NULL) {
         goto failed;
     }
-    code_ob = PyBytes_FromStringAndSize(assert0, 6);
+    code_ob = PyBytes_FromStringAndSize((const char *)assert0, 6);
     if (code_ob == NULL) {
         goto failed;
     }
+    linetable_ob = PyBytes_FromStringAndSize((const char *)linetable, 2);
+    if (linetable_ob == NULL) {
+        goto failed;
+    }
 
 #define emptystring (PyObject *)&_Py_SINGLETON(bytes_empty)
     struct _PyCodeConstructor con = {
@@ -675,7 +690,7 @@ PyCode_NewEmpty(const char *filename, const char *funcname, int firstlineno)
         .qualname = funcname_ob,
         .code = code_ob,
         .firstlineno = firstlineno,
-        .linetable = emptystring,
+        .linetable = linetable_ob,
         .consts = nulltuple,
         .names = nulltuple,
         .localsplusnames = nulltuple,
@@ -690,6 +705,7 @@ PyCode_NewEmpty(const char *filename, const char *funcname, int firstlineno)
     Py_XDECREF(funcname_ob);
     Py_XDECREF(filename_ob);
     Py_XDECREF(code_ob);
+    Py_XDECREF(linetable_ob);
     return result;
 }
 
diff --git a/Objects/descrobject.c b/Objects/descrobject.c
index c3c541bf3c..73ac14d2a8 100644
--- a/Objects/descrobject.c
+++ b/Objects/descrobject.c
@@ -775,7 +775,7 @@ PyTypeObject PyClassMethodDescr_Type = {
     0,                                          /* tp_weaklistoffset */
     0,                                          /* tp_iter */
     0,                                          /* tp_iternext */
-    descr_methods,                              /* tp_methods */
+    0,                                          /* tp_methods */
     descr_members,                              /* tp_members */
     method_getset,                              /* tp_getset */
     0,                                          /* tp_base */
diff --git a/Objects/exceptions.c b/Objects/exceptions.c
index 3c4df2facf..5ab4ac09e6 100644
--- a/Objects/exceptions.c
+++ b/Objects/exceptions.c
@@ -167,8 +167,14 @@ BaseException_setstate(PyObject *self, PyObject *state)
             return NULL;
         }
         while (PyDict_Next(state, &i, &d_key, &d_value)) {
-            if (PyObject_SetAttr(self, d_key, d_value) < 0)
+            Py_INCREF(d_key);
+            Py_INCREF(d_value);
+            int res = PyObject_SetAttr(self, d_key, d_value);
+            Py_DECREF(d_value);
+            Py_DECREF(d_key);
+            if (res < 0) {
                 return NULL;
+            }
         }
     }
     Py_RETURN_NONE;
@@ -3644,6 +3650,11 @@ _PyExc_InitState(PyInterpreterState *interp)
     ADD_ERRNO(InterruptedError, EINTR);
     ADD_ERRNO(PermissionError, EACCES);
     ADD_ERRNO(PermissionError, EPERM);
+#ifdef ENOTCAPABLE
+    // Extension for WASI capability-based security. Process lacks
+    // capability to access a resource.
+    ADD_ERRNO(PermissionError, ENOTCAPABLE);
+#endif
     ADD_ERRNO(ProcessLookupError, ESRCH);
     ADD_ERRNO(TimeoutError, ETIMEDOUT);
 
diff --git a/Objects/frameobject.c b/Objects/frameobject.c
index 1ddfec2fb0..f77f5ed393 100644
--- a/Objects/frameobject.c
+++ b/Objects/frameobject.c
@@ -590,6 +590,7 @@ first_line_not_before(int *lines, int len, int line)
 static PyFrameState
 _PyFrame_GetState(PyFrameObject *frame)
 {
+    assert(!_PyFrame_IsIncomplete(frame->f_frame));
     if (frame->f_frame->stacktop == 0) {
         return FRAME_CLEARED;
     }
@@ -1063,6 +1064,9 @@ PyFrame_New(PyThreadState *tstate, PyCodeObject *code,
     init_frame((_PyInterpreterFrame *)f->_f_frame_data, func, locals);
     f->f_frame = (_PyInterpreterFrame *)f->_f_frame_data;
     f->f_frame->owner = FRAME_OWNED_BY_FRAME_OBJECT;
+    // This frame needs to be "complete", so pretend that the first RESUME ran:
+    f->f_frame->prev_instr = _PyCode_CODE(code) + code->_co_firsttraceable;
+    assert(!_PyFrame_IsIncomplete(f->f_frame));
     Py_DECREF(func);
     _PyObject_GC_TRACK(f);
     return f;
@@ -1189,6 +1193,7 @@ _PyFrame_FastToLocalsWithError(_PyInterpreterFrame *frame) {
 int
 PyFrame_FastToLocalsWithError(PyFrameObject *f)
 {
+    assert(!_PyFrame_IsIncomplete(f->f_frame));
     if (f == NULL) {
         PyErr_BadInternalCall();
         return -1;
@@ -1204,7 +1209,7 @@ void
 PyFrame_FastToLocals(PyFrameObject *f)
 {
     int res;
-
+    assert(!_PyFrame_IsIncomplete(f->f_frame));
     assert(!PyErr_Occurred());
 
     res = PyFrame_FastToLocalsWithError(f);
@@ -1282,6 +1287,7 @@ _PyFrame_LocalsToFast(_PyInterpreterFrame *frame, int clear)
 void
 PyFrame_LocalsToFast(PyFrameObject *f, int clear)
 {
+    assert(!_PyFrame_IsIncomplete(f->f_frame));
     if (f && f->f_fast_as_locals && _PyFrame_GetState(f) != FRAME_CLEARED) {
         _PyFrame_LocalsToFast(f->f_frame, clear);
         f->f_fast_as_locals = 0;
@@ -1292,6 +1298,7 @@ PyFrame_LocalsToFast(PyFrameObject *f, int clear)
 int _PyFrame_IsEntryFrame(PyFrameObject *frame)
 {
     assert(frame != NULL);
+    assert(!_PyFrame_IsIncomplete(frame->f_frame));
     return frame->f_frame->is_entry;
 }
 
@@ -1300,6 +1307,7 @@ PyCodeObject *
 PyFrame_GetCode(PyFrameObject *frame)
 {
     assert(frame != NULL);
+    assert(!_PyFrame_IsIncomplete(frame->f_frame));
     PyCodeObject *code = frame->f_frame->f_code;
     assert(code != NULL);
     Py_INCREF(code);
@@ -1311,6 +1319,7 @@ PyFrameObject*
 PyFrame_GetBack(PyFrameObject *frame)
 {
     assert(frame != NULL);
+    assert(!_PyFrame_IsIncomplete(frame->f_frame));
     PyFrameObject *back = frame->f_back;
     if (back == NULL) {
         _PyInterpreterFrame *prev = frame->f_frame->previous;
@@ -1328,24 +1337,28 @@ PyFrame_GetBack(PyFrameObject *frame)
 PyObject*
 PyFrame_GetLocals(PyFrameObject *frame)
 {
+    assert(!_PyFrame_IsIncomplete(frame->f_frame));
     return frame_getlocals(frame, NULL);
 }
 
 PyObject*
 PyFrame_GetGlobals(PyFrameObject *frame)
 {
+    assert(!_PyFrame_IsIncomplete(frame->f_frame));
     return frame_getglobals(frame, NULL);
 }
 
 PyObject*
 PyFrame_GetBuiltins(PyFrameObject *frame)
 {
+    assert(!_PyFrame_IsIncomplete(frame->f_frame));
     return frame_getbuiltins(frame, NULL);
 }
 
 int
 PyFrame_GetLasti(PyFrameObject *frame)
 {
+    assert(!_PyFrame_IsIncomplete(frame->f_frame));
     int lasti = _PyInterpreterFrame_LASTI(frame->f_frame);
     if (lasti < 0) {
         return -1;
@@ -1356,6 +1369,7 @@ PyFrame_GetLasti(PyFrameObject *frame)
 PyObject *
 PyFrame_GetGenerator(PyFrameObject *frame)
 {
+    assert(!_PyFrame_IsIncomplete(frame->f_frame));
     if (frame->f_frame->owner != FRAME_OWNED_BY_GENERATOR) {
         return NULL;
     }
diff --git a/Objects/funcobject.c b/Objects/funcobject.c
index 32b4155c03..6307463474 100644
--- a/Objects/funcobject.c
+++ b/Objects/funcobject.c
@@ -300,7 +300,6 @@ func_get_annotation_dict(PyFunctionObject *op)
         }
         Py_SETREF(op->func_annotations, ann_dict);
     }
-    Py_INCREF(op->func_annotations);
     assert(PyDict_Check(op->func_annotations));
     return op->func_annotations;
 }
@@ -532,7 +531,11 @@ func_get_annotations(PyFunctionObject *op, void *Py_UNUSED(ignored))
         if (op->func_annotations == NULL)
             return NULL;
     }
-    return func_get_annotation_dict(op);
+    PyObject *d = func_get_annotation_dict(op);
+    if (d) {
+        Py_INCREF(d);
+    }
+    return d;
 }
 
 static int
diff --git a/Objects/genericaliasobject.c b/Objects/genericaliasobject.c
index 19f011fd3a..77acd1bc57 100644
--- a/Objects/genericaliasobject.c
+++ b/Objects/genericaliasobject.c
@@ -458,6 +458,13 @@ _Py_subs_parameters(PyObject *self, PyObject *args, PyObject *parameters, PyObje
     }
     for (Py_ssize_t iarg = 0, jarg = 0; iarg < nargs; iarg++) {
         PyObject *arg = PyTuple_GET_ITEM(args, iarg);
+        if (PyType_Check(arg)) {
+            Py_INCREF(arg);
+            PyTuple_SET_ITEM(newargs, jarg, arg);
+            jarg++;
+            continue;
+        }
+
         int unpack = _is_unpacked_typevartuple(arg);
         if (unpack < 0) {
             Py_DECREF(newargs);
diff --git a/Objects/obmalloc.c b/Objects/obmalloc.c
index ce5da5f1b7..fae9c8110f 100644
--- a/Objects/obmalloc.c
+++ b/Objects/obmalloc.c
@@ -2999,7 +2999,6 @@ _PyObject_DebugMallocStats(FILE *out)
      * will be living in full pools -- would be a shame to miss them.
      */
     for (i = 0; i < maxarenas; ++i) {
-        uint j;
         uintptr_t base = arenas[i].address;
 
         /* Skip arenas which are not allocated. */
@@ -3018,8 +3017,7 @@ _PyObject_DebugMallocStats(FILE *out)
 
         /* visit every pool in the arena */
         assert(base <= (uintptr_t) arenas[i].pool_address);
-        for (j = 0; base < (uintptr_t) arenas[i].pool_address;
-             ++j, base += POOL_SIZE) {
+        for (; base < (uintptr_t) arenas[i].pool_address; base += POOL_SIZE) {
             poolp p = (poolp)base;
             const uint sz = p->szidx;
             uint freeblocks;
diff --git a/Objects/unicodeobject.c b/Objects/unicodeobject.c
index a7bd961c64..a19eaadcfc 100644
--- a/Objects/unicodeobject.c
+++ b/Objects/unicodeobject.c
@@ -11134,8 +11134,8 @@ unicode_compare_eq(PyObject *str1, PyObject *str2)
 int
 _PyUnicode_Equal(PyObject *str1, PyObject *str2)
 {
-    assert(PyUnicode_CheckExact(str1));
-    assert(PyUnicode_CheckExact(str2));
+    assert(PyUnicode_Check(str1));
+    assert(PyUnicode_Check(str2));
     if (str1 == str2) {
         return 1;
     }
diff --git a/PC/clinic/_msi.c.h b/PC/clinic/_msi.c.h
index fd21142158..b717192b48 100644
--- a/PC/clinic/_msi.c.h
+++ b/PC/clinic/_msi.c.h
@@ -195,7 +195,7 @@ _msi_Record_SetString(msiobj *self, PyObject *const *args, Py_ssize_t nargs)
 {
     PyObject *return_value = NULL;
     int field;
-    const Py_UNICODE *value;
+    const Py_UNICODE *value = NULL;
 
     if (!_PyArg_CheckPositional("SetString", nargs, 2, 2)) {
         goto exit;
@@ -244,7 +244,7 @@ _msi_Record_SetStream(msiobj *self, PyObject *const *args, Py_ssize_t nargs)
 {
     PyObject *return_value = NULL;
     int field;
-    const Py_UNICODE *value;
+    const Py_UNICODE *value = NULL;
 
     if (!_PyArg_CheckPositional("SetStream", nargs, 2, 2)) {
         goto exit;
@@ -555,7 +555,7 @@ static PyObject *
 _msi_Database_OpenView(msiobj *self, PyObject *arg)
 {
     PyObject *return_value = NULL;
-    const Py_UNICODE *sql;
+    const Py_UNICODE *sql = NULL;
 
     if (!PyUnicode_Check(arg)) {
         _PyArg_BadArgument("OpenView", "argument", "str", arg);
@@ -650,7 +650,7 @@ static PyObject *
 _msi_OpenDatabase(PyObject *module, PyObject *const *args, Py_ssize_t nargs)
 {
     PyObject *return_value = NULL;
-    const Py_UNICODE *path;
+    const Py_UNICODE *path = NULL;
     int persist;
 
     if (!_PyArg_CheckPositional("OpenDatabase", nargs, 2, 2)) {
@@ -713,4 +713,4 @@ _msi_CreateRecord(PyObject *module, PyObject *arg)
 exit:
     return return_value;
 }
-/*[clinic end generated code: output=d7eb07e6bfcdc13f input=a9049054013a1b77]*/
+/*[clinic end generated code: output=276175d60fbfc956 input=a9049054013a1b77]*/
diff --git a/PC/clinic/winreg.c.h b/PC/clinic/winreg.c.h
index 2507e46e26..a413dec5dd 100644
--- a/PC/clinic/winreg.c.h
+++ b/PC/clinic/winreg.c.h
@@ -148,7 +148,7 @@ static PyObject *
 winreg_ConnectRegistry(PyObject *module, PyObject *const *args, Py_ssize_t nargs)
 {
     PyObject *return_value = NULL;
-    const Py_UNICODE *computer_name;
+    const Py_UNICODE *computer_name = NULL;
     HKEY key;
     HKEY _return_value;
 
@@ -220,7 +220,7 @@ winreg_CreateKey(PyObject *module, PyObject *const *args, Py_ssize_t nargs)
 {
     PyObject *return_value = NULL;
     HKEY key;
-    const Py_UNICODE *sub_key;
+    const Py_UNICODE *sub_key = NULL;
     HKEY _return_value;
 
     if (!_PyArg_CheckPositional("CreateKey", nargs, 2, 2)) {
@@ -301,7 +301,7 @@ winreg_CreateKeyEx(PyObject *module, PyObject *const *args, Py_ssize_t nargs, Py
     static const char * const _keywords[] = {"key", "sub_key", "reserved", "access", NULL};
     static _PyArg_Parser _parser = {"O&O&|ii:CreateKeyEx", _keywords, 0};
     HKEY key;
-    const Py_UNICODE *sub_key;
+    const Py_UNICODE *sub_key = NULL;
     int reserved = 0;
     REGSAM access = KEY_WRITE;
     HKEY _return_value;
@@ -354,7 +354,7 @@ winreg_DeleteKey(PyObject *module, PyObject *const *args, Py_ssize_t nargs)
 {
     PyObject *return_value = NULL;
     HKEY key;
-    const Py_UNICODE *sub_key;
+    const Py_UNICODE *sub_key = NULL;
 
     if (!_PyArg_CheckPositional("DeleteKey", nargs, 2, 2)) {
         goto exit;
@@ -428,7 +428,7 @@ winreg_DeleteKeyEx(PyObject *module, PyObject *const *args, Py_ssize_t nargs, Py
     static const char * const _keywords[] = {"key", "sub_key", "access", "reserved", NULL};
     static _PyArg_Parser _parser = {"O&O&|ii:DeleteKeyEx", _keywords, 0};
     HKEY key;
-    const Py_UNICODE *sub_key;
+    const Py_UNICODE *sub_key = NULL;
     REGSAM access = KEY_WOW64_64KEY;
     int reserved = 0;
 
@@ -469,7 +469,7 @@ winreg_DeleteValue(PyObject *module, PyObject *const *args, Py_ssize_t nargs)
 {
     PyObject *return_value = NULL;
     HKEY key;
-    const Py_UNICODE *value;
+    const Py_UNICODE *value = NULL;
 
     if (!_PyArg_CheckPositional("DeleteValue", nargs, 2, 2)) {
         goto exit;
@@ -619,7 +619,7 @@ static PyObject *
 winreg_ExpandEnvironmentStrings(PyObject *module, PyObject *arg)
 {
     PyObject *return_value = NULL;
-    const Py_UNICODE *string;
+    const Py_UNICODE *string = NULL;
 
     if (!PyUnicode_Check(arg)) {
         _PyArg_BadArgument("ExpandEnvironmentStrings", "argument", "str", arg);
@@ -724,8 +724,8 @@ winreg_LoadKey(PyObject *module, PyObject *const *args, Py_ssize_t nargs)
 {
     PyObject *return_value = NULL;
     HKEY key;
-    const Py_UNICODE *sub_key;
-    const Py_UNICODE *file_name;
+    const Py_UNICODE *sub_key = NULL;
+    const Py_UNICODE *file_name = NULL;
 
     if (!_PyArg_CheckPositional("LoadKey", nargs, 3, 3)) {
         goto exit;
@@ -805,7 +805,7 @@ winreg_OpenKey(PyObject *module, PyObject *const *args, Py_ssize_t nargs, PyObje
     static const char * const _keywords[] = {"key", "sub_key", "reserved", "access", NULL};
     static _PyArg_Parser _parser = {"O&O&|ii:OpenKey", _keywords, 0};
     HKEY key;
-    const Py_UNICODE *sub_key;
+    const Py_UNICODE *sub_key = NULL;
     int reserved = 0;
     REGSAM access = KEY_READ;
     HKEY _return_value;
@@ -862,7 +862,7 @@ winreg_OpenKeyEx(PyObject *module, PyObject *const *args, Py_ssize_t nargs, PyOb
     static const char * const _keywords[] = {"key", "sub_key", "reserved", "access", NULL};
     static _PyArg_Parser _parser = {"O&O&|ii:OpenKeyEx", _keywords, 0};
     HKEY key;
-    const Py_UNICODE *sub_key;
+    const Py_UNICODE *sub_key = NULL;
     int reserved = 0;
     REGSAM access = KEY_READ;
     HKEY _return_value;
@@ -953,7 +953,7 @@ winreg_QueryValue(PyObject *module, PyObject *const *args, Py_ssize_t nargs)
 {
     PyObject *return_value = NULL;
     HKEY key;
-    const Py_UNICODE *sub_key;
+    const Py_UNICODE *sub_key = NULL;
 
     if (!_PyArg_CheckPositional("QueryValue", nargs, 2, 2)) {
         goto exit;
@@ -1016,7 +1016,7 @@ winreg_QueryValueEx(PyObject *module, PyObject *const *args, Py_ssize_t nargs)
 {
     PyObject *return_value = NULL;
     HKEY key;
-    const Py_UNICODE *name;
+    const Py_UNICODE *name = NULL;
 
     if (!_PyArg_CheckPositional("QueryValueEx", nargs, 2, 2)) {
         goto exit;
@@ -1084,7 +1084,7 @@ winreg_SaveKey(PyObject *module, PyObject *const *args, Py_ssize_t nargs)
 {
     PyObject *return_value = NULL;
     HKEY key;
-    const Py_UNICODE *file_name;
+    const Py_UNICODE *file_name = NULL;
 
     if (!_PyArg_CheckPositional("SaveKey", nargs, 2, 2)) {
         goto exit;
@@ -1153,7 +1153,7 @@ winreg_SetValue(PyObject *module, PyObject *const *args, Py_ssize_t nargs)
 {
     PyObject *return_value = NULL;
     HKEY key;
-    const Py_UNICODE *sub_key;
+    const Py_UNICODE *sub_key = NULL;
     DWORD type;
     PyObject *value_obj;
 
@@ -1228,7 +1228,7 @@ winreg_SetValueEx(PyObject *module, PyObject *const *args, Py_ssize_t nargs)
 {
     PyObject *return_value = NULL;
     HKEY key;
-    const Py_UNICODE *value_name;
+    const Py_UNICODE *value_name = NULL;
     PyObject *reserved;
     DWORD type;
     PyObject *value;
@@ -1349,4 +1349,4 @@ winreg_QueryReflectionKey(PyObject *module, PyObject *arg)
 exit:
     return return_value;
 }
-/*[clinic end generated code: output=7ad1db69bc42cab4 input=a9049054013a1b77]*/
+/*[clinic end generated code: output=e83bdaabb4fa2167 input=a9049054013a1b77]*/
diff --git a/Parser/tokenizer.c b/Parser/tokenizer.c
index 8d9fbf5cf9..a5cfb659b4 100644
--- a/Parser/tokenizer.c
+++ b/Parser/tokenizer.c
@@ -1542,7 +1542,7 @@ tok_get(struct tok_state *tok, const char **p_start, const char **p_end)
     } while (c == ' ' || c == '\t' || c == '\014');
 
     /* Set start of current token */
-    tok->start = tok->cur - 1;
+    tok->start = tok->cur == NULL ? NULL : tok->cur - 1;
 
     /* Skip comment, unless it's a type comment */
     if (c == '#') {
diff --git a/Programs/_testembed.c b/Programs/_testembed.c
index d3d6588282..13eae178f9 100644
--- a/Programs/_testembed.c
+++ b/Programs/_testembed.c
@@ -22,7 +22,7 @@ char **main_argv;
 /*********************************************************
  * Embedded interpreter tests that need a custom exe
  *
- * Executed via 'EmbeddingTests' in Lib/test/test_capi.py
+ * Executed via Lib/test/test_embed.py
  *********************************************************/
 
 // Use to display the usage
@@ -73,7 +73,7 @@ static void init_from_config_clear(PyConfig *config)
 }
 
 
-static void _testembed_Py_Initialize(void)
+static void _testembed_Py_InitializeFromConfig(void)
 {
     PyConfig config;
     _PyConfig_InitCompatConfig(&config);
@@ -81,6 +81,12 @@ static void _testembed_Py_Initialize(void)
     init_from_config_clear(&config);
 }
 
+static void _testembed_Py_Initialize(void)
+{
+   Py_SetProgramName(PROGRAM_NAME);
+   Py_Initialize();
+}
+
 
 /*****************************************************
  * Test repeated initialisation and subinterpreters
@@ -110,7 +116,7 @@ static int test_repeated_init_and_subinterpreters(void)
 
     for (int i=1; i <= INIT_LOOPS; i++) {
         printf("--- Pass %d ---\n", i);
-        _testembed_Py_Initialize();
+        _testembed_Py_InitializeFromConfig();
         mainstate = PyThreadState_Get();
 
         PyEval_ReleaseThread(mainstate);
@@ -168,7 +174,7 @@ static int test_repeated_init_exec(void)
         fprintf(stderr, "--- Loop #%d ---\n", i);
         fflush(stderr);
 
-        _testembed_Py_Initialize();
+        _testembed_Py_InitializeFromConfig();
         int err = PyRun_SimpleString(code);
         Py_Finalize();
         if (err) {
@@ -178,6 +184,23 @@ static int test_repeated_init_exec(void)
     return 0;
 }
 
+/****************************************************************************
+ * Test the Py_Initialize(Ex) convenience/compatibility wrappers
+ ***************************************************************************/
+// This is here to help ensure there are no wrapper resource leaks (gh-96853)
+static int test_repeated_simple_init(void)
+{
+    for (int i=1; i <= INIT_LOOPS; i++) {
+        fprintf(stderr, "--- Loop #%d ---\n", i);
+        fflush(stderr);
+
+        _testembed_Py_Initialize();
+        Py_Finalize();
+        printf("Finalized\n"); // Give test_embed some output to check
+    }
+    return 0;
+}
+
 
 /*****************************************************
  * Test forcing a particular IO encoding
@@ -199,7 +222,7 @@ static void check_stdio_details(const char *encoding, const char * errors)
     fflush(stdout);
     /* Force the given IO encoding */
     Py_SetStandardStreamEncoding(encoding, errors);
-    _testembed_Py_Initialize();
+    _testembed_Py_InitializeFromConfig();
     PyRun_SimpleString(
         "import sys;"
         "print('stdin: {0.encoding}:{0.errors}'.format(sys.stdin));"
@@ -308,7 +331,7 @@ static int test_pre_initialization_sys_options(void)
     dynamic_xoption = NULL;
 
     _Py_EMBED_PREINIT_CHECK("Initializing interpreter\n");
-    _testembed_Py_Initialize();
+    _testembed_Py_InitializeFromConfig();
     _Py_EMBED_PREINIT_CHECK("Check sys module contents\n");
     PyRun_SimpleString("import sys; "
                        "print('sys.warnoptions:', sys.warnoptions); "
@@ -352,7 +375,7 @@ static int test_bpo20891(void)
         return 1;
     }
 
-    _testembed_Py_Initialize();
+    _testembed_Py_InitializeFromConfig();
 
     unsigned long thrd = PyThread_start_new_thread(bpo20891_thread, &lock);
     if (thrd == PYTHREAD_INVALID_THREAD_ID) {
@@ -375,7 +398,7 @@ static int test_bpo20891(void)
 
 static int test_initialize_twice(void)
 {
-    _testembed_Py_Initialize();
+    _testembed_Py_InitializeFromConfig();
 
     /* bpo-33932: Calling Py_Initialize() twice should do nothing
      * (and not crash!). */
@@ -393,7 +416,7 @@ static int test_initialize_pymain(void)
                         L"print(f'Py_Main() after Py_Initialize: "
                         L"sys.argv={sys.argv}')"),
                        L"arg2"};
-    _testembed_Py_Initialize();
+    _testembed_Py_InitializeFromConfig();
 
     /* bpo-34008: Calling Py_Main() after Py_Initialize() must not crash */
     Py_Main(Py_ARRAY_LENGTH(argv), argv);
@@ -416,7 +439,7 @@ dump_config(void)
 
 static int test_init_initialize_config(void)
 {
-    _testembed_Py_Initialize();
+    _testembed_Py_InitializeFromConfig();
     dump_config();
     Py_Finalize();
     return 0;
@@ -765,7 +788,7 @@ static int test_init_compat_env(void)
     /* Test initialization from environment variables */
     Py_IgnoreEnvironmentFlag = 0;
     set_all_env_vars();
-    _testembed_Py_Initialize();
+    _testembed_Py_InitializeFromConfig();
     dump_config();
     Py_Finalize();
     return 0;
@@ -801,7 +824,7 @@ static int test_init_env_dev_mode(void)
     /* Test initialization from environment variables */
     Py_IgnoreEnvironmentFlag = 0;
     set_all_env_vars_dev_mode();
-    _testembed_Py_Initialize();
+    _testembed_Py_InitializeFromConfig();
     dump_config();
     Py_Finalize();
     return 0;
@@ -814,7 +837,7 @@ static int test_init_env_dev_mode_alloc(void)
     Py_IgnoreEnvironmentFlag = 0;
     set_all_env_vars_dev_mode();
     putenv("PYTHONMALLOC=malloc");
-    _testembed_Py_Initialize();
+    _testembed_Py_InitializeFromConfig();
     dump_config();
     Py_Finalize();
     return 0;
@@ -1154,7 +1177,7 @@ static int test_open_code_hook(void)
     }
 
     Py_IgnoreEnvironmentFlag = 0;
-    _testembed_Py_Initialize();
+    _testembed_Py_InitializeFromConfig();
     result = 0;
 
     PyObject *r = PyFile_OpenCode("$$test-filename");
@@ -1218,7 +1241,7 @@ static int _test_audit(Py_ssize_t setValue)
 
     Py_IgnoreEnvironmentFlag = 0;
     PySys_AddAuditHook(_audit_hook, &sawSet);
-    _testembed_Py_Initialize();
+    _testembed_Py_InitializeFromConfig();
 
     if (PySys_Audit("_testembed.raise", NULL) == 0) {
         printf("No error raised");
@@ -1274,7 +1297,7 @@ static int test_audit_subinterpreter(void)
 {
     Py_IgnoreEnvironmentFlag = 0;
     PySys_AddAuditHook(_audit_subinterpreter_hook, NULL);
-    _testembed_Py_Initialize();
+    _testembed_Py_InitializeFromConfig();
 
     Py_NewInterpreter();
     Py_NewInterpreter();
@@ -1581,7 +1604,7 @@ static int test_init_is_python_build(void)
     config._is_python_build = INT_MAX;
     env = getenv("NEGATIVE_ISPYTHONBUILD");
     if (env && strcmp(env, "0") != 0) {
-        config._is_python_build++;
+        config._is_python_build = INT_MIN;
     }
     init_from_config_clear(&config);
     Py_Finalize();
@@ -1869,13 +1892,13 @@ static int test_unicode_id_init(void)
     _Py_IDENTIFIER(test_unicode_id_init);
 
     // Initialize Python once without using the identifier
-    _testembed_Py_Initialize();
+    _testembed_Py_InitializeFromConfig();
     Py_Finalize();
 
     // Now initialize Python multiple times and use the identifier.
     // The first _PyUnicode_FromId() call initializes the identifier index.
     for (int i=0; i<3; i++) {
-        _testembed_Py_Initialize();
+        _testembed_Py_InitializeFromConfig();
 
         PyObject *str1, *str2;
 
@@ -2007,7 +2030,7 @@ unwrap_allocator(PyMemAllocatorEx *allocator)
 static int
 test_get_incomplete_frame(void)
 {
-    _testembed_Py_Initialize();
+    _testembed_Py_InitializeFromConfig();
     PyMemAllocatorEx allocator;
     wrap_allocator(&allocator);
     // Force an allocation with an incomplete (generator) frame:
@@ -2039,6 +2062,7 @@ struct TestCase
 static struct TestCase TestCases[] = {
     // Python initialization
     {"test_repeated_init_exec", test_repeated_init_exec},
+    {"test_repeated_simple_init", test_repeated_simple_init},
     {"test_forced_io_encoding", test_forced_io_encoding},
     {"test_repeated_init_and_subinterpreters", test_repeated_init_and_subinterpreters},
     {"test_repeated_init_and_inittab", test_repeated_init_and_inittab},
diff --git a/Python/bltinmodule.c b/Python/bltinmodule.c
index 072bf75bf8..94a7819c25 100644
--- a/Python/bltinmodule.c
+++ b/Python/bltinmodule.c
@@ -260,8 +260,8 @@ importlib.import_module() to programmatically import a module.
 
 The globals argument is only used to determine the context;
 they are not modified.  The locals argument is unused.  The fromlist
-should be a list of names to emulate ``from name import ...'', or an
-empty list to emulate ``import name''.
+should be a list of names to emulate ``from name import ...``, or an
+empty list to emulate ``import name``.
 When importing a module from a package, note that __import__('A.B', ...)
 returns package A when fromlist is empty, but its submodule B when
 fromlist is not empty.  The level argument is used to determine whether to
@@ -272,7 +272,7 @@ is the number of parent directories to search relative to the current module.
 static PyObject *
 builtin___import___impl(PyObject *module, PyObject *name, PyObject *globals,
                         PyObject *locals, PyObject *fromlist, int level)
-/*[clinic end generated code: output=4febeda88a0cd245 input=35e9a6460412430f]*/
+/*[clinic end generated code: output=4febeda88a0cd245 input=73f4b960ea5b9dd6]*/
 {
     return PyImport_ImportModuleLevelObject(name, globals, locals,
                                             fromlist, level);
@@ -1509,13 +1509,13 @@ setattr as builtin_setattr
 
 Sets the named attribute on the given object to the specified value.
 
-setattr(x, 'y', v) is equivalent to ``x.y = v''
+setattr(x, 'y', v) is equivalent to ``x.y = v``
 [clinic start generated code]*/
 
 static PyObject *
 builtin_setattr_impl(PyObject *module, PyObject *obj, PyObject *name,
                      PyObject *value)
-/*[clinic end generated code: output=dc2ce1d1add9acb4 input=bd2b7ca6875a1899]*/
+/*[clinic end generated code: output=dc2ce1d1add9acb4 input=5e26417f2e8598d4]*/
 {
     if (PyObject_SetAttr(obj, name, value) != 0)
         return NULL;
@@ -1532,12 +1532,12 @@ delattr as builtin_delattr
 
 Deletes the named attribute from the given object.
 
-delattr(x, 'y') is equivalent to ``del x.y''
+delattr(x, 'y') is equivalent to ``del x.y``
 [clinic start generated code]*/
 
 static PyObject *
 builtin_delattr_impl(PyObject *module, PyObject *obj, PyObject *name)
-/*[clinic end generated code: output=85134bc58dff79fa input=db16685d6b4b9410]*/
+/*[clinic end generated code: output=85134bc58dff79fa input=164865623abe7216]*/
 {
     if (PyObject_SetAttr(obj, name, (PyObject *)NULL) != 0)
         return NULL;
diff --git a/Python/ceval.c b/Python/ceval.c
index 478ecd8e92..c0d9c68de0 100644
--- a/Python/ceval.c
+++ b/Python/ceval.c
@@ -3582,7 +3582,6 @@ _PyEval_EvalFrameDefault(PyThreadState *tstate, _PyInterpreterFrame *frame, int
             DISPATCH();
         }
 
-            DISPATCH();
         TARGET(STORE_ATTR_ADAPTIVE) {
             assert(cframe.use_tracing == 0);
             _PyAttrCache *cache = (_PyAttrCache *)next_instr;
@@ -4794,7 +4793,7 @@ _PyEval_EvalFrameDefault(PyThreadState *tstate, _PyInterpreterFrame *frame, int
 
         TARGET(PRECALL_ADAPTIVE) {
             _PyPrecallCache *cache = (_PyPrecallCache *)next_instr;
-            if (cache->counter == 0) {
+            if (ADAPTIVE_COUNTER_IS_ZERO(cache)) {
                 next_instr--;
                 int is_meth = is_method(stack_pointer, oparg);
                 int nargs = oparg + is_meth;
@@ -4808,7 +4807,7 @@ _PyEval_EvalFrameDefault(PyThreadState *tstate, _PyInterpreterFrame *frame, int
             }
             else {
                 STAT_INC(PRECALL, deferred);
-                cache->counter--;
+                DECREMENT_ADAPTIVE_COUNTER(cache);
                 JUMP_TO_INSTRUCTION(PRECALL);
             }
         }
@@ -5747,9 +5746,11 @@ _PyEval_EvalFrameDefault(PyThreadState *tstate, _PyInterpreterFrame *frame, int
 #endif
 
         /* Log traceback info. */
-        PyFrameObject *f = _PyFrame_GetFrameObject(frame);
-        if (f != NULL) {
-            PyTraceBack_Here(f);
+        if (!_PyFrame_IsIncomplete(frame)) {
+            PyFrameObject *f = _PyFrame_GetFrameObject(frame);
+            if (f != NULL) {
+                PyTraceBack_Here(f);
+            }
         }
 
         if (tstate->c_tracefunc != NULL) {
@@ -6931,7 +6932,7 @@ maybe_call_line_trace(Py_tracefunc func, PyObject *obj,
         }
     }
     /* Always emit an opcode event if we're tracing all opcodes. */
-    if (f->f_trace_opcodes) {
+    if (f->f_trace_opcodes && result == 0) {
         result = call_trace(func, obj, tstate, frame, PyTrace_OPCODE, Py_None);
     }
     return result;
diff --git a/Python/ceval_gil.h b/Python/ceval_gil.h
index 1b2dc7f8e1..476ed7f1a2 100644
--- a/Python/ceval_gil.h
+++ b/Python/ceval_gil.h
@@ -133,12 +133,14 @@ static void destroy_gil(struct _gil_runtime_state *gil)
     _Py_ANNOTATE_RWLOCK_DESTROY(&gil->locked);
 }
 
+#ifdef HAVE_FORK
 static void recreate_gil(struct _gil_runtime_state *gil)
 {
     _Py_ANNOTATE_RWLOCK_DESTROY(&gil->locked);
     /* XXX should we destroy the old OS resources here? */
     create_gil(gil);
 }
+#endif
 
 static void
 drop_gil(struct _ceval_runtime_state *ceval, struct _ceval_state *ceval2,
@@ -239,6 +241,7 @@ take_gil(PyThreadState *tstate)
         goto _ready;
     }
 
+    int drop_requested = 0;
     while (_Py_atomic_load_relaxed(&gil->locked)) {
         unsigned long saved_switchnum = gil->switch_number;
 
@@ -254,11 +257,21 @@ take_gil(PyThreadState *tstate)
         {
             if (tstate_must_exit(tstate)) {
                 MUTEX_UNLOCK(gil->mutex);
+                // gh-96387: If the loop requested a drop request in a previous
+                // iteration, reset the request. Otherwise, drop_gil() can
+                // block forever waiting for the thread which exited. Drop
+                // requests made by other threads are also reset: these threads
+                // may have to request again a drop request (iterate one more
+                // time).
+                if (drop_requested) {
+                    RESET_GIL_DROP_REQUEST(interp);
+                }
                 PyThread_exit_thread();
             }
             assert(is_tstate_valid(tstate));
 
             SET_GIL_DROP_REQUEST(interp);
+            drop_requested = 1;
         }
     }
 
diff --git a/Python/clinic/bltinmodule.c.h b/Python/clinic/bltinmodule.c.h
index 48f6509116..5d9a16a7b6 100644
--- a/Python/clinic/bltinmodule.c.h
+++ b/Python/clinic/bltinmodule.c.h
@@ -15,8 +15,8 @@ PyDoc_STRVAR(builtin___import____doc__,
 "\n"
 "The globals argument is only used to determine the context;\n"
 "they are not modified.  The locals argument is unused.  The fromlist\n"
-"should be a list of names to emulate ``from name import ...\'\', or an\n"
-"empty list to emulate ``import name\'\'.\n"
+"should be a list of names to emulate ``from name import ...``, or an\n"
+"empty list to emulate ``import name``.\n"
 "When importing a module from a package, note that __import__(\'A.B\', ...)\n"
 "returns package A when fromlist is empty, but its submodule B when\n"
 "fromlist is not empty.  The level argument is used to determine whether to\n"
@@ -539,7 +539,7 @@ PyDoc_STRVAR(builtin_setattr__doc__,
 "\n"
 "Sets the named attribute on the given object to the specified value.\n"
 "\n"
-"setattr(x, \'y\', v) is equivalent to ``x.y = v\'\'");
+"setattr(x, \'y\', v) is equivalent to ``x.y = v``");
 
 #define BUILTIN_SETATTR_METHODDEF    \
     {"setattr", _PyCFunction_CAST(builtin_setattr), METH_FASTCALL, builtin_setattr__doc__},
@@ -574,7 +574,7 @@ PyDoc_STRVAR(builtin_delattr__doc__,
 "\n"
 "Deletes the named attribute from the given object.\n"
 "\n"
-"delattr(x, \'y\') is equivalent to ``del x.y\'\'");
+"delattr(x, \'y\') is equivalent to ``del x.y``");
 
 #define BUILTIN_DELATTR_METHODDEF    \
     {"delattr", _PyCFunction_CAST(builtin_delattr), METH_FASTCALL, builtin_delattr__doc__},
@@ -1045,4 +1045,4 @@ builtin_issubclass(PyObject *module, PyObject *const *args, Py_ssize_t nargs)
 exit:
     return return_value;
 }
-/*[clinic end generated code: output=a2c5c53e8aead7c3 input=a9049054013a1b77]*/
+/*[clinic end generated code: output=cc844ea007c1241f input=a9049054013a1b77]*/
diff --git a/Python/compile.c b/Python/compile.c
index 32fd58e6c4..f4555b35ab 100644
--- a/Python/compile.c
+++ b/Python/compile.c
@@ -2930,6 +2930,7 @@ compiler_jump_if(struct compiler *c, expr_ty e, basicblock *next, int cond)
         return 1;
     }
     case Compare_kind: {
+        SET_LOC(c, e);
         Py_ssize_t i, n = asdl_seq_LEN(e->v.Compare.ops) - 1;
         if (n > 0) {
             if (!check_compare(c, e)) {
diff --git a/Python/frame.c b/Python/frame.c
index 9d5cab990c..d8f2f801f3 100644
--- a/Python/frame.c
+++ b/Python/frame.c
@@ -85,6 +85,13 @@ take_ownership(PyFrameObject *f, _PyInterpreterFrame *frame)
     frame = (_PyInterpreterFrame *)f->_f_frame_data;
     f->f_frame = frame;
     frame->owner = FRAME_OWNED_BY_FRAME_OBJECT;
+    if (_PyFrame_IsIncomplete(frame)) {
+        // This may be a newly-created generator or coroutine frame. Since it's
+        // dead anyways, just pretend that the first RESUME ran:
+        PyCodeObject *code = frame->f_code;
+        frame->prev_instr = _PyCode_CODE(code) + code->_co_firsttraceable;
+    }
+    assert(!_PyFrame_IsIncomplete(frame));
     assert(f->f_back == NULL);
     _PyInterpreterFrame *prev = frame->previous;
     while (prev && _PyFrame_IsIncomplete(prev)) {
diff --git a/Python/marshal.c b/Python/marshal.c
index 90a4405091..2690f55766 100644
--- a/Python/marshal.c
+++ b/Python/marshal.c
@@ -34,6 +34,8 @@ module marshal
  */
 #if defined(MS_WINDOWS)
 #define MAX_MARSHAL_STACK_DEPTH 1000
+#elif defined(__wasi__)
+#define MAX_MARSHAL_STACK_DEPTH 1500
 #else
 #define MAX_MARSHAL_STACK_DEPTH 2000
 #endif
diff --git a/Python/mysnprintf.c b/Python/mysnprintf.c
index cd69198011..2a505d14f8 100644
--- a/Python/mysnprintf.c
+++ b/Python/mysnprintf.c
@@ -9,6 +9,7 @@
    would have been written had the buffer not been too small, and to set
    the last byte of the buffer to \0.  At least MS _vsnprintf returns a
    negative value instead, and fills the entire buffer with non-\0 data.
+   Unlike C99, our wrappers do not support passing a null buffer.
 
    The wrappers ensure that str[size-1] is always \0 upon return.
 
diff --git a/Python/pylifecycle.c b/Python/pylifecycle.c
index 960a38aebe..0363e2e1dc 100644
--- a/Python/pylifecycle.c
+++ b/Python/pylifecycle.c
@@ -1289,6 +1289,7 @@ Py_InitializeEx(int install_sigs)
     config.install_signal_handlers = install_sigs;
 
     status = Py_InitializeFromConfig(&config);
+    PyConfig_Clear(&config);
     if (_PyStatus_EXCEPTION(status)) {
         Py_ExitStatusException(status);
     }
diff --git a/Python/pystate.c b/Python/pystate.c
index 12ebbe33cb..425065322e 100644
--- a/Python/pystate.c
+++ b/Python/pystate.c
@@ -1391,6 +1391,9 @@ _PyThread_CurrentFrames(void)
         PyThreadState *t;
         for (t = i->threads.head; t != NULL; t = t->next) {
             _PyInterpreterFrame *frame = t->cframe->current_frame;
+            while (frame && _PyFrame_IsIncomplete(frame)) {
+                frame = frame->previous;
+            }
             if (frame == NULL) {
                 continue;
             }
diff --git a/Python/sysmodule.c b/Python/sysmodule.c
index dca97f21a2..6f703e3005 100644
--- a/Python/sysmodule.c
+++ b/Python/sysmodule.c
@@ -2775,14 +2775,18 @@ EM_JS(char *, _Py_emscripten_runtime, (void), {
     if (typeof navigator == 'object') {
         info = navigator.userAgent;
     } else if (typeof process == 'object') {
-        info = "Node.js ".concat(process.version)
+        info = "Node.js ".concat(process.version);
     } else {
-        info = "UNKNOWN"
+        info = "UNKNOWN";
     }
     var len = lengthBytesUTF8(info) + 1;
     var res = _malloc(len);
-    stringToUTF8(info, res, len);
+    if (res) stringToUTF8(info, res, len);
+#if __wasm64__
+    return BigInt(res);
+#else
     return res;
+#endif
 });
 
 static PyObject *
diff --git a/README.rst b/README.rst
index 8b5b52a3bd..3350419720 100644
--- a/README.rst
+++ b/README.rst
@@ -65,7 +65,7 @@ Building a complete Python installation requires the use of various
 additional third-party libraries, depending on your build platform and
 configure options.  Not all standard library modules are buildable or
 useable on all platforms.  Refer to the
-`Install dependencies <https://devguide.python.org/setup/#install-dependencies>`_
+`Install dependencies <https://devguide.python.org/getting-started/setup-building.html#build-dependencies>`_
 section of the `Developer Guide`_ for current detailed information on
 dependencies for various Linux distributions and macOS.
 
@@ -135,7 +135,7 @@ What's New
 We have a comprehensive overview of the changes in the `What's New in Python
 3.11 <https://docs.python.org/3.11/whatsnew/3.11.html>`_ document.  For a more
 detailed change log, read `Misc/NEWS
-<https://github.com/python/cpython/blob/main/Misc/NEWS.d>`_, but a full
+<https://github.com/python/cpython/tree/main/Misc/NEWS.d>`_, but a full
 accounting of changes can only be gleaned from the `commit history
 <https://github.com/python/cpython/commits/main>`_.
 
@@ -189,7 +189,7 @@ your environment, you can `file a bug report
 <https://github.com/python/cpython/issues>`_ and include relevant output from
 that command to show the issue.
 
-See `Running & Writing Tests <https://devguide.python.org/runtests/>`_
+See `Running & Writing Tests <https://devguide.python.org/testing/run-write-tests.html>`_
 for more on running tests.
 
 Installing multiple versions
diff --git a/Tools/clinic/clinic.py b/Tools/clinic/clinic.py
index cd0446dc4f..97d8d0a941 100755
--- a/Tools/clinic/clinic.py
+++ b/Tools/clinic/clinic.py
@@ -3522,6 +3522,7 @@ def converter_init(self, *, accept={str}, zeroes=False):
                 self.converter = '_PyUnicode_WideCharString_Opt_Converter'
             else:
                 fail("Py_UNICODE_converter: illegal 'accept' argument " + repr(accept))
+        self.c_default = "NULL"
 
     def cleanup(self):
         if not self.length:
diff --git a/Tools/i18n/pygettext.py b/Tools/i18n/pygettext.py
index 6f889adffe..7ada79105d 100755
--- a/Tools/i18n/pygettext.py
+++ b/Tools/i18n/pygettext.py
@@ -335,9 +335,10 @@ def __waiting(self, ttype, tstring, lineno):
                 if ttype == tokenize.STRING and is_literal_string(tstring):
                     self.__addentry(safe_eval(tstring), lineno, isdocstring=1)
                     self.__freshmodule = 0
-                elif ttype not in (tokenize.COMMENT, tokenize.NL):
-                    self.__freshmodule = 0
-                return
+                    return
+                if ttype in (tokenize.COMMENT, tokenize.NL, tokenize.ENCODING):
+                    return
+                self.__freshmodule = 0
             # class or func/method docstring?
             if ttype == tokenize.NAME and tstring in ('class', 'def'):
                 self.__state = self.__suiteseen
diff --git a/Tools/scripts/get-remote-certificate.py b/Tools/scripts/get-remote-certificate.py
index 38901286e1..68272fca83 100755
--- a/Tools/scripts/get-remote-certificate.py
+++ b/Tools/scripts/get-remote-certificate.py
@@ -15,8 +15,8 @@
 def fetch_server_certificate (host, port):
 
     def subproc(cmd):
-        from subprocess import Popen, PIPE, STDOUT
-        proc = Popen(cmd, stdout=PIPE, stderr=STDOUT, shell=True)
+        from subprocess import Popen, PIPE, STDOUT, DEVNULL
+        proc = Popen(cmd, stdout=PIPE, stderr=STDOUT, stdin=DEVNULL)
         status = proc.wait()
         output = proc.stdout.read()
         return status, output
@@ -33,8 +33,8 @@ def strip_to_x509_cert(certfile_contents, outfile=None):
                 fp.write(m.group(1) + b"\n")
             try:
                 tn2 = (outfile or tempfile.mktemp())
-                status, output = subproc(r'openssl x509 -in "%s" -out "%s"' %
-                                         (tn, tn2))
+                cmd = ['openssl', 'x509', '-in', tn, '-out', tn2]
+                status, output = subproc(cmd)
                 if status != 0:
                     raise RuntimeError('OpenSSL x509 failed with status %s and '
                                        'output: %r' % (status, output))
@@ -45,20 +45,9 @@ def strip_to_x509_cert(certfile_contents, outfile=None):
             finally:
                 os.unlink(tn)
 
-    if sys.platform.startswith("win"):
-        tfile = tempfile.mktemp()
-        with open(tfile, "w") as fp:
-            fp.write("quit\n")
-        try:
-            status, output = subproc(
-                'openssl s_client -connect "%s:%s" -showcerts < "%s"' %
-                (host, port, tfile))
-        finally:
-            os.unlink(tfile)
-    else:
-        status, output = subproc(
-            'openssl s_client -connect "%s:%s" -showcerts < /dev/null' %
-            (host, port))
+    cmd = ['openssl', 's_client', '-connect', '%s:%s' % (host, port), '-showcerts']
+    status, output = subproc(cmd)
+
     if status != 0:
         raise RuntimeError('OpenSSL connect failed with status %s and '
                            'output: %r' % (status, output))
diff --git a/Tools/wasm/README.md b/Tools/wasm/README.md
index 6496a29e6f..fe9a1dc99b 100644
--- a/Tools/wasm/README.md
+++ b/Tools/wasm/README.md
@@ -1,11 +1,16 @@
 # Python WebAssembly (WASM) build
 
-**WARNING: WASM support is highly experimental! Lots of features are not working yet.**
+**WARNING: WASM support is work-in-progress! Lots of features are not working yet.**
 
 This directory contains configuration and helpers to facilitate cross
-compilation of CPython to WebAssembly (WASM). For now we support
-*wasm32-emscripten* builds for modern browser and for *Node.js*. WASI
-(*wasm32-wasi*) is work-in-progress
+compilation of CPython to WebAssembly (WASM). Python supports Emscripten
+(*wasm32-emscripten*) and WASI (*wasm32-wasi*) targets. Emscripten builds
+run in modern browsers and JavaScript runtimes like *Node.js*. WASI builds
+use WASM runtimes such as *wasmtime*.
+
+Users and developers are encouraged to use the script
+`Tools/wasm/wasm_build.py`. The tool automates the build process and provides
+assistance with installation of SDKs.
 
 ## wasm32-emscripten build
 
@@ -17,7 +22,7 @@ ## wasm32-emscripten build
 
 Cross compiling to the wasm32-emscripten platform needs the
 [Emscripten](https://emscripten.org/) SDK and a build Python interpreter.
-Emscripten 3.1.8 or newer are recommended. All commands below are relative
+Emscripten 3.1.19 or newer are recommended. All commands below are relative
 to a repository checkout.
 
 Christian Heimes maintains a container image with Emscripten SDK, Python
@@ -35,7 +40,13 @@ # other
 
 ### Compile a build Python interpreter
 
-From within the container, run the following commands:
+From within the container, run the following command:
+
+```shell
+./Tools/wasm/wasm_build.py build
+```
+
+The command is roughly equivalent to:
 
 ```shell
 mkdir -p builddir/build
@@ -45,13 +56,13 @@ ### Compile a build Python interpreter
 popd
 ```
 
-### Fetch and build additional emscripten ports
+### Cross-compile to wasm32-emscripten for browser
 
 ```shell
-embuilder build zlib bzip2
+./Tools/wasm/wasm_build.py emscripten-browser
 ```
 
-### Cross compile to wasm32-emscripten for browser
+The command is roughly equivalent to:
 
 ```shell
 mkdir -p builddir/emscripten-browser
@@ -85,14 +96,21 @@ ### Cross compile to wasm32-emscripten for browser
 ### Cross compile to wasm32-emscripten for node
 
 ```shell
-mkdir -p builddir/emscripten-node
-pushd builddir/emscripten-node
+./Tools/wasm/wasm_build.py emscripten-browser-dl
+```
+
+The command is roughly equivalent to:
+
+```shell
+mkdir -p builddir/emscripten-node-dl
+pushd builddir/emscripten-node-dl
 
 CONFIG_SITE=../../Tools/wasm/config.site-wasm32-emscripten \
   emconfigure ../../configure -C \
     --host=wasm32-unknown-emscripten \
     --build=$(../../config.guess) \
     --with-emscripten-target=node \
+    --enable-wasm-dynamic-linking \
     --with-build-python=$(pwd)/../build/python
 
 emmake make -j$(nproc)
@@ -100,7 +118,7 @@ ### Cross compile to wasm32-emscripten for node
 ```
 
 ```shell
-node --experimental-wasm-threads --experimental-wasm-bulk-memory --experimental-wasm-bigint builddir/emscripten-node/python.js
+node --experimental-wasm-threads --experimental-wasm-bulk-memory --experimental-wasm-bigint builddir/emscripten-node-dl/python.js
 ```
 
 (``--experimental-wasm-bigint`` is not needed with recent NodeJS versions)
@@ -199,6 +217,15 @@ ## wasm32-emscripten in node
 - Node RawFS allows direct access to the host file system without need to
   perform ``FS.mount()`` call.
 
+## wasm64-emscripten
+
+- wasm64 requires recent NodeJS and ``--experimental-wasm-memory64``.
+- ``EM_JS`` functions must return ``BigInt()``.
+- ``Py_BuildValue()`` format strings must match size of types. Confusing 32
+  and 64 bits types leads to memory corruption, see
+  [gh-95876](https://github.com/python/cpython/issues/95876) and
+  [gh-95878](https://github.com/python/cpython/issues/95878).
+
 # Hosting Python WASM builds
 
 The simple REPL terminal uses SharedArrayBuffer. For security reasons
@@ -234,6 +261,12 @@ ## Cross-compile to wasm32-wasi
 ``pkg-config`` overrides. The script assumes that WASI-SDK is installed in
 ``/opt/wasi-sdk`` or ``$WASI_SDK_PATH``.
 
+```shell
+./Tools/wasm/wasm_build.py wasi
+```
+
+The command is roughly equivalent to:
+
 ```shell
 mkdir -p builddir/wasi
 pushd builddir/wasi
@@ -308,26 +341,46 @@ ## Python code
 ```python
 >>> import os, sys
 >>> os.uname()
-posix.uname_result(sysname='Emscripten', nodename='emscripten', release='1.0', version='#1', machine='wasm32')
+posix.uname_result(
+    sysname='Emscripten',
+    nodename='emscripten',
+    release='3.1.19',
+    version='#1',
+    machine='wasm32'
+)
 >>> os.name
 'posix'
 >>> sys.platform
 'emscripten'
 >>> sys._emscripten_info
 sys._emscripten_info(
-    emscripten_version=(3, 1, 8),
-    runtime='Mozilla/5.0 (X11; Fedora; Linux x86_64; rv:99.0) Gecko/20100101 Firefox/99.0',
+    emscripten_version=(3, 1, 10),
+    runtime='Mozilla/5.0 (X11; Linux x86_64; rv:104.0) Gecko/20100101 Firefox/104.0',
     pthreads=False,
     shared_memory=False
 )
+```
+
+```python
 >>> sys._emscripten_info
-sys._emscripten_info(emscripten_version=(3, 1, 8), runtime='Node.js v14.18.2', pthreads=True, shared_memory=True)
+sys._emscripten_info(
+    emscripten_version=(3, 1, 19),
+    runtime='Node.js v14.18.2',
+    pthreads=True,
+    shared_memory=True
+)
 ```
 
 ```python
 >>> import os, sys
 >>> os.uname()
-posix.uname_result(sysname='wasi', nodename='(none)', release='0.0.0', version='0.0.0', machine='wasm32')
+posix.uname_result(
+    sysname='wasi',
+    nodename='(none)',
+    release='0.0.0',
+    version='0.0.0',
+    machine='wasm32'
+)
 >>> os.name
 'posix'
 >>> sys.platform
@@ -418,7 +471,8 @@ ### Install [WASI-SDK](https://github.com/WebAssembly/wasi-sdk)
 
 **NOTE**: WASI-SDK's clang may show a warning on Fedora:
 ``/lib64/libtinfo.so.6: no version information available``,
-[RHBZ#1875587](https://bugzilla.redhat.com/show_bug.cgi?id=1875587).
+[RHBZ#1875587](https://bugzilla.redhat.com/show_bug.cgi?id=1875587). The
+warning can be ignored.
 
 ```shell
 export WASI_VERSION=16
@@ -443,6 +497,8 @@ ### Install [wasmtime](https://github.com/bytecodealliance/wasmtime) WASI runtim
 
 ### WASI debugging
 
-* ``wasmtime run -g`` generates debugging symbols for gdb and lldb.
+* ``wasmtime run -g`` generates debugging symbols for gdb and lldb. The
+  feature is currently broken, see
+  https://github.com/bytecodealliance/wasmtime/issues/4669 .
 * The environment variable ``RUST_LOG=wasi_common`` enables debug and
   trace logging.
diff --git a/Tools/wasm/config.site-wasm32-emscripten b/Tools/wasm/config.site-wasm32-emscripten
index a31d60d05d..b695a7bf8f 100644
--- a/Tools/wasm/config.site-wasm32-emscripten
+++ b/Tools/wasm/config.site-wasm32-emscripten
@@ -49,6 +49,10 @@ ac_cv_func_geteuid=no
 ac_cv_func_getegid=no
 ac_cv_func_seteuid=no
 ac_cv_func_setegid=no
+ac_cv_func_getresuid=no
+ac_cv_func_getresgid=no
+ac_cv_func_setresuid=no
+ac_cv_func_setresgid=no
 
 # Syscalls not implemented in emscripten
 # [Errno 52] Function not implemented
diff --git a/Tools/wasm/wasi-env b/Tools/wasm/wasi-env
index 6c2d56e0e5..48908b02e6 100755
--- a/Tools/wasm/wasi-env
+++ b/Tools/wasm/wasi-env
@@ -72,4 +72,5 @@ export CFLAGS LDFLAGS
 export PKG_CONFIG_PATH PKG_CONFIG_LIBDIR PKG_CONFIG_SYSROOT_DIR
 export PATH
 
-exec "$@"
+# no exec, it makes arvg[0] path absolute.
+"$@"
diff --git a/Tools/wasm/wasm_assets.py b/Tools/wasm/wasm_assets.py
index 40acea2efa..6557e3f37a 100755
--- a/Tools/wasm/wasm_assets.py
+++ b/Tools/wasm/wasm_assets.py
@@ -58,6 +58,8 @@
     # Pure Python implementations of C extensions
     "_pydecimal.py",
     "_pyio.py",
+    # concurrent threading
+    "concurrent/futures/thread.py",
     # Misc unused or large files
     "pydoc_data/",
     "msilib/",
@@ -99,13 +101,12 @@
     "_dbm": ["dbm/ndbm.py"],
     "_gdbm": ["dbm/gnu.py"],
     "_json": ["json/"],
-    "_multiprocessing": ["concurrent/", "multiprocessing/"],
+    "_multiprocessing": ["concurrent/futures/process.py", "multiprocessing/"],
     "pyexpat": ["xml/", "xmlrpc/"],
     "readline": ["rlcompleter.py"],
     "_sqlite3": ["sqlite3/"],
     "_ssl": ["ssl.py"],
     "_tkinter": ["idlelib/", "tkinter/", "turtle.py", "turtledemo/"],
-
     "_zoneinfo": ["zoneinfo/"],
 }
 
@@ -116,19 +117,28 @@
     "unittest/test/",
 )
 
+SYSCONFIG_NAMES = (
+    "_sysconfigdata__emscripten_wasm32-emscripten",
+    "_sysconfigdata__emscripten_wasm32-emscripten",
+    "_sysconfigdata__wasi_wasm32-wasi",
+    "_sysconfigdata__wasi_wasm64-wasi",
+)
+
+
 def get_builddir(args: argparse.Namespace) -> pathlib.Path:
-    """Get builddir path from pybuilddir.txt
-    """
+    """Get builddir path from pybuilddir.txt"""
     with open("pybuilddir.txt", encoding="utf-8") as f:
         builddir = f.read()
     return pathlib.Path(builddir)
 
 
 def get_sysconfigdata(args: argparse.Namespace) -> pathlib.Path:
-    """Get path to sysconfigdata relative to build root
-    """
+    """Get path to sysconfigdata relative to build root"""
     data_name = sysconfig._get_sysconfigdata_name()
-    assert "emscripten_wasm32" in data_name
+    if not data_name.startswith(SYSCONFIG_NAMES):
+        raise ValueError(
+            f"Invalid sysconfig data name '{data_name}'.", SYSCONFIG_NAMES
+        )
     filename = data_name + ".py"
     return args.builddir / filename
 
@@ -138,20 +148,23 @@ def create_stdlib_zip(
     *,
     optimize: int = 0,
 ) -> None:
-    def filterfunc(name: str) -> bool:
-        return not name.startswith(args.omit_subdirs_absolute)
+    def filterfunc(filename: str) -> bool:
+        pathname = pathlib.Path(filename).resolve()
+        return pathname not in args.omit_files_absolute
 
     with zipfile.PyZipFile(
-        args.wasm_stdlib_zip, mode="w", compression=args.compression, optimize=optimize
+        args.wasm_stdlib_zip,
+        mode="w",
+        compression=args.compression,
+        optimize=optimize,
     ) as pzf:
         if args.compresslevel is not None:
             pzf.compresslevel = args.compresslevel
         pzf.writepy(args.sysconfig_data)
         for entry in sorted(args.srcdir_lib.iterdir()):
+            entry = entry.resolve()
             if entry.name == "__pycache__":
                 continue
-            if entry in args.omit_files_absolute:
-                continue
             if entry.name.endswith(".py") or entry.is_dir():
                 # writepy() writes .pyc files (bytecode).
                 pzf.writepy(entry, filterfunc=filterfunc)
@@ -229,15 +242,15 @@ def main():
 
     extmods = detect_extension_modules(args)
     omit_files = list(OMIT_FILES)
-    omit_files.extend(OMIT_NETWORKING_FILES)
+    if sysconfig.get_platform().startswith("emscripten"):
+        omit_files.extend(OMIT_NETWORKING_FILES)
     for modname, modfiles in OMIT_MODULE_FILES.items():
         if not extmods.get(modname):
             omit_files.extend(modfiles)
 
-    args.omit_files_absolute = {args.srcdir_lib / name for name in omit_files}
-    args.omit_subdirs_absolute = tuple(
-        str(args.srcdir_lib / name) for name in OMIT_SUBDIRS
-    )
+    args.omit_files_absolute = {
+        (args.srcdir_lib / name).resolve() for name in omit_files
+    }
 
     # Empty, unused directory for dynamic libs, but required for site initialization.
     args.wasm_dynload.mkdir(parents=True, exist_ok=True)
diff --git a/Tools/wasm/wasm_build.py b/Tools/wasm/wasm_build.py
new file mode 100755
index 0000000000..63812c6f31
--- /dev/null
+++ b/Tools/wasm/wasm_build.py
@@ -0,0 +1,907 @@
+#!/usr/bin/env python3
+"""Build script for Python on WebAssembly platforms.
+
+  $ ./Tools/wasm/wasm_builder.py emscripten-browser build repl
+  $ ./Tools/wasm/wasm_builder.py emscripten-node-dl build test
+  $ ./Tools/wasm/wasm_builder.py wasi build test
+
+Primary build targets are "emscripten-node-dl" (NodeJS, dynamic linking),
+"emscripten-browser", and "wasi".
+
+Emscripten builds require a recent Emscripten SDK. The tools looks for an
+activated EMSDK environment (". /path/to/emsdk_env.sh"). System packages
+(Debian, Homebrew) are not supported.
+
+WASI builds require WASI SDK and wasmtime. The tool looks for 'WASI_SDK_PATH'
+and falls back to /opt/wasi-sdk.
+
+The 'build' Python interpreter must be rebuilt every time Python's byte code
+changes.
+
+  ./Tools/wasm/wasm_builder.py --clean build build
+
+"""
+import argparse
+import enum
+import dataclasses
+import logging
+import os
+import pathlib
+import re
+import shlex
+import shutil
+import socket
+import subprocess
+import sys
+import sysconfig
+import tempfile
+import time
+import warnings
+import webbrowser
+
+# for Python 3.8
+from typing import Any, Callable, Dict, Iterable, List, Optional, Tuple, Union
+
+logger = logging.getLogger("wasm_build")
+
+SRCDIR = pathlib.Path(__file__).parent.parent.parent.absolute()
+WASMTOOLS = SRCDIR / "Tools" / "wasm"
+BUILDDIR = SRCDIR / "builddir"
+CONFIGURE = SRCDIR / "configure"
+SETUP_LOCAL = SRCDIR / "Modules" / "Setup.local"
+
+HAS_CCACHE = shutil.which("ccache") is not None
+
+# path to WASI-SDK root
+WASI_SDK_PATH = pathlib.Path(os.environ.get("WASI_SDK_PATH", "/opt/wasi-sdk"))
+
+# path to Emscripten SDK config file.
+# auto-detect's EMSDK in /opt/emsdk without ". emsdk_env.sh".
+EM_CONFIG = pathlib.Path(os.environ.setdefault("EM_CONFIG", "/opt/emsdk/.emscripten"))
+EMSDK_MIN_VERSION = (3, 1, 19)
+EMSDK_BROKEN_VERSION = {
+    (3, 1, 14): "https://github.com/emscripten-core/emscripten/issues/17338",
+    (3, 1, 16): "https://github.com/emscripten-core/emscripten/issues/17393",
+    (3, 1, 20): "https://github.com/emscripten-core/emscripten/issues/17720",
+}
+_MISSING = pathlib.PurePath("MISSING")
+
+WASM_WEBSERVER = WASMTOOLS / "wasm_webserver.py"
+
+CLEAN_SRCDIR = f"""
+Builds require a clean source directory. Please use a clean checkout or
+run "make clean -C '{SRCDIR}'".
+"""
+
+INSTALL_NATIVE = f"""
+Builds require a C compiler (gcc, clang), make, pkg-config, and development
+headers for dependencies like zlib.
+
+Debian/Ubuntu: sudo apt install build-essential git curl pkg-config zlib1g-dev
+Fedora/CentOS: sudo dnf install gcc make git-core curl pkgconfig zlib-devel
+"""
+
+INSTALL_EMSDK = """
+wasm32-emscripten builds need Emscripten SDK. Please follow instructions at
+https://emscripten.org/docs/getting_started/downloads.html how to install
+Emscripten and how to activate the SDK with "emsdk_env.sh".
+
+    git clone https://github.com/emscripten-core/emsdk.git /path/to/emsdk
+    cd /path/to/emsdk
+    ./emsdk install latest
+    ./emsdk activate latest
+    source /path/to/emsdk_env.sh
+"""
+
+INSTALL_WASI_SDK = """
+wasm32-wasi builds need WASI SDK. Please fetch the latest SDK from
+https://github.com/WebAssembly/wasi-sdk/releases and install it to
+"/opt/wasi-sdk". Alternatively you can install the SDK in a different location
+and point the environment variable WASI_SDK_PATH to the root directory
+of the SDK. The SDK is available for Linux x86_64, macOS x86_64, and MinGW.
+"""
+
+INSTALL_WASMTIME = """
+wasm32-wasi tests require wasmtime on PATH. Please follow instructions at
+https://wasmtime.dev/ to install wasmtime.
+"""
+
+
+def parse_emconfig(
+    emconfig: pathlib.Path = EM_CONFIG,
+) -> Tuple[pathlib.PurePath, pathlib.PurePath]:
+    """Parse EM_CONFIG file and lookup EMSCRIPTEN_ROOT and NODE_JS.
+
+    The ".emscripten" config file is a Python snippet that uses "EM_CONFIG"
+    environment variable. EMSCRIPTEN_ROOT is the "upstream/emscripten"
+    subdirectory with tools like "emconfigure".
+    """
+    if not emconfig.exists():
+        return _MISSING, _MISSING
+    with open(emconfig, encoding="utf-8") as f:
+        code = f.read()
+    # EM_CONFIG file is a Python snippet
+    local: Dict[str, Any] = {}
+    exec(code, globals(), local)
+    emscripten_root = pathlib.Path(local["EMSCRIPTEN_ROOT"])
+    node_js = pathlib.Path(local["NODE_JS"])
+    return emscripten_root, node_js
+
+
+EMSCRIPTEN_ROOT, NODE_JS = parse_emconfig()
+
+
+def read_python_version(configure: pathlib.Path = CONFIGURE) -> str:
+    """Read PACKAGE_VERSION from configure script
+
+    configure and configure.ac are the canonical source for major and
+    minor version number.
+    """
+    version_re = re.compile("^PACKAGE_VERSION='(\d\.\d+)'")
+    with configure.open(encoding="utf-8") as f:
+        for line in f:
+            mo = version_re.match(line)
+            if mo:
+                return mo.group(1)
+    raise ValueError(f"PACKAGE_VERSION not found in {configure}")
+
+
+PYTHON_VERSION = read_python_version()
+
+
+class ConditionError(ValueError):
+    def __init__(self, info: str, text: str):
+        self.info = info
+        self.text = text
+
+    def __str__(self):
+        return f"{type(self).__name__}: '{self.info}'\n{self.text}"
+
+
+class MissingDependency(ConditionError):
+    pass
+
+
+class DirtySourceDirectory(ConditionError):
+    pass
+
+
+@dataclasses.dataclass
+class Platform:
+    """Platform-specific settings
+
+    - CONFIG_SITE override
+    - configure wrapper (e.g. emconfigure)
+    - make wrapper (e.g. emmake)
+    - additional environment variables
+    - check function to verify SDK
+    """
+
+    name: str
+    pythonexe: str
+    config_site: Optional[pathlib.PurePath]
+    configure_wrapper: Optional[pathlib.PurePath]
+    make_wrapper: Optional[pathlib.PurePath]
+    environ: dict
+    check: Callable[[], None]
+    # Used for build_emports().
+    ports: Optional[pathlib.PurePath]
+    cc: Optional[pathlib.PurePath]
+
+    def getenv(self, profile: "BuildProfile") -> dict:
+        return self.environ.copy()
+
+
+def _check_clean_src():
+    candidates = [
+        SRCDIR / "Programs" / "python.o",
+        SRCDIR / "Python" / "frozen_modules" / "importlib._bootstrap.h",
+    ]
+    for candidate in candidates:
+        if candidate.exists():
+            raise DirtySourceDirectory(os.fspath(candidate), CLEAN_SRCDIR)
+
+
+def _check_native():
+    if not any(shutil.which(cc) for cc in ["cc", "gcc", "clang"]):
+        raise MissingDependency("cc", INSTALL_NATIVE)
+    if not shutil.which("make"):
+        raise MissingDependency("make", INSTALL_NATIVE)
+    if sys.platform == "linux":
+        # skip pkg-config check on macOS
+        if not shutil.which("pkg-config"):
+            raise MissingDependency("pkg-config", INSTALL_NATIVE)
+        # zlib is needed to create zip files
+        for devel in ["zlib"]:
+            try:
+                subprocess.check_call(["pkg-config", "--exists", devel])
+            except subprocess.CalledProcessError:
+                raise MissingDependency(devel, INSTALL_NATIVE) from None
+    _check_clean_src()
+
+
+NATIVE = Platform(
+    "native",
+    # macOS has python.exe
+    pythonexe=sysconfig.get_config_var("BUILDPYTHON") or "python",
+    config_site=None,
+    configure_wrapper=None,
+    ports=None,
+    cc=None,
+    make_wrapper=None,
+    environ={},
+    check=_check_native,
+)
+
+
+def _check_emscripten():
+    if EMSCRIPTEN_ROOT is _MISSING:
+        raise MissingDependency("Emscripten SDK EM_CONFIG", INSTALL_EMSDK)
+    # sanity check
+    emconfigure = EMSCRIPTEN.configure_wrapper
+    if not emconfigure.exists():
+        raise MissingDependency(os.fspath(emconfigure), INSTALL_EMSDK)
+    # version check
+    version_txt = EMSCRIPTEN_ROOT / "emscripten-version.txt"
+    if not version_txt.exists():
+        raise MissingDependency(os.fspath(version_txt), INSTALL_EMSDK)
+    with open(version_txt) as f:
+        version = f.read().strip().strip('"')
+    if version.endswith("-git"):
+        # git / upstream / tot-upstream installation
+        version = version[:-4]
+    version_tuple = tuple(int(v) for v in version.split("."))
+    if version_tuple < EMSDK_MIN_VERSION:
+        raise ConditionError(
+            os.fspath(version_txt),
+            f"Emscripten SDK {version} in '{EMSCRIPTEN_ROOT}' is older than "
+            "minimum required version "
+            f"{'.'.join(str(v) for v in EMSDK_MIN_VERSION)}.",
+        )
+    broken = EMSDK_BROKEN_VERSION.get(version_tuple)
+    if broken is not None:
+        raise ConditionError(
+            os.fspath(version_txt),
+            (
+                f"Emscripten SDK {version} in '{EMSCRIPTEN_ROOT}' has known "
+                f"bugs, see {broken}."
+            ),
+        )
+    if os.environ.get("PKG_CONFIG_PATH"):
+        warnings.warn(
+            "PKG_CONFIG_PATH is set and not empty. emconfigure overrides "
+            "this environment variable. Use EM_PKG_CONFIG_PATH instead."
+        )
+    _check_clean_src()
+
+
+EMSCRIPTEN = Platform(
+    "emscripten",
+    pythonexe="python.js",
+    config_site=WASMTOOLS / "config.site-wasm32-emscripten",
+    configure_wrapper=EMSCRIPTEN_ROOT / "emconfigure",
+    ports=EMSCRIPTEN_ROOT / "embuilder",
+    cc=EMSCRIPTEN_ROOT / "emcc",
+    make_wrapper=EMSCRIPTEN_ROOT / "emmake",
+    environ={
+        # workaround for https://github.com/emscripten-core/emscripten/issues/17635
+        "TZ": "UTC",
+        "EM_COMPILER_WRAPPER": "ccache" if HAS_CCACHE else None,
+        "PATH": [EMSCRIPTEN_ROOT, os.environ["PATH"]],
+    },
+    check=_check_emscripten,
+)
+
+
+def _check_wasi():
+    wasm_ld = WASI_SDK_PATH / "bin" / "wasm-ld"
+    if not wasm_ld.exists():
+        raise MissingDependency(os.fspath(wasm_ld), INSTALL_WASI_SDK)
+    wasmtime = shutil.which("wasmtime")
+    if wasmtime is None:
+        raise MissingDependency("wasmtime", INSTALL_WASMTIME)
+    _check_clean_src()
+
+
+WASI = Platform(
+    "wasi",
+    pythonexe="python.wasm",
+    config_site=WASMTOOLS / "config.site-wasm32-wasi",
+    configure_wrapper=WASMTOOLS / "wasi-env",
+    ports=None,
+    cc=WASI_SDK_PATH / "bin" / "clang",
+    make_wrapper=None,
+    environ={
+        "WASI_SDK_PATH": WASI_SDK_PATH,
+        # workaround for https://github.com/python/cpython/issues/95952
+        "HOSTRUNNER": (
+            "wasmtime run "
+            "--env PYTHONPATH=/{relbuilddir}/build/lib.wasi-wasm32-{version}:/Lib "
+            "--mapdir /::{srcdir} --"
+        ),
+        "PATH": [WASI_SDK_PATH / "bin", os.environ["PATH"]],
+    },
+    check=_check_wasi,
+)
+
+
+class Host(enum.Enum):
+    """Target host triplet"""
+
+    wasm32_emscripten = "wasm32-unknown-emscripten"
+    wasm64_emscripten = "wasm64-unknown-emscripten"
+    wasm32_wasi = "wasm32-unknown-wasi"
+    wasm64_wasi = "wasm64-unknown-wasi"
+    # current platform
+    build = sysconfig.get_config_var("BUILD_GNU_TYPE")
+
+    @property
+    def platform(self) -> Platform:
+        if self.is_emscripten:
+            return EMSCRIPTEN
+        elif self.is_wasi:
+            return WASI
+        else:
+            return NATIVE
+
+    @property
+    def is_emscripten(self) -> bool:
+        cls = type(self)
+        return self in {cls.wasm32_emscripten, cls.wasm64_emscripten}
+
+    @property
+    def is_wasi(self) -> bool:
+        cls = type(self)
+        return self in {cls.wasm32_wasi, cls.wasm64_wasi}
+
+    def get_extra_paths(self) -> Iterable[pathlib.PurePath]:
+        """Host-specific os.environ["PATH"] entries.
+
+        Emscripten's Node version 14.x works well for wasm32-emscripten.
+        wasm64-emscripten requires more recent v8 version, e.g. node 16.x.
+        Attempt to use system's node command.
+        """
+        cls = type(self)
+        if self == cls.wasm32_emscripten:
+            return [NODE_JS.parent]
+        elif self == cls.wasm64_emscripten:
+            # TODO: look for recent node
+            return []
+        else:
+            return []
+
+    @property
+    def emport_args(self) -> List[str]:
+        """Host-specific port args (Emscripten)."""
+        cls = type(self)
+        if self is cls.wasm64_emscripten:
+            return ["-sMEMORY64=1"]
+        elif self is cls.wasm32_emscripten:
+            return ["-sMEMORY64=0"]
+        else:
+            return []
+
+    @property
+    def embuilder_args(self) -> List[str]:
+        """Host-specific embuilder args (Emscripten)."""
+        cls = type(self)
+        if self is cls.wasm64_emscripten:
+            return ["--wasm64"]
+        else:
+            return []
+
+
+class EmscriptenTarget(enum.Enum):
+    """Emscripten-specific targets (--with-emscripten-target)"""
+
+    browser = "browser"
+    browser_debug = "browser-debug"
+    node = "node"
+    node_debug = "node-debug"
+
+    @property
+    def is_browser(self):
+        cls = type(self)
+        return self in {cls.browser, cls.browser_debug}
+
+    @property
+    def emport_args(self) -> List[str]:
+        """Target-specific port args."""
+        cls = type(self)
+        if self in {cls.browser_debug, cls.node_debug}:
+            # some libs come in debug and non-debug builds
+            return ["-O0"]
+        else:
+            return ["-O2"]
+
+
+class SupportLevel(enum.Enum):
+    supported = "tier 3, supported"
+    working = "working, unsupported"
+    experimental = "experimental, may be broken"
+    broken = "broken / unavailable"
+
+    def __bool__(self):
+        cls = type(self)
+        return self in {cls.supported, cls.working}
+
+
+@dataclasses.dataclass
+class BuildProfile:
+    name: str
+    support_level: SupportLevel
+    host: Host
+    target: Union[EmscriptenTarget, None] = None
+    dynamic_linking: Union[bool, None] = None
+    pthreads: Union[bool, None] = None
+    default_testopts: str = "-j2"
+
+    @property
+    def is_browser(self) -> bool:
+        """Is this a browser build?"""
+        return self.target is not None and self.target.is_browser
+
+    @property
+    def builddir(self) -> pathlib.Path:
+        """Path to build directory"""
+        return BUILDDIR / self.name
+
+    @property
+    def python_cmd(self) -> pathlib.Path:
+        """Path to python executable"""
+        return self.builddir / self.host.platform.pythonexe
+
+    @property
+    def makefile(self) -> pathlib.Path:
+        """Path to Makefile"""
+        return self.builddir / "Makefile"
+
+    @property
+    def configure_cmd(self) -> List[str]:
+        """Generate configure command"""
+        # use relative path, so WASI tests can find lib prefix.
+        # pathlib.Path.relative_to() does not work here.
+        configure = os.path.relpath(CONFIGURE, self.builddir)
+        cmd = [configure, "-C"]
+        platform = self.host.platform
+        if platform.configure_wrapper:
+            cmd.insert(0, os.fspath(platform.configure_wrapper))
+
+        cmd.append(f"--host={self.host.value}")
+        cmd.append(f"--build={Host.build.value}")
+
+        if self.target is not None:
+            assert self.host.is_emscripten
+            cmd.append(f"--with-emscripten-target={self.target.value}")
+
+        if self.dynamic_linking is not None:
+            assert self.host.is_emscripten
+            opt = "enable" if self.dynamic_linking else "disable"
+            cmd.append(f"--{opt}-wasm-dynamic-linking")
+
+        if self.pthreads is not None:
+            assert self.host.is_emscripten
+            opt = "enable" if self.pthreads else "disable"
+            cmd.append(f"--{opt}-wasm-pthreads")
+
+        if self.host != Host.build:
+            cmd.append(f"--with-build-python={BUILD.python_cmd}")
+
+        if platform.config_site is not None:
+            cmd.append(f"CONFIG_SITE={platform.config_site}")
+
+        return cmd
+
+    @property
+    def make_cmd(self) -> List[str]:
+        """Generate make command"""
+        cmd = ["make"]
+        platform = self.host.platform
+        if platform.make_wrapper:
+            cmd.insert(0, os.fspath(platform.make_wrapper))
+        return cmd
+
+    def getenv(self) -> dict:
+        """Generate environ dict for platform"""
+        env = os.environ.copy()
+        env.setdefault("MAKEFLAGS", f"-j{os.cpu_count()}")
+        platenv = self.host.platform.getenv(self)
+        for key, value in platenv.items():
+            if value is None:
+                env.pop(key, None)
+            elif key == "PATH":
+                # list of path items, prefix with extra paths
+                new_path: List[pathlib.PurePath] = []
+                new_path.extend(self.host.get_extra_paths())
+                new_path.extend(value)
+                env[key] = os.pathsep.join(os.fspath(p) for p in new_path)
+            elif isinstance(value, str):
+                env[key] = value.format(
+                    relbuilddir=self.builddir.relative_to(SRCDIR),
+                    srcdir=SRCDIR,
+                    version=PYTHON_VERSION,
+                )
+            else:
+                env[key] = value
+        return env
+
+    def _run_cmd(
+        self,
+        cmd: Iterable[str],
+        args: Iterable[str] = (),
+        cwd: Optional[pathlib.Path] = None,
+    ):
+        cmd = list(cmd)
+        cmd.extend(args)
+        if cwd is None:
+            cwd = self.builddir
+        logger.info('Running "%s" in "%s"', shlex.join(cmd), cwd)
+        return subprocess.check_call(
+            cmd,
+            cwd=os.fspath(cwd),
+            env=self.getenv(),
+        )
+
+    def _check_execute(self):
+        if self.is_browser:
+            raise ValueError(f"Cannot execute on {self.target}")
+
+    def run_build(self, *args):
+        """Run configure (if necessary) and make"""
+        if not self.makefile.exists():
+            logger.info("Makefile not found, running configure")
+            self.run_configure(*args)
+        self.run_make("all", *args)
+
+    def run_configure(self, *args):
+        """Run configure script to generate Makefile"""
+        os.makedirs(self.builddir, exist_ok=True)
+        return self._run_cmd(self.configure_cmd, args)
+
+    def run_make(self, *args):
+        """Run make (defaults to build all)"""
+        return self._run_cmd(self.make_cmd, args)
+
+    def run_pythoninfo(self, *args):
+        """Run 'make pythoninfo'"""
+        self._check_execute()
+        return self.run_make("pythoninfo", *args)
+
+    def run_test(self, target: str, testopts: Optional[str] = None):
+        """Run buildbottests"""
+        self._check_execute()
+        if testopts is None:
+            testopts = self.default_testopts
+        return self.run_make(target, f"TESTOPTS={testopts}")
+
+    def run_py(self, *args):
+        """Run Python with hostrunner"""
+        self._check_execute()
+        self.run_make(
+            "--eval", f"run: all; $(HOSTRUNNER) ./$(PYTHON) {shlex.join(args)}", "run"
+        )
+
+    def run_browser(self, bind="127.0.0.1", port=8000):
+        """Run WASM webserver and open build in browser"""
+        relbuilddir = self.builddir.relative_to(SRCDIR)
+        url = f"http://{bind}:{port}/{relbuilddir}/python.html"
+        args = [
+            sys.executable,
+            os.fspath(WASM_WEBSERVER),
+            "--bind",
+            bind,
+            "--port",
+            str(port),
+        ]
+        srv = subprocess.Popen(args, cwd=SRCDIR)
+        # wait for server
+        end = time.monotonic() + 3.0
+        while time.monotonic() < end and srv.returncode is None:
+            try:
+                with socket.create_connection((bind, port), timeout=0.1) as s:
+                    pass
+            except OSError:
+                time.sleep(0.01)
+            else:
+                break
+
+        webbrowser.open(url)
+
+        try:
+            srv.wait()
+        except KeyboardInterrupt:
+            pass
+
+    def clean(self, all: bool = False):
+        """Clean build directory"""
+        if all:
+            if self.builddir.exists():
+                shutil.rmtree(self.builddir)
+        elif self.makefile.exists():
+            self.run_make("clean")
+
+    def build_emports(self, force: bool = False):
+        """Pre-build emscripten ports."""
+        platform = self.host.platform
+        if platform.ports is None or platform.cc is None:
+            raise ValueError("Need ports and CC command")
+
+        embuilder_cmd = [os.fspath(platform.ports)]
+        embuilder_cmd.extend(self.host.embuilder_args)
+        if force:
+            embuilder_cmd.append("--force")
+
+        ports_cmd = [os.fspath(platform.cc)]
+        ports_cmd.extend(self.host.emport_args)
+        if self.target:
+            ports_cmd.extend(self.target.emport_args)
+
+        if self.dynamic_linking:
+            # Trigger PIC build.
+            ports_cmd.append("-sMAIN_MODULE")
+            embuilder_cmd.append("--pic")
+
+        if self.pthreads:
+            # Trigger multi-threaded build.
+            ports_cmd.append("-sUSE_PTHREADS")
+
+        # Pre-build libbz2, libsqlite3, libz, and some system libs.
+        ports_cmd.extend(["-sUSE_ZLIB", "-sUSE_BZIP2", "-sUSE_SQLITE3"])
+        # Multi-threaded sqlite3 has different suffix
+        embuilder_cmd.extend(
+            ["build", "bzip2", "sqlite3-mt" if self.pthreads else "sqlite3", "zlib"]
+        )
+
+        self._run_cmd(embuilder_cmd, cwd=SRCDIR)
+
+        with tempfile.TemporaryDirectory(suffix="-py-emport") as tmpdir:
+            tmppath = pathlib.Path(tmpdir)
+            main_c = tmppath / "main.c"
+            main_js = tmppath / "main.js"
+            with main_c.open("w") as f:
+                f.write("int main(void) { return 0; }\n")
+            args = [
+                os.fspath(main_c),
+                "-o",
+                os.fspath(main_js),
+            ]
+            self._run_cmd(ports_cmd, args, cwd=tmppath)
+
+
+# native build (build Python)
+BUILD = BuildProfile(
+    "build",
+    support_level=SupportLevel.working,
+    host=Host.build,
+)
+
+_profiles = [
+    BUILD,
+    # wasm32-emscripten
+    BuildProfile(
+        "emscripten-browser",
+        support_level=SupportLevel.supported,
+        host=Host.wasm32_emscripten,
+        target=EmscriptenTarget.browser,
+        dynamic_linking=True,
+    ),
+    BuildProfile(
+        "emscripten-browser-debug",
+        support_level=SupportLevel.working,
+        host=Host.wasm32_emscripten,
+        target=EmscriptenTarget.browser_debug,
+        dynamic_linking=True,
+    ),
+    BuildProfile(
+        "emscripten-node-dl",
+        support_level=SupportLevel.supported,
+        host=Host.wasm32_emscripten,
+        target=EmscriptenTarget.node,
+        dynamic_linking=True,
+    ),
+    BuildProfile(
+        "emscripten-node-dl-debug",
+        support_level=SupportLevel.working,
+        host=Host.wasm32_emscripten,
+        target=EmscriptenTarget.node_debug,
+        dynamic_linking=True,
+    ),
+    BuildProfile(
+        "emscripten-node-pthreads",
+        support_level=SupportLevel.supported,
+        host=Host.wasm32_emscripten,
+        target=EmscriptenTarget.node,
+        pthreads=True,
+    ),
+    BuildProfile(
+        "emscripten-node-pthreads-debug",
+        support_level=SupportLevel.working,
+        host=Host.wasm32_emscripten,
+        target=EmscriptenTarget.node_debug,
+        pthreads=True,
+    ),
+    # Emscripten build with both pthreads and dynamic linking is crashing.
+    BuildProfile(
+        "emscripten-node-dl-pthreads-debug",
+        support_level=SupportLevel.broken,
+        host=Host.wasm32_emscripten,
+        target=EmscriptenTarget.node_debug,
+        dynamic_linking=True,
+        pthreads=True,
+    ),
+    # wasm64-emscripten (requires Emscripten >= 3.1.21)
+    BuildProfile(
+        "wasm64-emscripten-node-debug",
+        support_level=SupportLevel.experimental,
+        host=Host.wasm64_emscripten,
+        target=EmscriptenTarget.node_debug,
+        # MEMORY64 is not compatible with dynamic linking
+        dynamic_linking=False,
+        pthreads=False,
+    ),
+    # wasm32-wasi
+    BuildProfile(
+        "wasi",
+        support_level=SupportLevel.supported,
+        host=Host.wasm32_wasi,
+    ),
+    # no SDK available yet
+    # BuildProfile(
+    #    "wasm64-wasi",
+    #    support_level=SupportLevel.broken,
+    #    host=Host.wasm64_wasi,
+    # ),
+]
+
+PROFILES = {p.name: p for p in _profiles}
+
+parser = argparse.ArgumentParser(
+    "wasm_build.py",
+    description=__doc__,
+    formatter_class=argparse.RawTextHelpFormatter,
+)
+
+parser.add_argument(
+    "--clean",
+    "-c",
+    help="Clean build directories first",
+    action="store_true",
+)
+
+parser.add_argument(
+    "--verbose",
+    "-v",
+    help="Verbose logging",
+    action="store_true",
+)
+
+parser.add_argument(
+    "--silent",
+    help="Run configure and make in silent mode",
+    action="store_true",
+)
+
+parser.add_argument(
+    "--testopts",
+    help=(
+        "Additional test options for 'test' and 'hostrunnertest', e.g. "
+        "--testopts='-v test_os'."
+    ),
+    default=None,
+)
+
+# Don't list broken and experimental variants in help
+platforms_choices = list(p.name for p in _profiles) + ["cleanall"]
+platforms_help = list(p.name for p in _profiles if p.support_level) + ["cleanall"]
+parser.add_argument(
+    "platform",
+    metavar="PLATFORM",
+    help=f"Build platform: {', '.join(platforms_help)}",
+    choices=platforms_choices,
+)
+
+ops = dict(
+    build="auto build (build 'build' Python, emports, configure, compile)",
+    configure="run ./configure",
+    compile="run 'make all'",
+    pythoninfo="run 'make pythoninfo'",
+    test="run 'make buildbottest TESTOPTS=...' (supports parallel tests)",
+    hostrunnertest="run 'make hostrunnertest TESTOPTS=...'",
+    repl="start interactive REPL / webserver + browser session",
+    clean="run 'make clean'",
+    cleanall="remove all build directories",
+    emports="build Emscripten port with embuilder (only Emscripten)",
+)
+ops_help = "\n".join(f"{op:16s} {help}" for op, help in ops.items())
+parser.add_argument(
+    "ops",
+    metavar="OP",
+    help=f"operation (default: build)\n\n{ops_help}",
+    choices=tuple(ops),
+    default="build",
+    nargs="*",
+)
+
+
+def main():
+    args = parser.parse_args()
+    logging.basicConfig(
+        level=logging.INFO if args.verbose else logging.ERROR,
+        format="%(message)s",
+    )
+
+    if args.platform == "cleanall":
+        for builder in PROFILES.values():
+            builder.clean(all=True)
+        parser.exit(0)
+
+    # additional configure and make args
+    cm_args = ("--silent",) if args.silent else ()
+
+    # nargs=* with default quirk
+    if args.ops == "build":
+        args.ops = ["build"]
+
+    builder = PROFILES[args.platform]
+    try:
+        builder.host.platform.check()
+    except ConditionError as e:
+        parser.error(str(e))
+
+    if args.clean:
+        builder.clean(all=False)
+
+    # hack for WASI
+    if builder.host.is_wasi and not SETUP_LOCAL.exists():
+        SETUP_LOCAL.touch()
+
+    # auto-build
+    if "build" in args.ops:
+        # check and create build Python
+        if builder is not BUILD:
+            logger.info("Auto-building 'build' Python.")
+            try:
+                BUILD.host.platform.check()
+            except ConditionError as e:
+                parser.error(str(e))
+            if args.clean:
+                BUILD.clean(all=False)
+            BUILD.run_build(*cm_args)
+        # build Emscripten ports with embuilder
+        if builder.host.is_emscripten and "emports" not in args.ops:
+            builder.build_emports()
+
+    for op in args.ops:
+        logger.info("\n*** %s %s", args.platform, op)
+        if op == "build":
+            builder.run_build(*cm_args)
+        elif op == "configure":
+            builder.run_configure(*cm_args)
+        elif op == "compile":
+            builder.run_make("all", *cm_args)
+        elif op == "pythoninfo":
+            builder.run_pythoninfo(*cm_args)
+        elif op == "repl":
+            if builder.is_browser:
+                builder.run_browser()
+            else:
+                builder.run_py()
+        elif op == "test":
+            builder.run_test("buildbottest", testopts=args.testopts)
+        elif op == "hostrunnertest":
+            builder.run_test("hostrunnertest", testopts=args.testopts)
+        elif op == "clean":
+            builder.clean(all=False)
+        elif op == "cleanall":
+            builder.clean(all=True)
+        elif op == "emports":
+            builder.build_emports(force=args.clean)
+        else:
+            raise ValueError(op)
+
+    print(builder.builddir)
+    parser.exit(0)
+
+
+if __name__ == "__main__":
+    main()
diff --git a/configure.ac b/configure.ac
index ab5e1de6fa..79dc1f159a 100644
--- a/configure.ac
+++ b/configure.ac
@@ -753,6 +753,16 @@ if test -z "$CFLAGS"; then
         CFLAGS=
 fi
 
+dnl Emscripten SDK and WASI SDK default to wasm32.
+dnl On Emscripten use MEMORY64 setting to build target wasm64-emscripten.
+dnl for wasm64.
+AS_CASE([$host],
+  [wasm64-*-emscripten], [
+    AS_VAR_APPEND([CFLAGS], [" -sMEMORY64=1"])
+    AS_VAR_APPEND([LDFLAGS], [" -sMEMORY64=1"])
+  ],
+)
+
 if test "$ac_sys_system" = "Darwin"
 then
 	# Compiler selection on MacOSX is more complicated than
@@ -1056,7 +1066,7 @@ cat > conftest.c <<EOF
 #    error unknown wasm32 platform
 #  endif
 #elif defined(__wasm64__)
-#  if defined(__EMSCRIPTEN)
+#  if defined(__EMSCRIPTEN__)
 	wasm64-emscripten
 #  elif defined(__wasi__)
 	wasm64-wasi
@@ -1523,16 +1533,41 @@ if test "$cross_compiling" = yes; then
 fi
 
 AC_ARG_VAR([HOSTRUNNER], [Program to run CPython for the host platform])
-AC_MSG_CHECKING([HOSTRUNNER])
 if test -z "$HOSTRUNNER"
 then
   AS_CASE([$ac_sys_system/$ac_sys_emscripten_target],
     [Emscripten/node*], [
+      AC_PATH_TOOL([NODE], [node], [node])
+      HOSTRUNNER="$NODE"
       # bigint for ctypes c_longlong, c_longdouble
-      HOSTRUNNER="node --experimental-wasm-bigint"
+      # no longer available in Node 16
+      AC_CACHE_CHECK([for node --experimental-wasm-bigint], [ac_cv_tool_node_wasm_bigint], [
+        if $NODE -v --experimental-wasm-bigint > /dev/null 2>&1; then
+          ac_cv_tool_node_wasm_bigint=yes
+        else
+          ac_cv_tool_node_wasm_bigint=no
+        fi
+      ])
+      AS_VAR_IF([ac_cv_tool_node_wasm_bigint], [yes], [
+        AS_VAR_APPEND([HOSTRUNNER], [" --experimental-wasm-bigint"])
+      ])
+
       AS_VAR_IF([enable_wasm_pthreads], [yes], [
-        HOSTRUNNER="$HOSTRUNNER --experimental-wasm-threads --experimental-wasm-bulk-memory"
+        AS_VAR_APPEND([HOSTRUNNER], [" --experimental-wasm-threads"])
+        # no longer available in Node 16
+        AC_CACHE_CHECK([for node --experimental-wasm-bulk-memory], [ac_cv_tool_node_wasm_bulk_memory], [
+          if $NODE -v --experimental-wasm-bulk-memory > /dev/null 2>&1; then
+            ac_cv_tool_node_wasm_bulk_memory=yes
+          else
+            ac_cv_tool_node_wasm_bulk_memory=no
+          fi
+        ])
+        AS_VAR_IF([ac_cv_tool_node_wasm_bulk_memory], [yes], [
+          AS_VAR_APPEND([HOSTRUNNER], [" --experimental-wasm-bulk-memory"])
+        ])
       ])
+
+      AS_VAR_IF([host_cpu], [wasm64], [AS_VAR_APPEND([HOSTRUNNER], [" --experimental-wasm-memory64"])])
     ],
     dnl TODO: support other WASI runtimes
     dnl wasmtime starts the proces with "/" as CWD. For OOT builds add the
@@ -1542,6 +1577,7 @@ then
   )
 fi
 AC_SUBST([HOSTRUNNER])
+AC_MSG_CHECKING([HOSTRUNNER])
 AC_MSG_RESULT([$HOSTRUNNER])
 
 if test -n "$HOSTRUNNER"; then
@@ -1553,7 +1589,7 @@ AC_MSG_RESULT($LDLIBRARY)
 
 # LIBRARY_DEPS, LINK_PYTHON_OBJS and LINK_PYTHON_DEPS variable
 AS_CASE([$ac_sys_system/$ac_sys_emscripten_target],
-  [Emscripten/browser*], [LIBRARY_DEPS='$(PY3LIBRARY) $(WASM_STDLIB)'],
+  [Emscripten/browser*], [LIBRARY_DEPS='$(PY3LIBRARY) $(WASM_STDLIB) python.html python.worker.js'],
   [LIBRARY_DEPS='$(PY3LIBRARY) $(EXPORTSYMS)']
 )
 LINK_PYTHON_DEPS='$(LIBRARY_DEPS)'
@@ -1746,7 +1782,7 @@ then
 fi
 AC_MSG_RESULT($PROFILE_TASK)
 
-# Make llvm-relatec checks work on systems where llvm tools are not installed with their
+# Make llvm-related checks work on systems where llvm tools are not installed with their
 # normal names in the default $PATH (ie: Ubuntu).  They exist under the
 # non-suffixed name in their versioned llvm directory.
 
@@ -1800,8 +1836,10 @@ esac
 if test "$Py_LTO" = 'true' ; then
   case $CC in
     *clang*)
-      dnl flag to disable lto during linking
       LDFLAGS_NOLTO="-fno-lto"
+      dnl Clang linker requires -flto in order to link objects with LTO information.
+      dnl Thin LTO is faster and works for object files with full LTO information, too.
+      AX_CHECK_COMPILE_FLAG([-flto=thin],[LDFLAGS_NOLTO="-flto=thin"],[LDFLAGS_NOLTO="-flto"])
       AC_SUBST(LLVM_AR)
       AC_PATH_TOOL(LLVM_AR, llvm-ar, '', ${llvm_path})
       AC_SUBST(LLVM_AR_FOUND)
@@ -6796,6 +6834,7 @@ AS_CASE([$ac_sys_system],
     dnl curses and tkinter user interface are not available.
     dnl dbm and gdbm aren't available, too.
     dnl Emscripten and WASI provide only stubs for pwd, grp APIs.
+    dnl resource functions (get/setrusage) are stubs, too.
     PY_STDLIB_MOD_SET_NA(
       [_curses],
       [_curses_panel],
@@ -6811,6 +6850,7 @@ AS_CASE([$ac_sys_system],
       [nis],
       [ossaudiodev],
       [pwd],
+      [resource],
       [spwd],
       [syslog],
     )
@@ -6819,7 +6859,6 @@ AS_CASE([$ac_sys_system],
         dnl These modules are not particularly useful in browsers.
         PY_STDLIB_MOD_SET_NA(
           [fcntl],
-          [resource],
           [readline],
           [termios],
         )
@@ -6831,7 +6870,6 @@ AS_CASE([$ac_sys_system],
           [_ctypes_test],
           [fcntl],
           [mmap],
-          [resource],
           [termios],
         )
       ]
